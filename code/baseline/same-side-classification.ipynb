{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:54:44.026561Z",
     "start_time": "2020-01-20T11:54:42.849462Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:54:46.029776Z",
     "start_time": "2020-01-20T11:54:46.023601Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Clasiification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:54:47.652537Z",
     "start_time": "2020-01-20T11:54:47.649684Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:54:53.124698Z",
     "start_time": "2020-01-20T11:54:49.900122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:01.730243\n",
      "Time for [read within]: 0:00:01.484252\n"
     ]
    }
   ],
   "source": [
    "# escapechar to detect quoting escapes, else it fails\n",
    "\n",
    "# na_filter=False, because pandas automatic \"nan\" detection fails with the topic column, too\n",
    "# cross_test_df['topic'].astype(str)[9270]\n",
    "\n",
    "with Timer(\"read cross\"):\n",
    "    # cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'), quotechar='\"',quoting=csv.QUOTE_ALL,encoding='utf-8',escapechar='\\\\',doublequote=False,index_col='id')\n",
    "    # cross_test_df =  pd.read_csv(data_cross_path.format('test'), quotechar='\"',quoting=csv.QUOTE_ALL,encoding='utf-8',escapechar='\\\\',doublequote=False,index_col='id')\n",
    "    cross_test_df =  pd.read_csv(data_cross_path.format('test'), index_col='id')\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    # within_traindev_df = pd.read_csv(data_within_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    within_traindev_df =  pd.read_csv(data_within_path.format('training'),quotechar='\"',quoting=csv.QUOTE_ALL,encoding='utf-8',escapechar='\\\\',doublequote=False,index_col='id')\n",
    "    # within_test_df =  pd.read_csv(data_within_path.format('test'),  quotechar='\"',quoting=csv.QUOTE_ALL,encoding='utf-8',escapechar='\\\\',doublequote=False,index_col='id')\n",
    "    within_test_df =  pd.read_csv(data_within_path.format('test'), index_col='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:26.136596Z",
     "start_time": "2020-01-20T11:54:54.464212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag cross]: 0:00:46.870798\n",
      "Time for [tag within]: 0:00:44.794555\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if title.find('abortion') > -1:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif title.find('gay marriage') > -1:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross\"):\n",
    "    cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "    cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within\"):\n",
    "    within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "    within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:26.255648Z",
     "start_time": "2020-01-20T11:56:26.243849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gay marriage', 'abortion'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_traindev_df['tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:26.431692Z",
     "start_time": "2020-01-20T11:56:26.363114Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63903 entries, 85249 to 3298\n",
      "Data columns (total 8 columns):\n",
      "argument1       63903 non-null object\n",
      "argument1_id    63903 non-null object\n",
      "argument2       63903 non-null object\n",
      "argument2_id    63903 non-null object\n",
      "debate_id       63903 non-null object\n",
      "is_same_side    63903 non-null bool\n",
      "topic           63903 non-null object\n",
      "tag             63903 non-null object\n",
      "dtypes: bool(1), object(7)\n",
      "memory usage: 4.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61048 entries, 0 to 61047\n",
      "Data columns (total 8 columns):\n",
      "argument1       61048 non-null object\n",
      "argument1_id    61048 non-null object\n",
      "argument2       61048 non-null object\n",
      "argument2_id    61048 non-null object\n",
      "debate_id       61048 non-null object\n",
      "is_same_side    61048 non-null bool\n",
      "topic           61048 non-null object\n",
      "tag             61048 non-null object\n",
      "dtypes: bool(1), object(7)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "within_traindev_df.info()\n",
    "cross_traindev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:26.510236Z",
     "start_time": "2020-01-20T11:56:26.500302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(within_traindev_df[['is_same_side']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:26.592699Z",
     "start_time": "2020-01-20T11:56:26.588652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cross_traindev_df[['is_same_side']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#74517\n",
    "# within_traindev_df.loc[82134]['argument2']\n",
    "#within_traindev_df.loc[74517]['argument2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within_traindev_df[(within_traindev_df['tag'] == 'gay marriage') & (within_traindev_df['tag'] == 'gay marriage')]\n",
    "within_traindev_df[(within_traindev_df['tag'] == 'gay marriage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within_traindev_df[(within_traindev_df['tag'] == 'gay marriage') and (within_traindev_df['is_same_side'] == 'True')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [\n",
    "        len(word_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_length_lst.extend(\n",
    "        [len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [\n",
    "        len(sent_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_sent_length_lst.extend(\n",
    "        [len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"overview cross\"):\n",
    "    get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"overview within\"):\n",
    "    get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:26.833172Z",
     "start_time": "2020-01-20T11:56:26.654158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "def get_train_test_sets(df):\n",
    "    X = df[['argument1', 'argument2', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.30,\n",
    "                                                        random_state=1,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:27.345335Z",
     "start_time": "2020-01-20T11:56:26.894555Z"
    },
    "code_folding": [
     8,
     25,
     31
    ]
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "        return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n",
    "        \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "def lemmatize_stemming(token, pos_tag):\n",
    "    stemmer = SnowballStemmer(\n",
    "        \"english\")  # pOrter, M. \"An algorithm for suffix stripping.\"\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(token, pos=pos_tag))\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    lemma = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('\\n', ' ').strip()\n",
    "        tokens = [token for token in word_tokenize(sentence)]\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "        for idx in range(0, len(tokens)):\n",
    "            token = tokens[idx].lower()\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(\n",
    "                    token) > 3:\n",
    "                wordnet_pos = get_wordnet_pos(pos_tags[idx][1])\n",
    "                l_ = lemmatize_stemming(token, wordnet_pos)\n",
    "                lemma.append(l_)\n",
    "    return ' '.join(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:28.905390Z",
     "start_time": "2020-01-20T11:56:28.902572Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_lemma(row):\n",
    "    row['argument1_lemmas'] = preprocess(row['argument1'])\n",
    "    row['argument2_lemmas'] = preprocess(row['argument2'])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting n grams lemma for argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:56:28.986226Z",
     "start_time": "2020-01-20T11:56:28.974629Z"
    },
    "code_folding": [
     3,
     41
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "def extract_ngrams(X_train, X_dev, col, idx='id'):\n",
    "    vectorizer = CountVectorizer(min_df=600,\n",
    "                                 max_df=0.7,\n",
    "                                 ngram_range=(3, 3),\n",
    "                                 max_features=5000)\n",
    "\n",
    "    vectorizer.fit(X_train[col])\n",
    "    features = vectorizer.transform(X_train[col])\n",
    "    features_dev = vectorizer.transform(X_dev[col])\n",
    "\n",
    "    train_df = pd.DataFrame(features.todense(),\n",
    "                            columns=vectorizer.get_feature_names())\n",
    "    train_df = train_df.add_prefix(col)\n",
    "\n",
    "    aid_df = X_train[[idx]]\n",
    "\n",
    "    train_df = train_df.merge(aid_df,\n",
    "                              left_index=True,\n",
    "                              right_index=True,\n",
    "                              suffixes=(False, False),\n",
    "                              how='inner')\n",
    "    train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    dev_df = pd.DataFrame(features_dev.todense(),\n",
    "                          columns=vectorizer.get_feature_names())\n",
    "    dev_df = dev_df.add_prefix(col)\n",
    "\n",
    "    aid_dev_df = X_dev[[idx]]\n",
    "\n",
    "    dev_df = dev_df.merge(aid_dev_df,\n",
    "                          left_index=True,\n",
    "                          right_index=True,\n",
    "                          suffixes=(False, False),\n",
    "                          how='inner')\n",
    "    dev_df.set_index(idx, inplace=True)\n",
    "    return train_df, dev_df\n",
    "\n",
    "\n",
    "def extract_n_grams_features(X_train, X_dev, columns, idx='id'):\n",
    "    X_train = X_train.reset_index()\n",
    "    result_train_df = X_train[[idx]]\n",
    "    result_train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    X_dev = X_dev.reset_index()\n",
    "    result_dev_df = X_dev[[idx]]\n",
    "    result_dev_df.set_index(idx, inplace=True)\n",
    "\n",
    "    for col in columns:\n",
    "        result_train_df_, result_dev_df_ = extract_ngrams(X_train, X_dev, col)\n",
    "        result_train_df = result_train_df.join(result_train_df_)\n",
    "        result_dev_df = result_dev_df.join(result_dev_df_)\n",
    "    return result_train_df, result_dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T13:36:37.150908Z",
     "start_time": "2020-01-20T13:36:37.142275Z"
    },
    "code_folding": [
     6,
     21
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def train_test_svm(X_train, y_train, X_test):\n",
    "    scaler = StandardScaler(copy=True, with_mean=False)\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    svclassifier = SVC(kernel='linear')\n",
    "    svclassifier.fit(X_train, y_train)\n",
    "\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, digits=3):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), digits))  #\n",
    "    print()\n",
    "\n",
    "    print('Report:')\n",
    "    print(classification_report(y_test, y_pred, digits=digits))\n",
    "    f1_dic = {}\n",
    "\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), digits)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), digits)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T14:03:19.728337Z",
     "start_time": "2020-01-20T13:36:39.303617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train]: 0:00:00.016843\n",
      "Time for [2 - lemmatize]: 0:24:58.456637\n",
      "Time for [3 - n-grams]: 0:00:20.130679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - SVM (train -> predict)]: 0:01:21.778531\n",
      "Confusion Matrix:\n",
      "[[ 363 8573]\n",
      " [ 300 9079]]\n",
      "\n",
      "Accuracy:  0.516\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.548     0.041     0.076      8936\n",
      "        True      0.514     0.968     0.672      9379\n",
      "\n",
      "    accuracy                          0.516     18315\n",
      "   macro avg      0.531     0.504     0.374     18315\n",
      "weighted avg      0.531     0.516     0.381     18315\n",
      "\n",
      "Time for [5 - report]: 0:00:00.034135\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "# 2. Lemmatizing argument1 and argument2\n",
    "with Timer(\"2 - lemmatize\"):\n",
    "    X_train = X_train.apply(get_lemma, axis=1)\n",
    "    X_dev = X_dev.apply(get_lemma, axis=1)\n",
    "\n",
    "# 3. Extracting features - 1-3 grams lemma\n",
    "with Timer(\"3 - n-grams\"):\n",
    "    X_train_, X_dev_ = extract_n_grams_features(\n",
    "        X_train, X_dev, columns=['argument1_lemmas', 'argument2_lemmas'])\n",
    "\n",
    "# 4. train\n",
    "with Timer(\"4 - SVM (train -> predict)\"):\n",
    "    y_pred = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 5. Evaluate\n",
    "with Timer(\"5 - report\"):\n",
    "    report_training_results(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T14:24:27.018669Z",
     "start_time": "2020-01-20T14:03:19.880702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train]: 0:00:00.024590\n",
      "Time for [2 - lemmatize]: 0:19:43.205894\n",
      "Time for [3 - n-grams]: 0:00:22.950521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - SVM (train -> predict)]: 0:01:00.917064\n",
      "Confusion Matrix:\n",
      "[[  181  8652]\n",
      " [  149 10189]]\n",
      "\n",
      "Accuracy:  0.541\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.548     0.020     0.040      8833\n",
      "        True      0.541     0.986     0.698     10338\n",
      "\n",
      "    accuracy                          0.541     19171\n",
      "   macro avg      0.545     0.503     0.369     19171\n",
      "weighted avg      0.544     0.541     0.395     19171\n",
      "\n",
      "Time for [5 - report]: 0:00:00.034107\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "# 2. Lemmatizing argument1 and argument2\n",
    "with Timer(\"2 - lemmatize\"):\n",
    "    X_train = X_train.apply(get_lemma, axis=1)\n",
    "    X_dev = X_dev.apply(get_lemma, axis=1)\n",
    "\n",
    "# 3. Extracting features - 1-3 grams lemma\n",
    "with Timer(\"3 - n-grams\"):\n",
    "    X_train_, X_dev_ = extract_n_grams_features(\n",
    "        X_train, X_dev, columns=['argument1_lemmas', 'argument2_lemmas'])\n",
    "\n",
    "# 4. train\n",
    "with Timer(\"4 - SVM (train -> predict)\"):\n",
    "    y_pred = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 5. Evaluate\n",
    "with Timer(\"5 - report\"):\n",
    "    report_training_results(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

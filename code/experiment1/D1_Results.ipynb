{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Side Stance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "- 3 epochs\n",
    "- accumulation steps: 64\n",
    "- sequence length 128-256-512 with batch sizes from 8-16(12)-32\n",
    "- tasks, within/cross\n",
    "- train/dev/test - 80:10:10 - @gregor\n",
    "\n",
    "See [D1_samestance_base.ipynb](D1_samestance_base.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result-Matrix\n",
    "\n",
    "- 3 epochs, acc-step: 64\n",
    "\n",
    "```\n",
    "model_name             task    seql  dev-acc (f1)     test-acc (f1)\n",
    "\n",
    "bert-base-uncased      cross   128   0.8013 (0.7742)  0.6033 (0.5735)\n",
    "bert-base-uncased      cross   256   0.8082 (0.7871)  0.6072 (0.5827)\n",
    "bert-base-uncased      cross   512   0.8627 (0.8641)  0.6477 (0.6594) *?\n",
    "bert-base-uncased      within  128   0.7782 (0.7456)  0.7759 (0.7423)\n",
    "bert-base-uncased      within  256   0.8536 (0.8597)  0.8545 (0.8602)\n",
    "bert-base-uncased      within  512   0.8594 (0.8600)  0.8626 (0.8628)\n",
    "\n",
    "bert-base-cased        cross   256   0.8657 (0.8625)  0.6323 (0.6516)\n",
    "bert-base-cased        cross   512   0.8768 (0.8755)  0.6354 (0.6564)\n",
    "bert-base-cased        within  256   0.8665 (0.8721)  0.8647 (0.8701)\n",
    "bert-base-cased        within  512   0.8708 (0.8759)  0.8731 (0.8762) *?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "roberta-base           cross   256   0.8007 (0.7619)  0.6031 (0.5459)\n",
    "roberta-base           cross   512   0.8097 (0.7787)  0.6155 (0.5538)\n",
    "roberta-base           within  256   0.7683 (0.7275)  0.7619 (0.7185)\n",
    "roberta-base           within  512   0.8199 (0.7979)  0.8221 (0.7999)\n",
    "\n",
    "distilbert-base-cased  cross   256   0.7966 (0.7668)  0.5908 (0.5691)\n",
    "distilbert-base-cased  cross   512   0.8111 (0.7789)  0.5877 (0.5487)\n",
    "distilbert-base-cased  within  256   0.6817 (0.6368)  0.6791 (0.6374)\n",
    "distilbert-base-cased  within  512   0.8216 (0.8039)  0.8235 (0.8044)\n",
    "\n",
    "distilroberta-base     cross   256   0.7982 (0.7644)  0.5907 (0.5480)\n",
    "distilroberta-base     cross   512   0.8087 (0.7739)  0.6010 (0.5569)\n",
    "distilroberta-base     within  256   0.7656 (0.7409)  0.7595 (0.7315)\n",
    "distilroberta-base     within  512   0.8235 (0.8075)  0.8223 (0.8051)\n",
    "\n",
    "xlnet-base-cased       cross   256   0.8179 (0.8101)  0.6162 (0.6363)\n",
    "xlnet-base-cased       cross   512   0.8231 (0.8123)  0.5984 (0.5791)\n",
    "xlnet-base-cased       within  256   0.8253 (0.8068)  0.8235 (0.8030)\n",
    "xlnet-base-cased       within  512   0.8611 (0.8730)  0.8532 (0.8662)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "albert-base-v2         cross   128   0.8008 (0.7762)  0.5925 (0.5865)\n",
    "albert-base-v2         cross   256   0.8496 (0.8518)  0.6455 (0.6729)\n",
    "albert-base-v2         cross   512   0.8826 (0.8841)  0.6619 (0.6895) *\n",
    "albert-base-v2         within  128   0.8122 (0.8086)  0.8079 (0.8038)\n",
    "albert-base-v2         within  256   0.8461 (0.8550)  0.8481 (0.8557)\n",
    "albert-base-v2         within  512   0.8840 (0.8900)  0.8881 (0.8930) *\n",
    "\n",
    "albert-base-v1         cross   256   0.8231 (0.8091)  0.6393 (0.6651)\n",
    "albert-base-v1         within  256   0.8416 (0.8465)  0.8376 (0.8409)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "electra-small-discr.   cross   256   0.7240 (0.6612)  0.5988 (0.5594)\n",
    "electra-small-discr.   cross   512   0.7830 (0.7642)  0.5961 (0.6061)\n",
    "electra-small-discr.   within  256   0.6594 (0.6456)  0.6548 (0.6392)\n",
    "electra-small-discr.   within  512   0.7683 (0.7372)  0.7681 (0.7341)\n",
    "electra-base-discr.    cross   256   0.8052 (0.7815)  0.5971 (0.6081)\n",
    "electra-base-discr.    cross   512   0.8008 (0.7724)  0.5945 (0.6068)\n",
    "electra-base-discr.    within  256   0.8267 (0.8200)  0.8229 (0.8152)\n",
    "electra-base-discr.    within  512   0.8218 (0.8069)  0.8204 (0.8042)\n",
    "\n",
    "# sentence-transformers-*-distilbert-base\n",
    "sent-stsb-distilbert   cross   256   0.8008 (0.7715)  0.5993 (0.5880)\n",
    "sent-stsb-distilbert   cross   512   0.8016 (0.7695)  0.5147 (0.4644)\n",
    "sent-stsb-distilbert   within  256   0.7429 (0.7085)  0.7432 (0.7085)\n",
    "sent-stsb-distilbert   within  512   0.8162 (0.7992)  0.8116 (0.7926)\n",
    "sent-quora-distilbert  within  256   0.6638 (0.6116)  0.6658 (0.6121)\n",
    "\n",
    "queezebert-uncased     cross   256   0.8075 (0.7783)  0.6186 (0.5996)\n",
    "queezebert-uncased     cross   512   0.8324 (0.8298)  0.6425 (0.6632)\n",
    "queezebert-uncased     within  256   0.8348 (0.8290)  0.8296 (0.8228)\n",
    "queezebert-uncased     within  512   0.8404 (0.8360)  0.8446 (0.8398)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- failures (GPU RAM):\n",
    "\n",
    "```\n",
    "distilbert-base-cased  within  128/512\n",
    "facebook-bart-base     *       256  - logging MLflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distilbert-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-base-cased-within_256_32-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/18/2021 21:19:55 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_loss = 0.5513255000114441\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_acc = 0.6816759388038943\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_f1 = 0.6367784169807578\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_acc_and_f1 = 0.659227177892326\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_pearson = 0.4050944720107399\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_spearmanr = 0.4050944720107398\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_corr = 0.40509447201073984\n",
    "[INFO|trainer.py:393] 01/18/2021 21:19:55 >>   eval_class_report = {'accuracy': 0.6816759388038943,\n",
    " 'macro avg': {'f1-score': 0.6767367251235212,\n",
    "               'precision': 0.7127972105949358,\n",
    "               'recall': 0.6927909801952608,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.7166950332662848,\n",
    "              'precision': 0.6133474576271186,\n",
    "              'recall': 0.8619278005210271,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.6367784169807578,\n",
    "          'precision': 0.812246963562753,\n",
    "          'recall': 0.5236541598694943,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.6741108140529433,\n",
    "                  'precision': 0.7193326776710546,\n",
    "                  'recall': 0.6816759388038943,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/18/2021 21:23:37 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_loss = 0.5579596757888794\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_acc = 0.6790799561883899\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_f1 = 0.6374403394025101\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_acc_and_f1 = 0.65826014779545\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_pearson = 0.3940089660430619\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_spearmanr = 0.39400896604306246\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_corr = 0.3940089660430622\n",
    "[INFO|trainer.py:393] 01/18/2021 21:23:37 >>   eval_class_report = {'accuracy': 0.6790799561883899,\n",
    " 'macro avg': {'f1-score': 0.6747903451398516,\n",
    "               'precision': 0.7055551714512976,\n",
    "               'recall': 0.6888094863124192,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.712140350877193,\n",
    "              'precision': 0.6147322510298038,\n",
    "              'recall': 0.8462308205470314,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.6374403394025101,\n",
    "          'precision': 0.7963780918727915,\n",
    "          'recall': 0.5313881520778072,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.6724819032268098,\n",
    "                  'precision': 0.7111685423739217,\n",
    "                  'recall': 0.6790799561883899,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-base-cased-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 00:12:16 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_loss = 0.3376932442188263\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_acc = 0.7965601965601966\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_f1 = 0.7668043559894855\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_acc_and_f1 = 0.781682276274841\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_pearson = 0.6243735883036032\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_spearmanr = 0.6243735883036062\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_corr = 0.6243735883036048\n",
    "[INFO|trainer.py:393] 01/20/2021 00:12:16 >>   eval_class_report = {'accuracy': 0.7965601965601966,\n",
    " 'macro avg': {'f1-score': 0.7931929972858527,\n",
    "               'precision': 0.824940211300326,\n",
    "               'recall': 0.7999339295458953,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8195816385822198,\n",
    "              'precision': 0.7229625832906202,\n",
    "              'recall': 0.9460093896713615,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.7668043559894855,\n",
    "          'precision': 0.9269178393100318,\n",
    "          'recall': 0.653858469420429,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.7925835298947326,\n",
    "                  'precision': 0.8272954685565698,\n",
    "                  'recall': 0.7965601965601966,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 00:34:07 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_loss = 1.083135962486267\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_acc = 0.5908459730826746\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_f1 = 0.5691468421348631\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_acc_and_f1 = 0.5799964076087689\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_pearson = 0.22966467032411747\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_spearmanr = 0.22966467032411791\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_corr = 0.2296646703241177\n",
    "[INFO|trainer.py:393] 01/20/2021 00:34:07 >>   eval_class_report = {'accuracy': 0.5908459730826746,\n",
    " 'macro avg': {'f1-score': 0.5898055357773517,\n",
    "               'precision': 0.6172931284865399,\n",
    "               'recall': 0.6124231689351236,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6104642294198402,\n",
    "              'precision': 0.5122450721051284,\n",
    "              'recall': 0.7552843482637142,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.5691468421348631,\n",
    "          'precision': 0.7223411848679515,\n",
    "          'recall': 0.46956198960653306,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.5866853271883238,\n",
    "                  'precision': 0.6331591775917862,\n",
    "                  'recall': 0.5908459730826746,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-base-cased-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.29273736476898193\n",
    "eval_acc = 0.8216272600834492\n",
    "eval_f1 = 0.8038990825688073\n",
    "eval_acc_and_f1 = 0.8127631713261283\n",
    "eval_pearson = 0.6819301299719024\n",
    "eval_spearmanr = 0.6819301299719028\n",
    "eval_corr = 0.6819301299719026\n",
    "eval_class_report = {'not same': {'precision': 0.7316596931659693, 'recall': 0.9761816151842203, 'f1-score': 0.8364158163265307, 'support': 2687}, 'same': {'precision': 0.970466082141209, 'recall': 0.6861337683523654, 'f1-score': 0.8038990825688073, 'support': 3065}, 'accuracy': 0.8216272600834492, 'macro avg': {'precision': 0.8510628876535892, 'recall': 0.8311576917682928, 'f1-score': 0.820157449447669, 'support': 5752}, 'weighted avg': {'precision': 0.8589096205319481, 'recall': 0.8216272600834492, 'f1-score': 0.8190890101778133, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.2910425066947937\n",
    "eval_acc = 0.8235017994054139\n",
    "eval_f1 = 0.8044382801664354\n",
    "eval_acc_and_f1 = 0.8139700397859246\n",
    "eval_pearson = 0.6871819603509052\n",
    "eval_spearmanr = 0.6871819603509062\n",
    "eval_corr = 0.6871819603509057\n",
    "eval_class_report = {'not same': {'precision': 0.7328187250996016, 'recall': 0.9816544362908606, 'f1-score': 0.8391787852865696, 'support': 2998}, 'same': {'precision': 0.9768421052631578, 'recall': 0.6837606837606838, 'f1-score': 0.8044382801664354, 'support': 3393}, 'accuracy': 0.8235017994054139, 'macro avg': {'precision': 0.8548304151813797, 'recall': 0.8327075600257722, 'f1-score': 0.8218085327265026, 'support': 6391}, 'weighted avg': {'precision': 0.8623714287289157, 'recall': 0.8235017994054139, 'f1-score': 0.82073495272944, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-base-cased-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.31272634863853455\n",
    "eval_acc = 0.8111384111384111\n",
    "eval_f1 = 0.7789069990412273\n",
    "eval_acc_and_f1 = 0.7950227050898192\n",
    "eval_pearson = 0.6634104539368715\n",
    "eval_spearmanr = 0.6634104539368704\n",
    "eval_corr = 0.6634104539368709\n",
    "eval_class_report = {'not same': {'precision': 0.7278843757787191, 'recall': 0.9795439302481556, 'f1-score': 0.8351679771265188, 'support': 2982}, 'same': {'precision': 0.9708413001912046, 'recall': 0.6503362151777138, 'f1-score': 0.7789069990412273, 'support': 3123}, 'accuracy': 0.8111384111384111, 'macro avg': {'precision': 0.8493628379849618, 'recall': 0.8149400727129347, 'f1-score': 0.8070374880838731, 'support': 6105}, 'weighted avg': {'precision': 0.8521684830580298, 'recall': 0.8111384111384111, 'f1-score': 0.8063877912853452, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 1.5841234922409058\n",
    "eval_acc = 0.5877483443708609\n",
    "eval_f1 = 0.5486756709349238\n",
    "eval_acc_and_f1 = 0.5682120076528923\n",
    "eval_pearson = 0.24002766752241633\n",
    "eval_spearmanr = 0.24002766752241617\n",
    "eval_corr = 0.24002766752241625\n",
    "eval_class_report = {'not same': {'precision': 0.5092361055093975, 'recall': 0.7942878711625566, 'f1-score': 0.6205947407225362, 'support': 7948}, 'same': {'precision': 0.74158368895211, 'recall': 0.4354120267260579, 'f1-score': 0.5486756709349238, 'support': 10776}, 'accuracy': 0.5877483443708609, 'macro avg': {'precision': 0.6254098972307538, 'recall': 0.6148499489443072, 'f1-score': 0.58463520582873, 'support': 18724}, 'weighted avg': {'precision': 0.6429563340491684, 'recall': 0.5877483443708609, 'f1-score': 0.5792040177984114, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-uncased-cross_128_32-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/18/2021 23:08:26 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_loss = 0.34257200360298157\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_acc = 0.8013104013104013\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_f1 = 0.7742415782616787\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_acc_and_f1 = 0.78777598978604\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_pearson = 0.631053472069863\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_spearmanr = 0.6310534720698627\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_corr = 0.6310534720698628\n",
    "[INFO|trainer.py:393] 01/18/2021 23:08:26 >>   eval_class_report = {'accuracy': 0.8013104013104013,\n",
    " 'macro avg': {'f1-score': 0.7984122912516526,\n",
    "               'precision': 0.82694336359706,\n",
    "               'recall': 0.8045087689119024,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8225830042416264,\n",
    "              'precision': 0.7294422827496757,\n",
    "              'recall': 0.9429912810194501,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.7742415782616787,\n",
    "          'precision': 0.9244444444444444,\n",
    "          'recall': 0.6660262568043548,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.7978540487403363,\n",
    "                  'precision': 0.8291952313119629,\n",
    "                  'recall': 0.8013104013104013,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/18/2021 23:19:20 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_loss = 0.938666820526123\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_acc = 0.6033967101046784\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_f1 = 0.5735615022395775\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_acc_and_f1 = 0.588479106172128\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_pearson = 0.265119841623542\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_spearmanr = 0.2651198416235421\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_corr = 0.2651198416235421\n",
    "[INFO|trainer.py:393] 01/18/2021 23:19:20 >>   eval_class_report = {'accuracy': 0.6033967101046784,\n",
    " 'macro avg': {'f1-score': 0.6014458205018393,\n",
    "               'precision': 0.6369651374150616,\n",
    "               'recall': 0.6282963894116509,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.629330138764101,\n",
    "              'precision': 0.5215952341552209,\n",
    "              'recall': 0.7931555108203322,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.5735615022395775,\n",
    "          'precision': 0.7523350406749021,\n",
    "          'recall': 0.4634372680029696,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.5972342817256335,\n",
    "                  'precision': 0.6543901580526832,\n",
    "                  'recall': 0.6033967101046784,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-uncased-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 02:13:32 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_loss = 0.31481632590293884\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_acc = 0.8081900081900082\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_f1 = 0.7870521913075105\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_acc_and_f1 = 0.7976210997487594\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_pearson = 0.6375176949647936\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_spearmanr = 0.6375176949647916\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_corr = 0.6375176949647926\n",
    "[INFO|trainer.py:393] 01/19/2021 02:13:32 >>   eval_class_report = {'accuracy': 0.8081900081900082,\n",
    " 'macro avg': {'f1-score': 0.8062812737196172,\n",
    "               'precision': 0.8268004529066476,\n",
    "               'recall': 0.8109151224993252,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8255103561317241,\n",
    "              'precision': 0.7428264950388844,\n",
    "              'recall': 0.9289067739771966,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.7870521913075105,\n",
    "          'precision': 0.9107744107744108,\n",
    "          'recall': 0.6929234710214537,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.8058371622339322,\n",
    "                  'precision': 0.8287399005822175,\n",
    "                  'recall': 0.8081900081900082,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 02:35:28 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_loss = 1.5795278549194336\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_acc = 0.6072420422986541\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_f1 = 0.5826807399841107\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_acc_and_f1 = 0.5949613911413825\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_pearson = 0.2678899209326689\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_spearmanr = 0.26788992093266895\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_corr = 0.26788992093266895\n",
    "[INFO|trainer.py:393] 01/19/2021 02:35:28 >>   eval_class_report = {'accuracy': 0.6072420422986541,\n",
    " 'macro avg': {'f1-score': 0.6058768372572627,\n",
    "               'precision': 0.6374655870568817,\n",
    "               'recall': 0.6305145005266227,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6290729345304146,\n",
    "              'precision': 0.5250042094628725,\n",
    "              'recall': 0.7845998993457474,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.5826807399841107,\n",
    "          'precision': 0.749926964650891,\n",
    "          'recall': 0.47642910170749814,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.6023733891111147,\n",
    "                  'precision': 0.6544513153113071,\n",
    "                  'recall': 0.6072420422986541,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-uncased-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 03:30:52 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_loss = 0.2642388343811035\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_acc = 0.8627354627354628\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_f1 = 0.8640934155043789\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_acc_and_f1 = 0.8634144391199208\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_pearson = 0.7257399049598463\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_spearmanr = 0.7257399049598477\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_corr = 0.725739904959847\n",
    "[INFO|trainer.py:393] 01/21/2021 03:30:52 >>   eval_class_report = {'accuracy': 0.8627354627354628,\n",
    " 'macro avg': {'f1-score': 0.862721757388192,\n",
    "               'precision': 0.8627749159499815,\n",
    "               'recall': 0.862965013906687,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8613500992720052,\n",
    "              'precision': 0.8500979751796212,\n",
    "              'recall': 0.8729040912139504,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.8640934155043789,\n",
    "          'precision': 0.8754518567203418,\n",
    "          'recall': 0.8530259365994236,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.8627534369613914,\n",
    "                  'precision': 0.8630677003314099,\n",
    "                  'recall': 0.8627354627354628,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 04:17:16 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_loss = 1.6137083768844604\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_acc = 0.6477248451185644\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_f1 = 0.6594382486575795\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_acc_and_f1 = 0.6535815468880719\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_pearson = 0.31250361219510653\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_spearmanr = 0.31250361219510636\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_corr = 0.3125036121951065\n",
    "[INFO|trainer.py:393] 01/21/2021 04:17:16 >>   eval_class_report = {'accuracy': 0.6477248451185644,\n",
    " 'macro avg': {'f1-score': 0.647307619904011,\n",
    "               'precision': 0.6549844198111925,\n",
    "               'recall': 0.6575295564450292,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6351769911504425,\n",
    "              'precision': 0.5667193051717331,\n",
    "              'recall': 0.7224458983392048,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.6594382486575795,\n",
    "          'precision': 0.7432495344506518,\n",
    "          'recall': 0.5926132145508537,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.649139782802702,\n",
    "                  'precision': 0.6683156387922002,\n",
    "                  'recall': 0.6477248451185644,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-uncased-within_128_32-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 00:07:45 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_loss = 0.33837682008743286\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_acc = 0.778164116828929\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_f1 = 0.7456140350877194\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_acc_and_f1 = 0.7618890759583242\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_pearson = 0.6111901136301958\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_spearmanr = 0.6111901136301963\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_corr = 0.611190113630196\n",
    "[INFO|trainer.py:393] 01/19/2021 00:07:45 >>   eval_class_report = {'accuracy': 0.778164116828929,\n",
    " 'macro avg': {'f1-score': 0.7744716291344885,\n",
    "               'precision': 0.8220459397841162,\n",
    "               'recall': 0.7899845246067252,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8033292231812577,\n",
    "              'precision': 0.6856090502499342,\n",
    "              'recall': 0.9698548567175288,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.7456140350877194,\n",
    "          'precision': 0.9584828293182983,\n",
    "          'recall': 0.6101141924959217,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.7725752156175066,\n",
    "                  'precision': 0.8310120636095545,\n",
    "                  'recall': 0.778164116828929,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 00:11:26 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_loss = 0.3452797830104828\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_acc = 0.775934908465029\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_f1 = 0.7422606191504679\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_acc_and_f1 = 0.7590977638077485\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_pearson = 0.6054086100340773\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_spearmanr = 0.6054086100340781\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_corr = 0.6054086100340776\n",
    "[INFO|trainer.py:393] 01/19/2021 00:11:26 >>   eval_class_report = {'accuracy': 0.775934908465029,\n",
    " 'macro avg': {'f1-score': 0.772043677967152,\n",
    "               'precision': 0.8192497696050065,\n",
    "               'recall': 0.7870163270257586,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8018267367838361,\n",
    "              'precision': 0.6851939451277199,\n",
    "              'recall': 0.966310873915944,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.7422606191504679,\n",
    "          'precision': 0.9533055940822931,\n",
    "          'recall': 0.6077217801355732,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.7702029162346233,\n",
    "                  'precision': 0.8275351788787552,\n",
    "                  'recall': 0.775934908465029,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-uncased-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 04:46:59 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_loss = 0.26056620478630066\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_acc = 0.8536161335187761\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_f1 = 0.8597134288570477\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_acc_and_f1 = 0.8566647811879119\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_pearson = 0.7075266689157588\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_spearmanr = 0.7075266689157627\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_corr = 0.7075266689157607\n",
    "[INFO|trainer.py:393] 01/19/2021 04:46:59 >>   eval_class_report = {'accuracy': 0.8536161335187761,\n",
    " 'macro avg': {'f1-score': 0.8533390844757794,\n",
    "               'precision': 0.853078049338053,\n",
    "               'recall': 0.8544499496397069,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8469647400945112,\n",
    "              'precision': 0.827708703374778,\n",
    "              'recall': 0.867138072199479,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.8597134288570477,\n",
    "          'precision': 0.8784473953013279,\n",
    "          'recall': 0.8417618270799347,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8537579826287904,\n",
    "                  'precision': 0.8547452281930805,\n",
    "                  'recall': 0.8536161335187761,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 04:54:23 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_loss = 0.26278257369995117\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_acc = 0.8544828665310593\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_f1 = 0.8601503759398498\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_acc_and_f1 = 0.8573166212354546\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_pearson = 0.7092633176605115\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_spearmanr = 0.7092633176605115\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_corr = 0.7092633176605115\n",
    "[INFO|trainer.py:393] 01/19/2021 04:54:23 >>   eval_class_report = {'accuracy': 0.8544828665310593,\n",
    " 'macro avg': {'f1-score': 0.8542434854258936,\n",
    "               'precision': 0.8540192455736689,\n",
    "               'recall': 0.8552451314925148,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8483365949119374,\n",
    "              'precision': 0.8299298021697511,\n",
    "              'recall': 0.8675783855903936,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8601503759398498,\n",
    "          'precision': 0.8781086889775868,\n",
    "          'recall': 0.842911877394636,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8546085647175558,\n",
    "                  'precision': 0.855508109623825,\n",
    "                  'recall': 0.8544828665310593,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-uncased-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 23:54:49 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_loss = 0.2525853216648102\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_acc = 0.8593532684283728\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_f1 = 0.8599619179504934\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_acc_and_f1 = 0.859657593189433\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_pearson = 0.7251990176989778\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_spearmanr = 0.7251990176989779\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_corr = 0.7251990176989778\n",
    "[INFO|trainer.py:393] 01/20/2021 23:54:49 >>   eval_class_report = {'accuracy': 0.8593532684283728,\n",
    " 'macro avg': {'f1-score': 0.8593506114983828,\n",
    "               'precision': 0.8624053912435957,\n",
    "               'recall': 0.8627937304318842,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8587393050462722,\n",
    "              'precision': 0.8088815789473685,\n",
    "              'recall': 0.9151470040937849,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.8599619179504934,\n",
    "          'precision': 0.915929203539823,\n",
    "          'recall': 0.8104404567699837,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8593907842798324,\n",
    "                  'precision': 0.8659227766830905,\n",
    "                  'recall': 0.8593532684283728,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 00:09:12 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_loss = 0.251834511756897\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_acc = 0.8626193084024409\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_f1 = 0.8627696155048452\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_acc_and_f1 = 0.8626944619536431\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_pearson = 0.7316206211850123\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_spearmanr = 0.731620621185013\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_corr = 0.7316206211850127\n",
    "[INFO|trainer.py:393] 01/21/2021 00:09:12 >>   eval_class_report = {'accuracy': 0.8626193084024409,\n",
    " 'macro avg': {'f1-score': 0.8626191435920216,\n",
    "               'precision': 0.8657614843541921,\n",
    "               'recall': 0.8658591433487342,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.862468671679198,\n",
    "              'precision': 0.8130537507383343,\n",
    "              'recall': 0.9182788525683789,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8627696155048452,\n",
    "          'precision': 0.9184692179700499,\n",
    "          'recall': 0.8134394341290893,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8626284436085395,\n",
    "                  'precision': 0.8690191208396034,\n",
    "                  'recall': 0.8626193084024409,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert-base-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-cased-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/22/2021 01:41:40 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_loss = 0.27282389998435974\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_acc = 0.8656838656838657\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_f1 = 0.8624622609862461\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_acc_and_f1 = 0.864073063335056\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_pearson = 0.7349786393471499\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_spearmanr = 0.7349786393471499\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_corr = 0.7349786393471499\n",
    "[INFO|trainer.py:393] 01/22/2021 01:41:40 >>   eval_class_report = {'accuracy': 0.8656838656838657,\n",
    " 'macro avg': {'f1-score': 0.8656101317735327,\n",
    "               'precision': 0.8682932395358414,\n",
    "               'recall': 0.8666871546280566,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8687580025608195,\n",
    "              'precision': 0.8309859154929577,\n",
    "              'recall': 0.9101274312541918,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.8624622609862461,\n",
    "          'precision': 0.9056005635787249,\n",
    "          'recall': 0.8232468780019212,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.8655374291067011,\n",
    "                  'precision': 0.8691548828921143,\n",
    "                  'recall': 0.8656838656838657,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/22/2021 02:03:23 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_loss = 1.2834948301315308\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_acc = 0.6323435163426618\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_f1 = 0.6516194331983807\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_acc_and_f1 = 0.6419814747705213\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_pearson = 0.2741512500312657\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_spearmanr = 0.2741512500312656\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_corr = 0.27415125003126567\n",
    "[INFO|trainer.py:393] 01/22/2021 02:03:23 >>   eval_class_report = {'accuracy': 0.6323435163426618,\n",
    " 'macro avg': {'f1-score': 0.6312145108099547,\n",
    "               'precision': 0.6356137125366383,\n",
    "               'recall': 0.6385532968751226,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6108095884215288,\n",
    "              'precision': 0.5546201232032855,\n",
    "              'recall': 0.6796678409662809,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.6516194331983807,\n",
    "          'precision': 0.7166073018699911,\n",
    "          'recall': 0.5974387527839644,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.6342963907776149,\n",
    "                  'precision': 0.6478466686696612,\n",
    "                  'recall': 0.6323435163426618,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-cased-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/23/2021 02:20:38 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_loss = 0.2603161633014679\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_acc = 0.8768222768222769\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_f1 = 0.8754966887417218\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_acc_and_f1 = 0.8761594827819994\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_pearson = 0.7556159530056163\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_spearmanr = 0.7556159530056179\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_corr = 0.7556159530056171\n",
    "[INFO|trainer.py:393] 01/23/2021 02:20:38 >>   eval_class_report = {'accuracy': 0.8768222768222769,\n",
    " 'macro avg': {'f1-score': 0.8768083119559501,\n",
    "               'precision': 0.8780798774458041,\n",
    "               'recall': 0.8775362711008285,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8781199351701784,\n",
    "              'precision': 0.8497490589711418,\n",
    "              'recall': 0.9084507042253521,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.8754966887417218,\n",
    "          'precision': 0.9064106959204662,\n",
    "          'recall': 0.8466218379763049,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.876778018938226,\n",
    "                  'precision': 0.8787342010174546,\n",
    "                  'recall': 0.8768222768222769,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/23/2021 03:04:12 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_loss = 1.5683422088623047\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_acc = 0.6353877376628926\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_f1 = 0.6563648260935219\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_acc_and_f1 = 0.6458762818782072\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_pearson = 0.27845722859784605\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_spearmanr = 0.27845722859784605\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_corr = 0.27845722859784605\n",
    "[INFO|trainer.py:393] 01/23/2021 03:04:12 >>   eval_class_report = {'accuracy': 0.6353877376628926,\n",
    " 'macro avg': {'f1-score': 0.6340239465203972,\n",
    "               'precision': 0.6376891162054849,\n",
    "               'recall': 0.6407853254767719,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6116830669472726,\n",
    "              'precision': 0.5581854043392505,\n",
    "              'recall': 0.6765223955712129,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.6563648260935219,\n",
    "          'precision': 0.7171928280717192,\n",
    "          'recall': 0.6050482553823311,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.6373982259175771,\n",
    "                  'precision': 0.6496970470513358,\n",
    "                  'recall': 0.6353877376628926,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-cased-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 20:54:22 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_loss = 0.2576597034931183\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_acc = 0.866481223922114\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_f1 = 0.872127872127872\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_acc_and_f1 = 0.869304548024993\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_pearson = 0.733249123703038\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_spearmanr = 0.7332491237030369\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_corr = 0.7332491237030374\n",
    "[INFO|trainer.py:393] 01/20/2021 20:54:22 >>   eval_class_report = {'accuracy': 0.866481223922114,\n",
    " 'macro avg': {'f1-score': 0.8662203565804875,\n",
    "               'precision': 0.8659255165413091,\n",
    "               'recall': 0.8673249425819805,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8603128410331029,\n",
    "              'precision': 0.8413376022767698,\n",
    "              'recall': 0.8801637513956085,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.872127872127872,\n",
    "          'precision': 0.8905134308058483,\n",
    "          'recall': 0.8544861337683524,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.866608576482593,\n",
    "                  'precision': 0.8675413426178036,\n",
    "                  'recall': 0.866481223922114,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 21:01:52 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_loss = 0.25777843594551086\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_acc = 0.8646534188702863\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_f1 = 0.8701396186758745\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_acc_and_f1 = 0.8673965187730804\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_pearson = 0.7294866296572445\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_spearmanr = 0.7294866296572462\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_corr = 0.7294866296572453\n",
    "[INFO|trainer.py:393] 01/20/2021 21:01:52 >>   eval_class_report = {'accuracy': 0.8646534188702863,\n",
    " 'macro avg': {'f1-score': 0.8644114201858379,\n",
    "               'precision': 0.8641397324152819,\n",
    "               'recall': 0.865347897714303,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8586832216958014,\n",
    "              'precision': 0.8414985590778098,\n",
    "              'recall': 0.8765843895930621,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8701396186758745,\n",
    "          'precision': 0.8867809057527539,\n",
    "          'recall': 0.8541114058355438,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8647654552982718,\n",
    "                  'precision': 0.865539085172018,\n",
    "                  'recall': 0.8646534188702863,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-cased-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/22/2021 22:43:58 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_loss = 0.2563546299934387\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_acc = 0.8708275382475661\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_f1 = 0.875939221906829\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_acc_and_f1 = 0.8733833800771975\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_pearson = 0.7422659648093448\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_spearmanr = 0.7422659648093463\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_corr = 0.7422659648093455\n",
    "[INFO|trainer.py:393] 01/22/2021 22:43:58 >>   eval_class_report = {'accuracy': 0.8708275382475661,\n",
    " 'macro avg': {'f1-score': 0.8706078702462522,\n",
    "               'precision': 0.8703823113403777,\n",
    "               'recall': 0.8718851748889432,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8652765185856753,\n",
    "              'precision': 0.8437057991513437,\n",
    "              'recall': 0.8879791589132862,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.875939221906829,\n",
    "          'precision': 0.8970588235294118,\n",
    "          'recall': 0.8557911908646003,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8709582268053097,\n",
    "                  'precision': 0.8721353922874318,\n",
    "                  'recall': 0.8708275382475661,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/22/2021 22:58:58 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_loss = 0.25487756729125977\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_acc = 0.8731028008136442\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_f1 = 0.8762021065486185\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_acc_and_f1 = 0.8746524536811313\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_pearson = 0.7484131586973857\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_spearmanr = 0.7484131586973878\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_corr = 0.7484131586973868\n",
    "[INFO|trainer.py:393] 01/22/2021 22:58:58 >>   eval_class_report = {'accuracy': 0.8731028008136442,\n",
    " 'macro avg': {'f1-score': 0.8730232166509743,\n",
    "               'precision': 0.873516892668172,\n",
    "               'recall': 0.8748975395130303,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.86984432675333,\n",
    "              'precision': 0.838230745437674,\n",
    "              'recall': 0.9039359573048699,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8762021065486185,\n",
    "          'precision': 0.9088030398986701,\n",
    "          'recall': 0.8458591217211907,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8732196900525655,\n",
    "                  'precision': 0.875697776435352,\n",
    "                  'recall': 0.8731028008136442,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roberta-base-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 15:16:14 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_loss = 0.38359323143959045\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_acc = 0.7682545201668984\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_f1 = 0.7274585974238397\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_acc_and_f1 = 0.747856558795369\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_pearson = 0.6033646670547663\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_spearmanr = 0.6033646670547667\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_corr = 0.6033646670547665\n",
    "[INFO|trainer.py:393] 01/20/2021 15:16:14 >>   eval_class_report = {'accuracy': 0.7682545201668984,\n",
    " 'macro avg': {'f1-score': 0.7629429687557728,\n",
    "               'precision': 0.8233504108593872,\n",
    "               'recall': 0.7814662586035962,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.798427340087706,\n",
    "              'precision': 0.6724401426388181,\n",
    "              'recall': 0.9825083736509118,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.7274585974238397,\n",
    "          'precision': 0.9742606790799562,\n",
    "          'recall': 0.5804241435562806,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.7606110681362542,\n",
    "                  'precision': 0.8332676711840352,\n",
    "                  'recall': 0.7682545201668984,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 15:23:35 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_loss = 0.39903610944747925\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_acc = 0.7618526052260992\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_f1 = 0.7184609692933777\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_acc_and_f1 = 0.7401567872597384\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_pearson = 0.589469157969766\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_spearmanr = 0.5894691579697647\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_corr = 0.5894691579697653\n",
    "[INFO|trainer.py:393] 01/20/2021 15:23:35 >>   eval_class_report = {'accuracy': 0.7618526052260992,\n",
    " 'macro avg': {'f1-score': 0.7560580334536302,\n",
    "               'precision': 0.8166496915776098,\n",
    "               'recall': 0.7743361966234685,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.7936550976138828,\n",
    "              'precision': 0.6685701233439927,\n",
    "              'recall': 0.97631754503002,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.7184609692933777,\n",
    "          'precision': 0.964729259811227,\n",
    "          'recall': 0.5723548482169172,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.7537343219306605,\n",
    "                  'precision': 0.8258018476490038,\n",
    "                  'recall': 0.7618526052260992,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roberta-base-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 16:38:05 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_loss = 0.32770270109176636\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_acc = 0.8006552006552007\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_f1 = 0.7618861279593034\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_acc_and_f1 = 0.781270664307252\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_pearson = 0.6503544939562766\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_spearmanr = 0.650354493956278\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_corr = 0.6503544939562773\n",
    "[INFO|trainer.py:393] 01/20/2021 16:38:05 >>   eval_class_report = {'accuracy': 0.8006552006552007,\n",
    " 'macro avg': {'f1-score': 0.7952267659095009,\n",
    "               'precision': 0.8468656852457959,\n",
    "               'recall': 0.8048449196620646,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8285674038596985,\n",
    "              'precision': 0.7143551129463201,\n",
    "              'recall': 0.9862508383635145,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.7618861279593034,\n",
    "          'precision': 0.9793762575452716,\n",
    "          'recall': 0.6234390009606148,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.7944567364335012,\n",
    "                  'precision': 0.8499261259819508,\n",
    "                  'recall': 0.8006552006552007,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 17:00:03 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_loss = 1.6704630851745605\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_acc = 0.6030762657551805\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_f1 = 0.5459433040078201\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_acc_and_f1 = 0.5745097848815003\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_pearson = 0.2950521101308142\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_spearmanr = 0.2950521101308145\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_corr = 0.29505211013081434\n",
    "[INFO|trainer.py:393] 01/20/2021 17:00:03 >>   eval_class_report = {'accuracy': 0.6030762657551805,\n",
    " 'macro avg': {'f1-score': 0.596690817089299,\n",
    "               'precision': 0.6593226170104196,\n",
    "               'recall': 0.6366029339182787,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.647438330170778,\n",
    "              'precision': 0.5196466646360036,\n",
    "              'recall': 0.8585807750377453,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.5459433040078201,\n",
    "          'precision': 0.7989985693848355,\n",
    "          'recall': 0.41462509279881216,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.5890261104563989,\n",
    "                  'precision': 0.6804187285952757,\n",
    "                  'recall': 0.6030762657551805,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roberta-base-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.2914811968803406\n",
    "eval_acc = 0.8198887343532685\n",
    "eval_f1 = 0.7978930940304332\n",
    "eval_acc_and_f1 = 0.8088909141918508\n",
    "eval_pearson = 0.6880303207746608\n",
    "eval_spearmanr = 0.6880303207746609\n",
    "eval_corr = 0.6880303207746608\n",
    "eval_class_report = {'not same': {'precision': 0.7236521267949065, 'recall': 0.9940454037960551, 'f1-score': 0.8375666353088743, 'support': 2687}, 'same': {'precision': 0.9922367782629792, 'recall': 0.66721044045677, 'f1-score': 0.7978930940304332, 'support': 3065}, 'accuracy': 0.8198887343532685, 'macro avg': {'precision': 0.8579444525289428, 'recall': 0.8306279221264126, 'f1-score': 0.8177298646696538, 'support': 5752}, 'weighted avg': {'precision': 0.8667696436150809, 'recall': 0.8198887343532685, 'f1-score': 0.8164262660428064, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.2918856739997864\n",
    "eval_acc = 0.8220935690815209\n",
    "eval_f1 = 0.79985917972188\n",
    "eval_acc_and_f1 = 0.8109763744017005\n",
    "eval_pearson = 0.6914777402908828\n",
    "eval_spearmanr = 0.6914777402908818\n",
    "eval_corr = 0.6914777402908823\n",
    "eval_class_report = {'not same': {'precision': 0.7267852790640994, 'recall': 0.9946631087391594, 'f1-score': 0.8398817068018588, 'support': 2998}, 'same': {'precision': 0.993006993006993, 'recall': 0.6696139109932213, 'f1-score': 0.79985917972188, 'support': 3393}, 'accuracy': 0.8220935690815209, 'macro avg': {'precision': 0.8598961360355462, 'recall': 0.8321385098661904, 'f1-score': 0.8198704432618694, 'support': 6391}, 'weighted avg': {'precision': 0.8681231409649347, 'recall': 0.8220935690815209, 'f1-score': 0.8186336338269931, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roberta-base-cross_512_8-acc64_380966\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.3148132264614105\n",
    "eval_acc = 0.8096642096642097\n",
    "eval_f1 = 0.7786666666666666\n",
    "eval_acc_and_f1 = 0.7941654381654382\n",
    "eval_pearson = 0.6574447516717615\n",
    "eval_spearmanr = 0.6574447516717651\n",
    "eval_corr = 0.6574447516717633\n",
    "eval_class_report = {'not same': {'precision': 0.7287581699346405, 'recall': 0.9721663313212608, 'f1-score': 0.8330459770114942, 'support': 2982}, 'same': {'precision': 0.9609779031499764, 'recall': 0.654498879282741, 'f1-score': 0.7786666666666666, 'support': 3123}, 'accuracy': 0.8096642096642097, 'macro avg': {'precision': 0.8448680365423085, 'recall': 0.8133326053020009, 'f1-score': 0.8058563218390804, 'support': 6105}, 'weighted avg': {'precision': 0.8475496894811588, 'recall': 0.8096642096642097, 'f1-score': 0.805228354373182, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 1.621971845626831\n",
    "eval_acc = 0.6154667806024354\n",
    "eval_f1 = 0.5538480604783741\n",
    "eval_acc_and_f1 = 0.5846574205404047\n",
    "eval_pearson = 0.3305876516786534\n",
    "eval_spearmanr = 0.3305876516786539\n",
    "eval_corr = 0.33058765167865367\n",
    "eval_class_report = {'not same': {'precision': 0.5279898218829516, 'recall': 0.8876446904881731, 'f1-score': 0.662130455185359, 'support': 7948}, 'same': {'precision': 0.8334576650503543, 'recall': 0.4147178916109874, 'f1-score': 0.5538480604783741, 'support': 10776}, 'accuracy': 0.6154667806024354, 'macro avg': {'precision': 0.680723743466653, 'recall': 0.6511812910495802, 'f1-score': 0.6079892578318665, 'support': 18724}, 'weighted avg': {'precision': 0.7037920798391539, 'recall': 0.6154667806024354, 'f1-score': 0.5998119823503627, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## albert-base-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v2-within_128_32-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.35398009419441223\n",
    "eval_acc = 0.8122392211404729\n",
    "eval_f1 = 0.8086463501063076\n",
    "eval_acc_and_f1 = 0.8104427856233902\n",
    "eval_pearson = 0.6360329237743425\n",
    "eval_spearmanr = 0.6360329237743446\n",
    "eval_corr = 0.6360329237743436\n",
    "eval_class_report = {'not same': {'precision': 0.753230381342578, 'recall': 0.8894678079642724, 'f1-score': 0.8156996587030717, 'support': 2687}, 'same': {'precision': 0.8848390849166343, 'recall': 0.7445350734094617, 'f1-score': 0.8086463501063076, 'support': 3065}, 'accuracy': 0.8122392211404729, 'macro avg': {'precision': 0.8190347331296062, 'recall': 0.8170014406868671, 'f1-score': 0.8121730044046896, 'support': 5752}, 'weighted avg': {'precision': 0.8233591498499637, 'recall': 0.8122392211404729, 'f1-score': 0.8119412458294482, 'support': 5752}}\n",
    "epoch = 2.988875154511743\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.3576366901397705\n",
    "eval_acc = 0.807854795806603\n",
    "eval_f1 = 0.8037711728986896\n",
    "eval_acc_and_f1 = 0.8058129843526463\n",
    "eval_pearson = 0.626654255455429\n",
    "eval_spearmanr = 0.6266542554554264\n",
    "eval_corr = 0.6266542554554277\n",
    "eval_class_report = {'not same': {'precision': 0.7509926262053318, 'recall': 0.8832555036691128, 'f1-score': 0.8117719190680565, 'support': 2998}, 'same': {'precision': 0.8778359511343804, 'recall': 0.7412319481284999, 'f1-score': 0.8037711728986896, 'support': 3393}, 'accuracy': 0.807854795806603, 'macro avg': {'precision': 0.8144142886698561, 'recall': 0.8122437258988063, 'f1-score': 0.807771545983373, 'support': 6391}, 'weighted avg': {'precision': 0.8183341066441148, 'recall': 0.807854795806603, 'f1-score': 0.807524300267765, 'support': 6391}}\n",
    "epoch = 2.988875154511743\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v2-cross_128_32-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.35145360231399536\n",
    "eval_acc = 0.8008190008190008\n",
    "eval_f1 = 0.7762237762237764\n",
    "eval_acc_and_f1 = 0.7885213885213886\n",
    "eval_pearson = 0.6261656400471884\n",
    "eval_spearmanr = 0.626165640047192\n",
    "eval_corr = 0.6261656400471902\n",
    "eval_class_report = {'not same': {'precision': 0.7327358987875593, 'recall': 0.932260228034876, 'f1-score': 0.820543093270366, 'support': 2982}, 'same': {'precision': 0.9125919515361316, 'recall': 0.675312199807877, 'f1-score': 0.7762237762237764, 'support': 3123}, 'accuracy': 0.8008190008190008, 'macro avg': {'precision': 0.8226639251618455, 'recall': 0.8037862139213765, 'f1-score': 0.7983834347470712, 'support': 6105}, 'weighted avg': {'precision': 0.8247408869503424, 'recall': 0.8008190008190008, 'f1-score': 0.7978716391939533, 'support': 6105}}\n",
    "epoch = 2.969132207338381\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.8830269575119019\n",
    "eval_acc = 0.5925016022217475\n",
    "eval_f1 = 0.58649468892261\n",
    "eval_acc_and_f1 = 0.5894981455721788\n",
    "eval_pearson = 0.21823393212604086\n",
    "eval_spearmanr = 0.21823393212604084\n",
    "eval_corr = 0.21823393212604086\n",
    "eval_class_report = {'not same': {'precision': 0.5143917451122375, 'recall': 0.7150226472068445, 'f1-score': 0.5983364918930302, 'support': 7948}, 'same': {'precision': 0.7049244398124023, 'recall': 0.5021343726800297, 'f1-score': 0.58649468892261, 'support': 10776}, 'accuracy': 0.5925016022217475, 'macro avg': {'precision': 0.6096580924623198, 'recall': 0.6085785099434371, 'f1-score': 0.5924155904078201, 'support': 18724}, 'weighted avg': {'precision': 0.6240467503509138, 'recall': 0.5925016022217475, 'f1-score': 0.5915213205188982, 'support': 18724}}\n",
    "epoch = 2.969132207338381\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v2-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "INFO|trainer.py:389] 01/19/2021 15:29:05 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_loss = 0.28017380833625793\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_acc = 0.8461404728789986\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_f1 = 0.8549893495002459\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_acc_and_f1 = 0.8505649111896223\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_pearson = 0.6911683212271397\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_spearmanr = 0.6911683212271403\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_corr = 0.69116832122714\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   eval_class_report = {'accuracy': 0.8461404728789986,\n",
    " 'macro avg': {'f1-score': 0.845565402393152,\n",
    "               'precision': 0.8453854953444044,\n",
    "               'recall': 0.8457829401547297,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8361414552860582,\n",
    "              'precision': 0.8319823139277819,\n",
    "              'recall': 0.8403423892817269,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.8549893495002459,\n",
    "          'precision': 0.858788676761027,\n",
    "          'recall': 0.8512234910277324,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8461847090702177,\n",
    "                  'precision': 0.8462663024680978,\n",
    "                  'recall': 0.8461404728789986,\n",
    "                  'support': 5752}}\n",
    "[INFO|trainer.py:393] 01/19/2021 15:29:05 >>   epoch = 2.989180834621329\n",
    "```\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 10:16:12 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_loss = 0.28366678953170776\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_acc = 0.8444019471488178\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_f1 = 0.8491488285858757\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_acc_and_f1 = 0.8467753878673467\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_pearson = 0.6904819396344508\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_spearmanr = 0.6904819396344521\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_corr = 0.6904819396344515\n",
    "[INFO|trainer.py:393] 01/20/2021 10:16:12 >>   eval_class_report = {'accuracy': 0.8444019471488178,\n",
    " 'macro avg': {'f1-score': 0.844247722496133,\n",
    "               'precision': 0.8444960122408633,\n",
    "               'recall': 0.8459875383318024,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8393466164063903,\n",
    "              'precision': 0.8106796116504854,\n",
    "              'recall': 0.8701153703014515,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.8491488285858757,\n",
    "          'precision': 0.8783124128312413,\n",
    "          'recall': 0.8218597063621533,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8445698049199721,\n",
    "                  'precision': 0.8467183000404396,\n",
    "                  'recall': 0.8444019471488178,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 15:36:29 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_loss = 0.2766660749912262\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_acc = 0.8480675950555469\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_f1 = 0.8557420888426683\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_acc_and_f1 = 0.8519048419491075\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_pearson = 0.6953989569255735\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_spearmanr = 0.6953989569255765\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_corr = 0.695398956925575\n",
    "[INFO|trainer.py:393] 01/19/2021 15:36:29 >>   eval_class_report = {'accuracy': 0.8480675950555469,\n",
    " 'macro avg': {'f1-score': 0.8476363724662854,\n",
    "               'precision': 0.84738032329583,\n",
    "               'recall': 0.8480189268530922,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8395306560899025,\n",
    "              'precision': 0.8319685555191615,\n",
    "              'recall': 0.8472314876584389,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8557420888426683,\n",
    "          'precision': 0.8627920910724985,\n",
    "          'recall': 0.8488063660477454,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8481373516508688,\n",
    "                  'precision': 0.8483328578399991,\n",
    "                  'recall': 0.8480675950555469,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 10:23:41 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_loss = 0.2772209048271179\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_acc = 0.8432170239399155\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_f1 = 0.847162904209884\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_acc_and_f1 = 0.8451899640748998\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_pearson = 0.6884142920625937\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_spearmanr = 0.688414292062597\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_corr = 0.6884142920625953\n",
    "[INFO|trainer.py:393] 01/20/2021 10:23:41 >>   eval_class_report = {'accuracy': 0.8432170239399155,\n",
    " 'macro avg': {'f1-score': 0.8431124511412413,\n",
    "               'precision': 0.8435668614137835,\n",
    "               'recall': 0.8448486239082269,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8390619980725987,\n",
    "              'precision': 0.8091697645600991,\n",
    "              'recall': 0.8712474983322215,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.847162904209884,\n",
    "          'precision': 0.8779639582674676,\n",
    "          'recall': 0.8184497494842322,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8433627920835217,\n",
    "                  'precision': 0.8456927968319035,\n",
    "                  'recall': 0.8432170239399155,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v2-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 08:33:43 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_loss = 0.22960491478443146\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_acc = 0.8840403337969402\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_f1 = 0.8899521531100478\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_acc_and_f1 = 0.886996243453494\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_pearson = 0.767665182077424\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_spearmanr = 0.7676651820774242\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_corr = 0.7676651820774241\n",
    "[INFO|trainer.py:393] 01/20/2021 08:33:43 >>   eval_class_report = {'accuracy': 0.8840403337969402,\n",
    " 'macro avg': {'f1-score': 0.883704718847877,\n",
    "               'precision': 0.8833367082573571,\n",
    "               'recall': 0.8843291152919834,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8774572845857064,\n",
    "              'precision': 0.8664731494920174,\n",
    "              'recall': 0.8887234834387793,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.8899521531100478,\n",
    "          'precision': 0.900200267022697,\n",
    "          'recall': 0.8799347471451876,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8841152769409056,\n",
    "                  'precision': 0.8844449184822004,\n",
    "                  'recall': 0.8840403337969402,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 08:48:43 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_loss = 0.22570578753948212\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_acc = 0.8881239242685026\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_f1 = 0.8930441286462228\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_acc_and_f1 = 0.8905840264573628\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_pearson = 0.7762187149105191\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_spearmanr = 0.7762187149105186\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_corr = 0.7762187149105189\n",
    "[INFO|trainer.py:393] 01/20/2021 08:48:43 >>   eval_class_report = {'accuracy': 0.8881239242685026,\n",
    " 'macro avg': {'f1-score': 0.8878866698668214,\n",
    "               'precision': 0.8875441240991391,\n",
    "               'recall': 0.8886754152045956,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.88272921108742,\n",
    "              'precision': 0.8683446272991288,\n",
    "              'recall': 0.8975983989326217,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8930441286462228,\n",
    "          'precision': 0.9067436208991495,\n",
    "          'recall': 0.8797524314765695,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8882054300323453,\n",
    "                  'precision': 0.8887307617514634,\n",
    "                  'recall': 0.8881239242685026,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v2-cross_256_12-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 19:10:24 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_loss = 0.2749919295310974\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_acc = 0.8496314496314497\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_f1 = 0.8517920568291896\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_acc_and_f1 = 0.8507117532303197\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_pearson = 0.6993223047520287\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_spearmanr = 0.6993223047520276\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_corr = 0.6993223047520282\n",
    "[INFO|trainer.py:393] 01/19/2021 19:10:24 >>   eval_class_report = {'accuracy': 0.8496314496314497,\n",
    " 'macro avg': {'f1-score': 0.8495994858614033,\n",
    "               'precision': 0.8495743024835003,\n",
    "               'recall': 0.8497480238459254,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8474069148936171,\n",
    "              'precision': 0.8401450230718523,\n",
    "              'recall': 0.8547954393024816,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.8517920568291896,\n",
    "          'precision': 0.8590035818951481,\n",
    "          'recall': 0.8447006083893692,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.8496501250926003,\n",
    "                  'precision': 0.8497920794527127,\n",
    "                  'recall': 0.8496314496314497,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 19:45:18 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_loss = 1.2454228401184082\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_acc = 0.6454817346720786\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_f1 = 0.672876010250345\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_acc_and_f1 = 0.6591788724612118\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_pearson = 0.2918662590839507\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_spearmanr = 0.2918662590839506\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_corr = 0.29186625908395064\n",
    "[INFO|trainer.py:393] 01/19/2021 19:45:18 >>   eval_class_report = {'accuracy': 0.6454817346720786,\n",
    " 'macro avg': {'f1-score': 0.6429779911358976,\n",
    "               'precision': 0.6442785418969706,\n",
    "               'recall': 0.6476066920133055,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6130799720214501,\n",
    "              'precision': 0.571133796698523,\n",
    "              'recall': 0.6616758933064922,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.672876010250345,\n",
    "          'precision': 0.7174232870954182,\n",
    "          'recall': 0.6335374907201188,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.6474936714422241,\n",
    "                  'precision': 0.6553260391956894,\n",
    "                  'recall': 0.6454817346720786,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v2-cross_512_8-acc64_3\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 04:13:35 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_loss = 0.24087363481521606\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_acc = 0.8825552825552826\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_f1 = 0.8840743734842361\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_acc_and_f1 = 0.8833148280197594\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_pearson = 0.7652465162460181\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_spearmanr = 0.7652465162460199\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_corr = 0.765246516246019\n",
    "[INFO|trainer.py:393] 01/20/2021 04:13:35 >>   eval_class_report = {'accuracy': 0.8825552825552826,\n",
    " 'macro avg': {'f1-score': 0.8825351120533214,\n",
    "               'precision': 0.8825230481539046,\n",
    "               'recall': 0.8827234943442274,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8809958506224066,\n",
    "              'precision': 0.8721656260269471,\n",
    "              'recall': 0.8900067069081153,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.8840743734842361,\n",
    "          'precision': 0.8928804702808621,\n",
    "          'recall': 0.8754402817803394,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.882570662563028,\n",
    "                  'precision': 0.8827622613430777,\n",
    "                  'recall': 0.8825552825552826,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 04:57:43 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_loss = 1.2090873718261719\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_acc = 0.6618778038880581\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_f1 = 0.6895198862243146\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_acc_and_f1 = 0.6756988450561863\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_pearson = 0.32350191454713284\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_spearmanr = 0.32350191454713273\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_corr = 0.3235019145471328\n",
    "[INFO|trainer.py:393] 01/20/2021 04:57:43 >>   eval_class_report = {'accuracy': 0.6618778038880581,\n",
    " 'macro avg': {'f1-score': 0.6591763117584608,\n",
    "               'precision': 0.6599538084059315,\n",
    "               'recall': 0.66356829787083,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6288327372926071,\n",
    "              'precision': 0.5887583708420244,\n",
    "              'recall': 0.6747609461499748,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.6895198862243146,\n",
    "          'precision': 0.7311492459698388,\n",
    "          'recall': 0.6523756495916853,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.6637592870089113,\n",
    "                  'precision': 0.6707068898752079,\n",
    "                  'recall': 0.6618778038880581,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## albert-large-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-large-v2-within_256_8-acc64_3\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/23/2021 15:42:23 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_loss = 0.6909940242767334\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_acc = 0.5328581363004172\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_f1 = 0.6952478167177044\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_acc_and_f1 = 0.6140529765090608\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_pearson = nan\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_spearmanr = nan\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_corr = nan\n",
    "[INFO|trainer.py:393] 01/23/2021 15:42:23 >>   eval_class_report = {'accuracy': 0.5328581363004172,\n",
    " 'macro avg': {'f1-score': 0.3476239083588522,\n",
    "               'precision': 0.2664290681502086,\n",
    "               'recall': 0.5,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.0,\n",
    "              'precision': 0.0,\n",
    "              'recall': 0.0,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.6952478167177044,\n",
    "          'precision': 0.5328581363004172,\n",
    "          'recall': 1.0,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.37046845588313004,\n",
    "                  'precision': 0.283937793421554,\n",
    "                  'recall': 0.5328581363004172,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/23/2021 15:57:18 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_loss = 0.6912679672241211\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_acc = 0.5309028321076514\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_f1 = 0.6935813573180704\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_acc_and_f1 = 0.6122420947128608\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_pearson = nan\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_spearmanr = nan\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_corr = nan\n",
    "[INFO|trainer.py:393] 01/23/2021 15:57:18 >>   eval_class_report = {'accuracy': 0.5309028321076514,\n",
    " 'macro avg': {'f1-score': 0.3467906786590352,\n",
    "               'precision': 0.2654514160538257,\n",
    "               'recall': 0.5,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.0,\n",
    "              'precision': 0.0,\n",
    "              'recall': 0.0,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.6935813573180704,\n",
    "          'precision': 0.5309028321076514,\n",
    "          'recall': 1.0,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.36822430689723246,\n",
    "                  'precision': 0.2818578171399251,\n",
    "                  'recall': 0.5309028321076514,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## albert-base-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v1-cross_256_16-acc64_3\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 15:20:17 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_loss = 0.31151360273361206\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_acc = 0.8230958230958231\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_f1 = 0.8090523338048091\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_acc_and_f1 = 0.8160740784503161\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_pearson = 0.6599230044027254\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_spearmanr = 0.6599230044027257\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_corr = 0.6599230044027256\n",
    "[INFO|trainer.py:393] 01/21/2021 15:20:17 >>   eval_class_report = {'accuracy': 0.8230958230958231,\n",
    " 'macro avg': {'f1-score': 0.8221337347998718,\n",
    "               'precision': 0.8347570744780322,\n",
    "               'recall': 0.8252346290358223,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8352151357949344,\n",
    "              'precision': 0.7662374020156775,\n",
    "              'recall': 0.9178403755868545,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.8090523338048091,\n",
    "          'precision': 0.9032767469403868,\n",
    "          'recall': 0.7326288824847903,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.8218316090766443,\n",
    "                  'precision': 0.8363395927118065,\n",
    "                  'recall': 0.8230958230958231,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 15:42:07 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_loss = 1.3032617568969727\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_acc = 0.6393398846400342\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_f1 = 0.6651128192412596\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_acc_and_f1 = 0.6522263519406469\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_pearson = 0.2814743425181645\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_spearmanr = 0.28147434251816433\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_corr = 0.2814743425181644\n",
    "[INFO|trainer.py:393] 01/21/2021 15:42:07 >>   eval_class_report = {'accuracy': 0.6393398846400342,\n",
    " 'macro avg': {'f1-score': 0.6371910216671495,\n",
    "               'precision': 0.6391232477942741,\n",
    "               'recall': 0.6423698173241138,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6092692240930394,\n",
    "              'precision': 0.5640064274236744,\n",
    "              'recall': 0.6624308002013085,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.6651128192412596,\n",
    "          'precision': 0.7142400681648738,\n",
    "          'recall': 0.6223088344469191,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.6414082211725748,\n",
    "                  'precision': 0.6504685996426001,\n",
    "                  'recall': 0.6393398846400342,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albert-base-v1-within_256_16-acc64_3\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 17:06:10 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_loss = 0.28364089131355286\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_acc = 0.8416203059805285\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_f1 = 0.8464520478678578\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_acc_and_f1 = 0.8440361769241931\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_pearson = 0.6849065838033949\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_spearmanr = 0.684906583803396\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_corr = 0.6849065838033954\n",
    "[INFO|trainer.py:393] 01/21/2021 17:06:10 >>   eval_class_report = {'accuracy': 0.8416203059805285,\n",
    " 'macro avg': {'f1-score': 0.8414633242390805,\n",
    "               'precision': 0.8417143495493822,\n",
    "               'recall': 0.8431938321845682,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8364746006103034,\n",
    "              'precision': 0.8079056865464632,\n",
    "              'recall': 0.867138072199479,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.8464520478678578,\n",
    "          'precision': 0.8755230125523012,\n",
    "          'recall': 0.8192495921696574,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8417911645609996,\n",
    "                  'precision': 0.8439361288635517,\n",
    "                  'recall': 0.8416203059805285,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 17:13:42 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_loss = 0.287702351808548\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_acc = 0.8375841026443436\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_f1 = 0.8408951563458001\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_acc_and_f1 = 0.8392396294950719\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_pearson = 0.6778494755959008\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_spearmanr = 0.6778494755958996\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_corr = 0.6778494755959001\n",
    "[INFO|trainer.py:393] 01/21/2021 17:13:42 >>   eval_class_report = {'accuracy': 0.8375841026443436,\n",
    " 'macro avg': {'f1-score': 0.837513733494089,\n",
    "               'precision': 0.838345713653099,\n",
    "               'recall': 0.8395047528492814,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8341323106423778,\n",
    "              'precision': 0.8006134969325154,\n",
    "              'recall': 0.8705803869246164,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8408951563458001,\n",
    "          'precision': 0.8760779303736825,\n",
    "          'recall': 0.8084291187739464,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8377227245794319,\n",
    "                  'precision': 0.8406777783698304,\n",
    "                  'recall': 0.8375841026443436,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distilroberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilroberta-base-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 23:13:28 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_loss = 0.3782177269458771\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_acc = 0.7656467315716272\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_f1 = 0.7408688965782392\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_acc_and_f1 = 0.7532578140749332\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_pearson = 0.5684536930320547\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_spearmanr = 0.5684536930320541\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_corr = 0.5684536930320544\n",
    "[INFO|trainer.py:393] 01/19/2021 23:13:28 >>   eval_class_report = {'accuracy': 0.7656467315716272,\n",
    " 'macro avg': {'f1-score': 0.763484273741357,\n",
    "               'precision': 0.7934659762040217,\n",
    "               'recall': 0.775278590470339,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.7860996509044749,\n",
    "              'precision': 0.6852005532503458,\n",
    "              'recall': 0.9218459248232229,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.7408688965782392,\n",
    "          'precision': 0.9017313991576977,\n",
    "          'recall': 0.6287112561174552,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.7619980754507348,\n",
    "                  'precision': 0.8005807762520902,\n",
    "                  'recall': 0.7656467315716272,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 23:20:51 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_loss = 0.38409894704818726\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_acc = 0.7595055546862776\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_f1 = 0.731528384279476\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_acc_and_f1 = 0.7455169694828767\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_pearson = 0.5574781562096623\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_spearmanr = 0.557478156209664\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_corr = 0.5574781562096631\n",
    "[INFO|trainer.py:393] 01/19/2021 23:20:51 >>   eval_class_report = {'accuracy': 0.7595055546862776,\n",
    " 'macro avg': {'f1-score': 0.7568652265736333,\n",
    "               'precision': 0.788956058514273,\n",
    "               'recall': 0.7688833522377724,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.7822020688677908,\n",
    "              'precision': 0.679970436067997,\n",
    "              'recall': 0.9206137424949966,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.731528384279476,\n",
    "          'precision': 0.8979416809605489,\n",
    "          'recall': 0.6171529619805481,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.7552992662065245,\n",
    "                  'precision': 0.7956919872994833,\n",
    "                  'recall': 0.7595055546862776,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilroberta-base-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 21:48:00 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_loss = 0.33110690116882324\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_acc = 0.7981981981981981\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_f1 = 0.7644359464627151\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_acc_and_f1 = 0.7813170723304566\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_pearson = 0.6349379656957238\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_spearmanr = 0.6349379656957235\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_corr = 0.6349379656957237\n",
    "[INFO|trainer.py:393] 01/19/2021 21:48:00 >>   eval_class_report = {'accuracy': 0.7981981981981981,\n",
    " 'macro avg': {'f1-score': 0.7939658242342229,\n",
    "               'precision': 0.8338008586637884,\n",
    "               'recall': 0.8019361767788931,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8234957020057306,\n",
    "              'precision': 0.7188594297148574,\n",
    "              'recall': 0.9637826961770624,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.7644359464627151,\n",
    "          'precision': 0.9487422876127195,\n",
    "          'recall': 0.6400896573807237,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.7932838074011709,\n",
    "                  'precision': 0.836455525573174,\n",
    "                  'recall': 0.7981981981981981,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/19/2021 22:09:49 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_loss = 1.4416067600250244\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_acc = 0.5906857509079256\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_f1 = 0.547953285360387\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_acc_and_f1 = 0.5693195181341564\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_pearson = 0.25036372981551563\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_spearmanr = 0.2503637298155157\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_corr = 0.2503637298155157\n",
    "[INFO|trainer.py:393] 01/19/2021 22:09:49 >>   eval_class_report = {'accuracy': 0.5906857509079256,\n",
    " 'macro avg': {'f1-score': 0.5869950871029515,\n",
    "               'precision': 0.631589896155279,\n",
    "               'recall': 0.6190858854641286,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6260368888455158,\n",
    "              'precision': 0.5113183484776024,\n",
    "              'recall': 0.8071212883744339,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.547953285360387,\n",
    "          'precision': 0.7518614438329556,\n",
    "          'recall': 0.43105048255382333,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.5810983654981676,\n",
    "                  'precision': 0.6497552420660069,\n",
    "                  'recall': 0.5906857509079256,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilroberta-base-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.31419679522514343\n",
    "eval_acc = 0.8086814086814087\n",
    "eval_f1 = 0.7739063104916764\n",
    "eval_acc_and_f1 = 0.7912938595865425\n",
    "eval_pearson = 0.662442260215558\n",
    "eval_spearmanr = 0.662442260215556\n",
    "eval_corr = 0.662442260215557\n",
    "eval_class_report = {'not same': {'precision': 0.7232890201871, 'recall': 0.9852448021462106, 'f1-score': 0.8341851220897218, 'support': 2982}, 'same': {'precision': 0.9784630445423397, 'recall': 0.6400896573807237, 'f1-score': 0.7739063104916764, 'support': 3123}, 'accuracy': 0.8086814086814087, 'macro avg': {'precision': 0.8508760323647198, 'recall': 0.8126672297634672, 'f1-score': 0.8040457162906991, 'support': 6105}, 'weighted avg': {'precision': 0.8538227594272988, 'recall': 0.8086814086814087, 'f1-score': 0.8033496219061516, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 1.854202151298523\n",
    "eval_acc = 0.6009933774834437\n",
    "eval_f1 = 0.5568539059256185\n",
    "eval_acc_and_f1 = 0.5789236417045311\n",
    "eval_pearson = 0.27528132972100966\n",
    "eval_spearmanr = 0.27528132972100944\n",
    "eval_corr = 0.27528132972100955\n",
    "eval_class_report = {'not same': {'precision': 0.5188671782295704, 'recall': 0.8252390538500252, 'f1-score': 0.6371363349361309, 'support': 7948}, 'same': {'precision': 0.7716587210258097, 'recall': 0.43559762435040833, 'f1-score': 0.5568539059256185, 'support': 10776}, 'accuracy': 0.6009933774834437, 'macro avg': {'precision': 0.64526294962769, 'recall': 0.6304183391002167, 'f1-score': 0.5969951204308747, 'support': 18724}, 'weighted avg': {'precision': 0.6643532744254834, 'recall': 0.6009933774834437, 'f1-score': 0.5909323478063893, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilroberta-base-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.29001525044441223\n",
    "eval_acc = 0.8235396383866481\n",
    "eval_f1 = 0.8075099563815664\n",
    "eval_acc_and_f1 = 0.8155247973841073\n",
    "eval_pearson = 0.6824412203854425\n",
    "eval_spearmanr = 0.6824412203854464\n",
    "eval_corr = 0.6824412203854444\n",
    "eval_class_report = {'not same': {'precision': 0.7358916478555305, 'recall': 0.9705991812430219, 'f1-score': 0.8371047985877066, 'support': 2687}, 'same': {'precision': 0.9642210144927537, 'recall': 0.6946166394779771, 'f1-score': 0.8075099563815664, 'support': 3065}, 'accuracy': 0.8235396383866481, 'macro avg': {'precision': 0.850056331174142, 'recall': 0.8326079103604995, 'f1-score': 0.8223073774846366, 'support': 5752}, 'weighted avg': {'precision': 0.857558808624496, 'recall': 0.8235396383866481, 'f1-score': 0.8213349461256377, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.2928236126899719\n",
    "eval_acc = 0.822250039117509\n",
    "eval_f1 = 0.8050789293067948\n",
    "eval_acc_and_f1 = 0.8136644842121519\n",
    "eval_pearson = 0.6800104368557991\n",
    "eval_spearmanr = 0.680010436855801\n",
    "eval_corr = 0.6800104368558\n",
    "eval_class_report = {'not same': {'precision': 0.7353387259858443, 'recall': 0.9703135423615744, 'f1-score': 0.8366407822835777, 'support': 2998}, 'same': {'precision': 0.9634496919917864, 'recall': 0.6914235190097259, 'f1-score': 0.8050789293067948, 'support': 3393}, 'accuracy': 0.822250039117509, 'macro avg': {'precision': 0.8493942089888153, 'recall': 0.8308685306856501, 'f1-score': 0.8208598557951863, 'support': 6391}, 'weighted avg': {'precision': 0.8564434838732112, 'recall': 0.822250039117509, 'f1-score': 0.8198845051516384, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## google-electra-{small,base}-discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-small-discriminator-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 11:56:04 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_loss = 0.5857097506523132\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_acc = 0.6594228094575799\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_f1 = 0.6455581689886014\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_acc_and_f1 = 0.6524904892230907\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_pearson = 0.33247947382595683\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_spearmanr = 0.3324794738259579\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_corr = 0.33247947382595733\n",
    "[INFO|trainer.py:393] 01/20/2021 11:56:04 >>   eval_class_report = {'accuracy': 0.6594228094575799,\n",
    " 'macro avg': {'f1-score': 0.6589008847285319,\n",
    "               'precision': 0.667626216361028,\n",
    "               'recall': 0.6648647253922123,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.6722436004684624,\n",
    "              'precision': 0.6106382978723405,\n",
    "              'recall': 0.7476739858578341,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.6455581689886014,\n",
    "          'precision': 0.7246141348497157,\n",
    "          'recall': 0.5820554649265905,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.6580240511837312,\n",
    "                  'precision': 0.6713712499473848,\n",
    "                  'recall': 0.6594228094575799,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 12:03:21 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_loss = 0.5906827449798584\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_acc = 0.6548271006102332\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_f1 = 0.6391887471377167\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_acc_and_f1 = 0.647007923873975\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_pearson = 0.323023508577506\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_spearmanr = 0.3230235085775057\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_corr = 0.32302350857750584\n",
    "[INFO|trainer.py:393] 01/20/2021 12:03:21 >>   eval_class_report = {'accuracy': 0.6548271006102332,\n",
    " 'macro avg': {'f1-score': 0.6541774569521817,\n",
    "               'precision': 0.6630101231014804,\n",
    "               'recall': 0.6600271582961192,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.6691661667666466,\n",
    "              'precision': 0.6079019073569483,\n",
    "              'recall': 0.7441627751834556,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.6391887471377167,\n",
    "          'precision': 0.7181183388460125,\n",
    "          'recall': 0.5758915414087827,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.6532510697863683,\n",
    "                  'precision': 0.6664161229792914,\n",
    "                  'recall': 0.6548271006102332,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-small-discriminator-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 13:31:20 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_loss = 0.5128113031387329\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_acc = 0.723996723996724\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_f1 = 0.6611703197265232\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_acc_and_f1 = 0.6925835218616236\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_pearson = 0.49743841385600396\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_spearmanr = 0.49743841385600385\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_corr = 0.4974384138560039\n",
    "[INFO|trainer.py:393] 01/21/2021 13:31:20 >>   eval_class_report = {'accuracy': 0.723996723996724,\n",
    " 'macro avg': {'f1-score': 0.7141695180227199,\n",
    "               'precision': 0.7705287896592244,\n",
    "               'recall': 0.7286678766160846,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.7671687163189167,\n",
    "              'precision': 0.6524089306698002,\n",
    "              'recall': 0.9309188464118041,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.6611703197265232,\n",
    "          'precision': 0.8886486486486487,\n",
    "          'recall': 0.526416906820365,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.7129454579146505,\n",
    "                  'precision': 0.7732568650265478,\n",
    "                  'recall': 0.723996723996724,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 13:52:56 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_loss = 0.6586917638778687\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_acc = 0.5987502670369579\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_f1 = 0.5593806814849569\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_acc_and_f1 = 0.5790654742609573\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_pearson = 0.2649930110807973\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_spearmanr = 0.26499301108079754\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_corr = 0.2649930110807974\n",
    "[INFO|trainer.py:393] 01/21/2021 13:52:56 >>   eval_class_report = {'accuracy': 0.5987502670369579,\n",
    " 'macro avg': {'f1-score': 0.5955211001678842,\n",
    "               'precision': 0.6387356414169814,\n",
    "               'recall': 0.6265379523323279,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.6316615188508115,\n",
    "              'precision': 0.5174712828339626,\n",
    "              'recall': 0.8105183694011072,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.5593806814849569,\n",
    "          'precision': 0.76,\n",
    "          'recall': 0.44255753526354863,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.5900625921548892,\n",
    "                  'precision': 0.6570509376182618,\n",
    "                  'recall': 0.5987502670369579,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-small-discriminator-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.3882655203342438\n",
    "eval_acc = 0.782964782964783\n",
    "eval_f1 = 0.7641929168891262\n",
    "eval_acc_and_f1 = 0.7735788499269546\n",
    "eval_pearson = 0.580012605286061\n",
    "eval_spearmanr = 0.5800126052860608\n",
    "eval_corr = 0.5800126052860609\n",
    "eval_class_report = {'not same': {'precision': 0.7295649764477695, 'recall': 0.8829644533869886, 'f1-score': 0.7989682900925504, 'support': 2982}, 'same': {'precision': 0.860176282051282, 'recall': 0.6874799871918027, 'f1-score': 0.7641929168891262, 'support': 3123}, 'accuracy': 0.782964782964783, 'macro avg': {'precision': 0.7948706292495258, 'recall': 0.7852222202893957, 'f1-score': 0.7815806034908384, 'support': 6105}, 'weighted avg': {'precision': 0.7963789170537924, 'recall': 0.782964782964783, 'f1-score': 0.7811790205570395, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.8302304148674011\n",
    "eval_acc = 0.5961333048493912\n",
    "eval_f1 = 0.6061048025836024\n",
    "eval_acc_and_f1 = 0.6011190537164968\n",
    "eval_pearson = 0.2109045367636189\n",
    "eval_spearmanr = 0.21090453676361867\n",
    "eval_corr = 0.21090453676361878\n",
    "eval_class_report = {'not same': {'precision': 0.5187342263638128, 'recall': 0.6723704076497232, 'f1-score': 0.5856438356164384, 'support': 7948}, 'same': {'precision': 0.6908097838993114, 'recall': 0.5399034892353378, 'f1-score': 0.6061048025836024, 'support': 10776}, 'accuracy': 0.5961333048493912, 'macro avg': {'precision': 0.6047720051315622, 'recall': 0.6061369484425305, 'f1-score': 0.5958743191000204, 'support': 18724}, 'weighted avg': {'precision': 0.6177668159815511, 'recall': 0.5961333048493912, 'f1-score': 0.5974194914612451, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-small-discriminator-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.4254252314567566\n",
    "eval_acc = 0.7682545201668984\n",
    "eval_f1 = 0.7372363493002168\n",
    "eval_acc_and_f1 = 0.7527454347335576\n",
    "eval_pearson = 0.5848188235318036\n",
    "eval_spearmanr = 0.5848188235318024\n",
    "eval_corr = 0.584818823531803\n",
    "eval_class_report = {'not same': {'precision': 0.6808226495726496, 'recall': 0.9486416077409751, 'f1-score': 0.7927227491836418, 'support': 2687}, 'same': {'precision': 0.9312749003984063, 'recall': 0.6101141924959217, 'f1-score': 0.7372363493002168, 'support': 3065}, 'accuracy': 0.7682545201668984, 'macro avg': {'precision': 0.806048774985528, 'recall': 0.7793779001184484, 'f1-score': 0.7649795492419293, 'support': 5752}, 'weighted avg': {'precision': 0.814278169179907, 'recall': 0.7682545201668984, 'f1-score': 0.7631563695517403, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.4281770586967468\n",
    "eval_acc = 0.7681114066656235\n",
    "eval_f1 = 0.7341227125941874\n",
    "eval_acc_and_f1 = 0.7511170596299055\n",
    "eval_pearson = 0.587292580508521\n",
    "eval_spearmanr = 0.5872925805085206\n",
    "eval_corr = 0.5872925805085207\n",
    "eval_class_report = {'not same': {'precision': 0.6800475059382423, 'recall': 0.9549699799866578, 'f1-score': 0.7943951165371809, 'support': 2998}, 'same': {'precision': 0.938101788170564, 'recall': 0.6030061892130858, 'f1-score': 0.7341227125941874, 'support': 3393}, 'accuracy': 0.7681114066656235, 'macro avg': {'precision': 0.8090746470544031, 'recall': 0.7789880845998718, 'f1-score': 0.7642589145656842, 'support': 6391}, 'weighted avg': {'precision': 0.8170492552128891, 'recall': 0.7681114066656235, 'f1-score': 0.7623963265859093, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-base-discriminator-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 13:57:43 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_loss = 0.2934107780456543\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_acc = 0.8266689847009736\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_f1 = 0.820003610760065\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_acc_and_f1 = 0.8233362977305193\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_pearson = 0.6705416164684774\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_spearmanr = 0.6705416164684798\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_corr = 0.6705416164684785\n",
    "[INFO|trainer.py:393] 01/20/2021 13:57:43 >>   eval_class_report = {'accuracy': 0.8266689847009736,\n",
    " 'macro avg': {'f1-score': 0.8264309755392949,\n",
    "               'precision': 0.8378628893635974,\n",
    "               'recall': 0.8326986135286143,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.8328583403185247,\n",
    "              'precision': 0.7577791336180598,\n",
    "              'recall': 0.9244510606624489,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.820003610760065,\n",
    "          'precision': 0.917946645109135,\n",
    "          'recall': 0.7409461663947797,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8260085930833581,\n",
    "                  'precision': 0.8431256952870698,\n",
    "                  'recall': 0.8266689847009736,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 14:05:19 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_loss = 0.2989029884338379\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_acc = 0.8228759192614614\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_f1 = 0.8151534944480732\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_acc_and_f1 = 0.8190147068547673\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_pearson = 0.6630323142553108\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_spearmanr = 0.6630323142553095\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_corr = 0.6630323142553102\n",
    "[INFO|trainer.py:393] 01/20/2021 14:05:19 >>   eval_class_report = {'accuracy': 0.8228759192614614,\n",
    " 'macro avg': {'f1-score': 0.8225662335562685,\n",
    "               'precision': 0.834434483255398,\n",
    "               'recall': 0.8286232967572251,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8299789726644639,\n",
    "              'precision': 0.7549180327868853,\n",
    "              'recall': 0.9216144096064043,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8151534944480732,\n",
    "          'precision': 0.9139509337239107,\n",
    "          'recall': 0.735632183908046,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.8221080842920317,\n",
    "                  'precision': 0.8393490502926476,\n",
    "                  'recall': 0.8228759192614614,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-base-discriminator-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 11:43:38 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_loss = 0.31584039330482483\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_acc = 0.8052416052416053\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_f1 = 0.7814739937511488\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_acc_and_f1 = 0.793357799496377\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_pearson = 0.6348578426123624\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_spearmanr = 0.6348578426123619\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_corr = 0.6348578426123621\n",
    "[INFO|trainer.py:393] 01/21/2021 11:43:38 >>   eval_class_report = {'accuracy': 0.8052416052416053,\n",
    " 'macro avg': {'f1-score': 0.8029101391417881,\n",
    "               'precision': 0.8269504478447111,\n",
    "               'recall': 0.8081846828650416,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8243462845324273,\n",
    "              'precision': 0.7367309215738052,\n",
    "              'recall': 0.9356136820925554,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.7814739937511488,\n",
    "          'precision': 0.917169974115617,\n",
    "          'recall': 0.680755683637528,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.8024150537199894,\n",
    "                  'precision': 0.8290341420632529,\n",
    "                  'recall': 0.8052416052416053,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 12:05:31 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_loss = 1.16436767578125\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_acc = 0.5971480452894681\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_f1 = 0.6080947680157947\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_acc_and_f1 = 0.6026214066526314\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_pearson = 0.21205463931731305\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_spearmanr = 0.2120546393173132\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_corr = 0.2120546393173131\n",
    "[INFO|trainer.py:393] 01/21/2021 12:05:31 >>   eval_class_report = {'accuracy': 0.5971480452894681,\n",
    " 'macro avg': {'f1-score': 0.5968334946611581,\n",
    "               'precision': 0.6052889230988628,\n",
    "               'recall': 0.6067708946309887,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.5855722213065215,\n",
    "              'precision': 0.519750316980396,\n",
    "              'recall': 0.6704831404126824,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.6080947680157947,\n",
    "          'precision': 0.6908275292173297,\n",
    "          'recall': 0.5430586488492948,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.5985343535079275,\n",
    "                  'precision': 0.6182083408569821,\n",
    "                  'recall': 0.5971480452894681,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-base-discriminator-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.30031126737594604\n",
    "eval_acc = 0.8218011126564673\n",
    "eval_f1 = 0.8069316255415333\n",
    "eval_acc_and_f1 = 0.8143663690990003\n",
    "eval_pearson = 0.6759926578752187\n",
    "eval_spearmanr = 0.675992657875218\n",
    "eval_corr = 0.6759926578752183\n",
    "eval_class_report = {'not same': {'precision': 0.7368871151653363, 'recall': 0.9620394491998512, 'f1-score': 0.8345439870863598, 'support': 2687}, 'same': {'precision': 0.9545454545454546, 'recall': 0.698858075040783, 'f1-score': 0.8069316255415333, 'support': 3065}, 'accuracy': 0.8218011126564673, 'macro avg': {'precision': 0.8457162848553954, 'recall': 0.8304487621203172, 'f1-score': 0.8207378063139465, 'support': 5752}, 'weighted avg': {'precision': 0.8528681322376699, 'recall': 0.8218011126564673, 'f1-score': 0.8198305155747303, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.30624982714653015\n",
    "eval_acc = 0.8203723986856517\n",
    "eval_f1 = 0.8042291950886767\n",
    "eval_acc_and_f1 = 0.8123007968871643\n",
    "eval_pearson = 0.6735519571591688\n",
    "eval_spearmanr = 0.6735519571591679\n",
    "eval_corr = 0.6735519571591684\n",
    "eval_class_report = {'not same': {'precision': 0.735969387755102, 'recall': 0.9623082054703136, 'f1-score': 0.8340560855738653, 'support': 2998}, 'same': {'precision': 0.9542695265074869, 'recall': 0.6949602122015915, 'f1-score': 0.8042291950886767, 'support': 3393}, 'accuracy': 0.8203723986856517, 'macro avg': {'precision': 0.8451194571312944, 'recall': 0.8286342088359526, 'f1-score': 0.819142640331271, 'support': 6391}, 'weighted avg': {'precision': 0.8518655496682364, 'recall': 0.8203723986856517, 'f1-score': 0.8182209049423139, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-electra-base-discriminator-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.3325725495815277\n",
    "eval_acc = 0.8008190008190008\n",
    "eval_f1 = 0.7723698989142644\n",
    "eval_acc_and_f1 = 0.7865944498666326\n",
    "eval_pearson = 0.6321284940330373\n",
    "eval_spearmanr = 0.632128494033035\n",
    "eval_corr = 0.6321284940330361\n",
    "eval_class_report = {'not same': {'precision': 0.7272259392691713, 'recall': 0.9476861167002012, 'f1-score': 0.8229470005824111, 'support': 2982}, 'same': {'precision': 0.9296980621901757, 'recall': 0.6605827729747038, 'f1-score': 0.7723698989142644, 'support': 3123}, 'accuracy': 0.8008190008190008, 'macro avg': {'precision': 0.8284620007296735, 'recall': 0.8041344448374526, 'f1-score': 0.7976584497483378, 'support': 6105}, 'weighted avg': {'precision': 0.8308001308960831, 'recall': 0.8008190008190008, 'f1-score': 0.7970743898519242, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 1.2830554246902466\n",
    "eval_acc = 0.5944776757103183\n",
    "eval_f1 = 0.6067636853280852\n",
    "eval_acc_and_f1 = 0.6006206805192018\n",
    "eval_pearson = 0.20548471493687545\n",
    "eval_spearmanr = 0.20548471493687537\n",
    "eval_corr = 0.20548471493687542\n",
    "eval_class_report = {'not same': {'precision': 0.5174173290157983, 'recall': 0.6634373427277303, 'f1-score': 0.5813991951044711, 'support': 7948}, 'same': {'precision': 0.6865111918434313, 'recall': 0.543615441722346, 'f1-score': 0.6067636853280852, 'support': 10776}, 'accuracy': 0.5944776757103183, 'macro avg': {'precision': 0.6019642604296148, 'recall': 0.6035263922250381, 'f1-score': 0.5940814402162782, 'support': 18724}, 'weighted avg': {'precision': 0.6147338995045065, 'recall': 0.5944776757103183, 'f1-score': 0.5959969171002876, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence-transformers-*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence-transformers-stsb-distilbert-base-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/22/2021 19:17:05 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_loss = 0.3450496792793274\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_acc = 0.8008190008190008\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_f1 = 0.7715144682450207\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_acc_and_f1 = 0.7861667345320107\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_pearson = 0.6335264760464568\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_spearmanr = 0.6335264760464555\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_corr = 0.6335264760464562\n",
    "[INFO|trainer.py:393] 01/22/2021 19:17:05 >>   eval_class_report = {'accuracy': 0.8008190008190008,\n",
    " 'macro avg': {'f1-score': 0.7974877799993976,\n",
    "               'precision': 0.8298343263136644,\n",
    "               'recall': 0.8042101472105125,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8234610917537746,\n",
    "              'precision': 0.7260624679979518,\n",
    "              'recall': 0.9510395707578806,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.7715144682450207,\n",
    "          'precision': 0.933606184629377,\n",
    "          'recall': 0.6573807236631444,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.7968879049859059,\n",
    "                  'precision': 0.832231022795649,\n",
    "                  'recall': 0.8008190008190008,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/22/2021 19:39:05 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_loss = 0.9359179139137268\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_acc = 0.5993377483443708\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_f1 = 0.5880285557386051\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_acc_and_f1 = 0.593683152041488\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_pearson = 0.23753793301393983\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_spearmanr = 0.23753793301393966\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_corr = 0.23753793301393974\n",
    "[INFO|trainer.py:393] 01/22/2021 19:39:05 >>   eval_class_report = {'accuracy': 0.5993377483443708,\n",
    " 'macro avg': {'f1-score': 0.5990355898559956,\n",
    "               'precision': 0.6199782294406305,\n",
    "               'recall': 0.6175718917581952,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.610042623973386,\n",
    "              'precision': 0.5197519929140832,\n",
    "              'recall': 0.7382989431303473,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.5880285557386051,\n",
    "          'precision': 0.7202044659671778,\n",
    "          'recall': 0.49684484038604304,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.5973731303129503,\n",
    "                  'precision': 0.6351160096637173,\n",
    "                  'recall': 0.5993377483443708,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence-transformers-stsb-distilbert-base-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 19:00:33 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_loss = 0.4477314054965973\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_acc = 0.7428720445062587\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_f1 = 0.7084565345949143\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_acc_and_f1 = 0.7256642895505865\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_pearson = 0.5314554974872577\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_spearmanr = 0.531455497487256\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_corr = 0.5314554974872568\n",
    "[INFO|trainer.py:393] 01/20/2021 19:00:33 >>   eval_class_report = {'accuracy': 0.7428720445062587,\n",
    " 'macro avg': {'f1-score': 0.7392383745902577,\n",
    "               'precision': 0.7781225525249429,\n",
    "               'recall': 0.7538853315249364,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.770020214585601,\n",
    "              'precision': 0.6613247863247863,\n",
    "              'recall': 0.9214737625604764,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.7084565345949143,\n",
    "          'precision': 0.8949203187250996,\n",
    "          'recall': 0.5862969004893964,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.7372155068019683,\n",
    "                  'precision': 0.785798066367721,\n",
    "                  'recall': 0.7428720445062587,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 19:08:04 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_loss = 0.4496627151966095\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_acc = 0.7432326709435143\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_f1 = 0.7084739740628887\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_acc_and_f1 = 0.7258533225032016\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_pearson = 0.5304690587671419\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_spearmanr = 0.5304690587671419\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_corr = 0.5304690587671419\n",
    "[INFO|trainer.py:393] 01/20/2021 19:08:04 >>   eval_class_report = {'accuracy': 0.7432326709435143,\n",
    " 'macro avg': {'f1-score': 0.7395298711360159,\n",
    "               'precision': 0.7775341259641486,\n",
    "               'recall': 0.753480019197394,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.770585768209143,\n",
    "              'precision': 0.6632972322503008,\n",
    "              'recall': 0.9192795196797865,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.7084739740628887,\n",
    "          'precision': 0.8917710196779964,\n",
    "          'recall': 0.5876805187150015,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.7376104407896091,\n",
    "                  'precision': 0.7845946130580258,\n",
    "                  'recall': 0.7432326709435143,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence-transformers-stsb-distilbert-base-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.3095523416996002\n",
    "eval_acc = 0.8162378303198887\n",
    "eval_f1 = 0.7991639749192475\n",
    "eval_acc_and_f1 = 0.8077009026195681\n",
    "eval_pearson = 0.6682048377757859\n",
    "eval_spearmanr = 0.668204837775785\n",
    "eval_corr = 0.6682048377757854\n",
    "eval_class_report = {'not same': {'precision': 0.7293190770962296, 'recall': 0.964644585039077, 'f1-score': 0.8306361160070501, 'support': 2687}, 'same': {'precision': 0.956778889899909, 'recall': 0.6861337683523654, 'f1-score': 0.7991639749192475, 'support': 3065}, 'accuracy': 0.8162378303198887, 'macro avg': {'precision': 0.8430489834980692, 'recall': 0.8253891766957212, 'f1-score': 0.8149000454631488, 'support': 5752}, 'weighted avg': {'precision': 0.85052288903004, 'recall': 0.8162378303198887, 'f1-score': 0.8138659295616197, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.31675851345062256\n",
    "eval_acc = 0.8116100766703176\n",
    "eval_f1 = 0.7926283155356528\n",
    "eval_acc_and_f1 = 0.8021191961029852\n",
    "eval_pearson = 0.6596613111197852\n",
    "eval_spearmanr = 0.6596613111197853\n",
    "eval_corr = 0.6596613111197853\n",
    "eval_class_report = {'not same': {'precision': 0.7254901960784313, 'recall': 0.962641761174116, 'f1-score': 0.8274082568807339, 'support': 2998}, 'same': {'precision': 0.9535847492747617, 'recall': 0.6781609195402298, 'f1-score': 0.7926283155356528, 'support': 3393}, 'accuracy': 0.8116100766703176, 'macro avg': {'precision': 0.8395374726765965, 'recall': 0.8204013403571729, 'f1-score': 0.8100182862081934, 'support': 6391}, 'weighted avg': {'precision': 0.8465862403586926, 'recall': 0.8116100766703176, 'f1-score': 0.8089434875200924, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence-transformers-stsb-distilbert-base-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.32317113876342773\n",
    "eval_acc = 0.8016380016380016\n",
    "eval_f1 = 0.7694650675804302\n",
    "eval_acc_and_f1 = 0.7855515346092159\n",
    "eval_pearson = 0.6403613282494534\n",
    "eval_spearmanr = 0.640361328249456\n",
    "eval_corr = 0.6403613282494547\n",
    "eval_class_report = {'not same': {'precision': 0.7227672955974843, 'recall': 0.9634473507712944, 'f1-score': 0.8259307172631882, 'support': 2982}, 'same': {'precision': 0.9488262910798122, 'recall': 0.6471341658661544, 'f1-score': 0.7694650675804302, 'support': 3123}, 'accuracy': 0.8016380016380016, 'macro avg': {'precision': 0.8357967933386483, 'recall': 0.8052907583187243, 'f1-score': 0.7976978924218092, 'support': 6105}, 'weighted avg': {'precision': 0.8384073026230879, 'recall': 0.8016380016380016, 'f1-score': 0.7970458320937774, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.9492101073265076\n",
    "eval_acc = 0.5146870326853237\n",
    "eval_f1 = 0.4643678160919541\n",
    "eval_acc_and_f1 = 0.4895274243886389\n",
    "eval_pearson = 0.08662568050987275\n",
    "eval_spearmanr = 0.08662568050987272\n",
    "eval_corr = 0.08662568050987274\n",
    "eval_class_report = {'not same': {'precision': 0.45456721180694054, 'recall': 0.7169099144438853, 'f1-score': 0.5563638138944491, 'support': 7948}, 'same': {'precision': 0.6364517692680562, 'recall': 0.3655345211581292, 'f1-score': 0.4643678160919541, 'support': 10776}, 'accuracy': 0.5146870326853237, 'macro avg': {'precision': 0.5455094905374984, 'recall': 0.5412222178010072, 'f1-score': 0.5103658149932015, 'support': 18724}, 'weighted avg': {'precision': 0.5592450579509793, 'recall': 0.5146870326853237, 'f1-score': 0.503418456475111, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence-transformers-quora-distilbert-base-within_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 18:03:52 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_loss = 0.5804098844528198\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_acc = 0.663769123783032\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_f1 = 0.6116465863453815\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_acc_and_f1 = 0.6377078550642068\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_pearson = 0.37161380534817934\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_spearmanr = 0.37161380534817945\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_corr = 0.3716138053481794\n",
    "[INFO|trainer.py:393] 01/20/2021 18:03:52 >>   eval_class_report = {'accuracy': 0.663769123783032,\n",
    " 'macro avg': {'f1-score': 0.6576013434485952,\n",
    "               'precision': 0.6967118975537759,\n",
    "               'recall': 0.6755064411998803,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.7035561005518088,\n",
    "              'precision': 0.5981235340109461,\n",
    "              'recall': 0.8541123930033495,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.6116465863453815,\n",
    "          'precision': 0.7953002610966058,\n",
    "          'recall': 0.49690048939641107,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.6545813681034952,\n",
    "                  'precision': 0.7031907573276268,\n",
    "                  'recall': 0.663769123783032,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/20/2021 18:11:15 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_loss = 0.5795391201972961\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_acc = 0.6657800031294007\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_f1 = 0.61205957137668\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_acc_and_f1 = 0.6389197872530403\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_pearson = 0.3753663753311783\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_spearmanr = 0.37536637533117906\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_corr = 0.37536637533117867\n",
    "[INFO|trainer.py:393] 01/20/2021 18:11:15 >>   eval_class_report = {'accuracy': 0.6657800031294007,\n",
    " 'macro avg': {'f1-score': 0.6592458384645907,\n",
    "               'precision': 0.699096202475072,\n",
    "               'recall': 0.6769244138984886,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.7064321055525014,\n",
    "              'precision': 0.6007480130902291,\n",
    "              'recall': 0.857238158772515,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.61205957137668,\n",
    "          'precision': 0.7974443918599148,\n",
    "          'recall': 0.4966106690244621,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.6563294598853817,\n",
    "                  'precision': 0.7051746776443745,\n",
    "                  'recall': 0.6657800031294007,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xlnet-base-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlnet-base-cased-cross_256_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 22:57:27 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_loss = 0.30419042706489563\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_acc = 0.8178542178542179\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_f1 = 0.8101092896174863\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_acc_and_f1 = 0.813981753735852\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_pearson = 0.6418215032470128\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_spearmanr = 0.6418215032470113\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_corr = 0.641821503247012\n",
    "[INFO|trainer.py:393] 01/21/2021 22:57:27 >>   eval_class_report = {'accuracy': 0.8178542178542179,\n",
    " 'macro avg': {'f1-score': 0.8175507102793129,\n",
    "               'precision': 0.8225971160444443,\n",
    "               'recall': 0.8192332026098312,\n",
    "               'support': 6105},\n",
    " 'not same': {'f1-score': 0.8249921309411394,\n",
    "              'precision': 0.7772835112692764,\n",
    "              'recall': 0.8789403085177733,\n",
    "              'support': 2982},\n",
    " 'same': {'f1-score': 0.8101092896174863,\n",
    "          'precision': 0.8679107208196122,\n",
    "          'recall': 0.7595260967018892,\n",
    "          'support': 3123},\n",
    " 'weighted avg': {'f1-score': 0.8173788445441257,\n",
    "                  'precision': 0.8236436710441657,\n",
    "                  'recall': 0.8178542178542179,\n",
    "                  'support': 6105}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 23:41:11 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_loss = 1.6446138620376587\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_acc = 0.6162144840845973\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_f1 = 0.6362992205688834\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_acc_and_f1 = 0.6262568523267404\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_pearson = 0.24152696200837429\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_spearmanr = 0.24152696200837426\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_corr = 0.24152696200837426\n",
    "[INFO|trainer.py:393] 01/21/2021 23:41:11 >>   eval_class_report = {'accuracy': 0.6162144840845973,\n",
    " 'macro avg': {'f1-score': 0.6150405090973303,\n",
    "               'precision': 0.6194765726164799,\n",
    "               'recall': 0.6220642509646033,\n",
    "               'support': 18724},\n",
    " 'not same': {'f1-score': 0.5937817976257773,\n",
    "              'precision': 0.5391090125230958,\n",
    "              'recall': 0.6607951685958732,\n",
    "              'support': 7948},\n",
    " 'same': {'f1-score': 0.6362992205688834,\n",
    "          'precision': 0.6998441327098641,\n",
    "          'recall': 0.5833333333333334,\n",
    "          'support': 10776},\n",
    " 'weighted avg': {'f1-score': 0.6182513420412287,\n",
    "                  'precision': 0.6316149757324857,\n",
    "                  'recall': 0.6162144840845973,\n",
    "                  'support': 18724}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlnet-base-cased-within_256_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 19:43:30 >> ***** Eval 'dev' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_loss = 0.28896164894104004\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_acc = 0.825278164116829\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_f1 = 0.8068422064193734\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_acc_and_f1 = 0.8160601852681012\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_pearson = 0.6920375919904205\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_spearmanr = 0.6920375919904191\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_corr = 0.6920375919904198\n",
    "[INFO|trainer.py:393] 01/21/2021 19:43:30 >>   eval_class_report = {'accuracy': 0.825278164116829,\n",
    " 'macro avg': {'f1-score': 0.8236718570582822,\n",
    "               'precision': 0.8572323978623821,\n",
    "               'recall': 0.8351571915045009,\n",
    "               'support': 5752},\n",
    " 'not same': {'f1-score': 0.840501507697191,\n",
    "              'precision': 0.7327061427780852,\n",
    "              'recall': 0.9854856717528843,\n",
    "              'support': 2687},\n",
    " 'same': {'f1-score': 0.8068422064193734,\n",
    "          'precision': 0.9817586529466792,\n",
    "          'recall': 0.6848287112561174,\n",
    "          'support': 3065},\n",
    " 'weighted avg': {'f1-score': 0.8225658751491188,\n",
    "                  'precision': 0.8654157991874629,\n",
    "                  'recall': 0.825278164116829,\n",
    "                  'support': 5752}}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "[INFO|trainer.py:389] 01/21/2021 19:58:34 >> ***** Eval 'test' results same-b *****\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_loss = 0.2877608835697174\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_acc = 0.8235017994054139\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_f1 = 0.8030038421236464\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_acc_and_f1 = 0.8132528207645302\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_pearson = 0.690587819661487\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_spearmanr = 0.690587819661486\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_corr = 0.6905878196614865\n",
    "[INFO|trainer.py:393] 01/21/2021 19:58:34 >>   eval_class_report = {'accuracy': 0.8235017994054139,\n",
    " 'macro avg': {'f1-score': 0.8215699482727076,\n",
    "               'precision': 0.8579177790025767,\n",
    "               'recall': 0.8331152883728163,\n",
    "               'support': 6391},\n",
    " 'not same': {'f1-score': 0.8401360544217688,\n",
    "              'precision': 0.7304090685066535,\n",
    "              'recall': 0.9886591060707138,\n",
    "              'support': 2998},\n",
    " 'same': {'f1-score': 0.8030038421236464,\n",
    "          'precision': 0.9854264894984998,\n",
    "          'recall': 0.677571470674919,\n",
    "          'support': 3393},\n",
    " 'weighted avg': {'f1-score': 0.820422457750273,\n",
    "                  'precision': 0.865798539548014,\n",
    "                  'recall': 0.8235017994054139,\n",
    "                  'support': 6391}}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlnet-base-cased-within_512_4-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.25013595819473267\n",
    "eval_acc = 0.8610917941585535\n",
    "eval_f1 = 0.8730335293182901\n",
    "eval_acc_and_f1 = 0.8670626617384218\n",
    "eval_pearson = 0.7211089273861645\n",
    "eval_spearmanr = 0.7211089273861674\n",
    "eval_corr = 0.7211089273861659\n",
    "eval_class_report = {'not same': {'precision': 0.8740095087163233, 'recall': 0.8209899516189059, 'f1-score': 0.8466705047015928, 'support': 2687}, 'same': {'precision': 0.8509913258983891, 'recall': 0.8962479608482871, 'f1-score': 0.8730335293182901, 'support': 3065}, 'accuracy': 0.8610917941585535, 'macro avg': {'precision': 0.8625004173073563, 'recall': 0.8586189562335964, 'f1-score': 0.8598520170099415, 'support': 5752}, 'weighted avg': {'precision': 0.8617440827189365, 'recall': 0.8610917941585535, 'f1-score': 0.8607182568660883, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.26528200507164\n",
    "eval_acc = 0.8532311062431545\n",
    "eval_f1 = 0.8662293211637192\n",
    "eval_acc_and_f1 = 0.8597302137034368\n",
    "eval_pearson = 0.7058347943758488\n",
    "eval_spearmanr = 0.7058347943758506\n",
    "eval_corr = 0.7058347943758497\n",
    "eval_class_report = {'not same': {'precision': 0.8715728715728716, 'recall': 0.8058705803869246, 'f1-score': 0.8374350086655113, 'support': 2998}, 'same': {'precision': 0.8391820945012435, 'recall': 0.8950781019746537, 'f1-score': 0.8662293211637192, 'support': 3393}, 'accuracy': 0.8532311062431545, 'macro avg': {'precision': 0.8553774830370575, 'recall': 0.8504743411807891, 'f1-score': 0.8518321649146152, 'support': 6391}, 'weighted avg': {'precision': 0.8543765162913767, 'recall': 0.8532311062431545, 'f1-score': 0.8527219907194027, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlnet-base-cased-cross_512_4-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.282042533159256\n",
    "eval_acc = 0.8230958230958231\n",
    "eval_f1 = 0.8123044838373307\n",
    "eval_acc_and_f1 = 0.8177001534665769\n",
    "eval_pearson = 0.6558365943456839\n",
    "eval_spearmanr = 0.6558365943456793\n",
    "eval_corr = 0.6558365943456816\n",
    "eval_class_report = {'not same': {'precision': 0.7737478411053541, 'recall': 0.9014084507042254, 'f1-score': 0.8327137546468402, 'support': 2982}, 'same': {'precision': 0.8882554161915621, 'recall': 0.7483189241114313, 'f1-score': 0.8123044838373307, 'support': 3123}, 'accuracy': 0.8230958230958231, 'macro avg': {'precision': 0.8310016286484581, 'recall': 0.8248636874078283, 'f1-score': 0.8225091192420855, 'support': 6105}, 'weighted avg': {'precision': 0.8323239519971195, 'recall': 0.8230958230958231, 'f1-score': 0.8222734347880198, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 1.9847371578216553\n",
    "eval_acc = 0.5983764152958769\n",
    "eval_f1 = 0.5791358853816879\n",
    "eval_acc_and_f1 = 0.5887561503387824\n",
    "eval_pearson = 0.243344407918002\n",
    "eval_spearmanr = 0.24334440791800188\n",
    "eval_corr = 0.24334440791800194\n",
    "eval_class_report = {'not same': {'precision': 0.5183975240715268, 'recall': 0.7586814292903875, 'f1-score': 0.6159346271705823, 'support': 7948}, 'same': {'precision': 0.7295544275239707, 'recall': 0.4801410541945063, 'f1-score': 0.5791358853816879, 'support': 10776}, 'accuracy': 0.5983764152958769, 'macro avg': {'precision': 0.6239759757977488, 'recall': 0.6194112417424469, 'f1-score': 0.5975352562761351, 'support': 18724}, 'weighted avg': {'precision': 0.639922133749135, 'recall': 0.5983764152958769, 'f1-score': 0.594756286991287, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## facebook-bart-base - **ERROR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### facebook-bart-base-cross_256_16-acc64_3 - **ERROR**\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### facebook-bart-base-within_256_16-acc64_3 - **ERROR**\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## squeezebert/squeezebert-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezebert-squeezebert-uncased-within_256_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.2944766879081726\n",
    "eval_acc = 0.8348400556328234\n",
    "eval_f1 = 0.8290136789056874\n",
    "eval_acc_and_f1 = 0.8319268672692555\n",
    "eval_pearson = 0.686122656925977\n",
    "eval_spearmanr = 0.686122656925979\n",
    "eval_corr = 0.686122656925978\n",
    "eval_class_report = {'not same': {'precision': 0.766329346826127, 'recall': 0.9300334946036471, 'f1-score': 0.840282447881641, 'support': 2687}, 'same': {'precision': 0.9245283018867925, 'recall': 0.7513866231647635, 'f1-score': 0.8290136789056874, 'support': 3065}, 'accuracy': 0.8348400556328234, 'macro avg': {'precision': 0.8454288243564597, 'recall': 0.8407100588842054, 'f1-score': 0.8346480633936642, 'support': 5752}, 'weighted avg': {'precision': 0.8506269471844268, 'recall': 0.8348400556328234, 'f1-score': 0.8342777926467143, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.2993025481700897\n",
    "eval_acc = 0.8296041308089501\n",
    "eval_f1 = 0.8228404099560761\n",
    "eval_acc_and_f1 = 0.8262222703825131\n",
    "eval_pearson = 0.6755049954859349\n",
    "eval_spearmanr = 0.6755049954859358\n",
    "eval_corr = 0.6755049954859353\n",
    "eval_class_report = {'not same': {'precision': 0.7624415727247732, 'recall': 0.9249499666444296, 'f1-score': 0.8358703843255463, 'support': 2998}, 'same': {'precision': 0.9183006535947712, 'recall': 0.7453580901856764, 'f1-score': 0.8228404099560761, 'support': 3393}, 'accuracy': 0.8296041308089501, 'macro avg': {'precision': 0.8403711131597722, 'recall': 0.835154028415053, 'f1-score': 0.8293553971408112, 'support': 6391}, 'weighted avg': {'precision': 0.8451876001683506, 'recall': 0.8296041308089501, 'f1-score': 0.8289527340305044, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezebert-squeezebert-uncased-cross_256_16-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.32461732625961304\n",
    "eval_acc = 0.8075348075348076\n",
    "eval_f1 = 0.7783437087342012\n",
    "eval_acc_and_f1 = 0.7929392581345044\n",
    "eval_pearson = 0.6490578572186733\n",
    "eval_spearmanr = 0.6490578572186759\n",
    "eval_corr = 0.6490578572186746\n",
    "eval_class_report = {'not same': {'precision': 0.7300738477209066, 'recall': 0.9614352783366867, 'f1-score': 0.8299319727891157, 'support': 2982}, 'same': {'precision': 0.9471992653810836, 'recall': 0.6605827729747038, 'f1-score': 0.7783437087342012, 'support': 3123}, 'accuracy': 0.8075348075348076, 'macro avg': {'precision': 0.838636556550995, 'recall': 0.8110090256556952, 'f1-score': 0.8041378407616584, 'support': 6105}, 'weighted avg': {'precision': 0.8411439016689383, 'recall': 0.8075348075348076, 'f1-score': 0.803542104051442, 'support': 6105}}\n",
    "epoch = 2.987769365171811\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.9906368851661682\n",
    "eval_acc = 0.618564409314249\n",
    "eval_f1 = 0.5996187913443212\n",
    "eval_acc_and_f1 = 0.6090916003292851\n",
    "eval_pearson = 0.2861878609630287\n",
    "eval_spearmanr = 0.28618786096302895\n",
    "eval_corr = 0.28618786096302884\n",
    "eval_class_report = {'not same': {'precision': 0.534556679814783, 'recall': 0.7843482637141419, 'f1-score': 0.6357980622131565, 'support': 7948}, 'same': {'precision': 0.757292551685075, 'recall': 0.4962880475129918, 'f1-score': 0.5996187913443212, 'support': 10776}, 'accuracy': 0.618564409314249, 'macro avg': {'precision': 0.645924615749929, 'recall': 0.6403181556135669, 'f1-score': 0.6177084267787388, 'support': 18724}, 'weighted avg': {'precision': 0.6627451948369079, 'recall': 0.618564409314249, 'f1-score': 0.6149762387308574, 'support': 18724}}\n",
    "epoch = 2.987769365171811\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezebert-squeezebert-uncased-within_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.28705912828445435\n",
    "eval_acc = 0.8404033379694019\n",
    "eval_f1 = 0.8360128617363344\n",
    "eval_acc_and_f1 = 0.8382080998528681\n",
    "eval_pearson = 0.6950971267757147\n",
    "eval_spearmanr = 0.6950971267757124\n",
    "eval_corr = 0.6950971267757136\n",
    "eval_class_report = {'not same': {'precision': 0.7747747747747747, 'recall': 0.9281726832899144, 'f1-score': 0.8445648493057906, 'support': 2687}, 'same': {'precision': 0.9238057639163048, 'recall': 0.763458401305057, 'f1-score': 0.8360128617363344, 'support': 3065}, 'accuracy': 0.8404033379694019, 'macro avg': {'precision': 0.8492902693455398, 'recall': 0.8458155422974858, 'f1-score': 0.8402888555210625, 'support': 5752}, 'weighted avg': {'precision': 0.8541871498997382, 'recall': 0.8404033379694019, 'f1-score': 0.8400078531478659, 'support': 5752}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.28681451082229614\n",
    "eval_acc = 0.8446252542638085\n",
    "eval_f1 = 0.8397611747619816\n",
    "eval_acc_and_f1 = 0.8421932145128951\n",
    "eval_pearson = 0.7034568981872531\n",
    "eval_spearmanr = 0.7034568981872513\n",
    "eval_corr = 0.7034568981872522\n",
    "eval_class_report = {'not same': {'precision': 0.7794814608307779, 'recall': 0.9326217478318879, 'f1-score': 0.8492027334851936, 'support': 2998}, 'same': {'precision': 0.927960057061341, 'recall': 0.7668729737695255, 'f1-score': 0.8397611747619816, 'support': 3393}, 'accuracy': 0.8446252542638085, 'macro avg': {'precision': 0.8537207589460594, 'recall': 0.8497473608007067, 'f1-score': 0.8444819541235876, 'support': 6391}, 'weighted avg': {'precision': 0.8583091680769522, 'recall': 0.8446252542638085, 'f1-score': 0.8441901832195297, 'support': 6391}}\n",
    "epoch = 2.9990726429675423\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezebert-squeezebert-uncased-cross_512_8-acc64_3\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 0.29773375391960144\n",
    "eval_acc = 0.8324324324324325\n",
    "eval_f1 = 0.8297553669495755\n",
    "eval_acc_and_f1 = 0.831093899691004\n",
    "eval_pearson = 0.6672957801179994\n",
    "eval_spearmanr = 0.6672957801180006\n",
    "eval_corr = 0.667295780118\n",
    "eval_class_report = {'not same': {'precision': 0.804287045666356, 'recall': 0.8682092555331992, 'f1-score': 0.8350266086115141, 'support': 2982}, 'same': {'precision': 0.8638253638253638, 'recall': 0.7982708933717579, 'f1-score': 0.8297553669495755, 'support': 3123}, 'accuracy': 0.8324324324324325, 'macro avg': {'precision': 0.83405620474586, 'recall': 0.8332400744524786, 'f1-score': 0.8323909877805449, 'support': 6105}, 'weighted avg': {'precision': 0.8347437479776715, 'recall': 0.8324324324324325, 'f1-score': 0.832330115948085, 'support': 6105}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "eval_loss = 1.1942470073699951\n",
    "eval_acc = 0.6424909207434308\n",
    "eval_f1 = 0.6631780215356747\n",
    "eval_acc_and_f1 = 0.6528344711395528\n",
    "eval_pearson = 0.2927139352881322\n",
    "eval_spearmanr = 0.2927139352881325\n",
    "eval_corr = 0.2927139352881324\n",
    "eval_class_report = {'not same': {'precision': 0.5651360897569083, 'recall': 0.6844489179667841, 'f1-score': 0.6190963923978604, 'support': 7948}, 'same': {'precision': 0.7243350186854254, 'recall': 0.6115441722345955, 'f1-score': 0.6631780215356747, 'support': 10776}, 'accuracy': 0.6424909207434308, 'macro avg': {'precision': 0.6447355542211668, 'recall': 0.6479965451006897, 'f1-score': 0.6411372069667676, 'support': 18724}, 'weighted avg': {'precision': 0.6567579471663133, 'recall': 0.6424909207434308, 'f1-score': 0.6444661657149447, 'support': 18724}}\n",
    "epoch = 2.9970879440885265\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert-base-v2-within_512_8-acc64_3-art-art\n",
      "squeezebert-squeezebert-uncased-cross_256_16-acc64_3\n",
      "squeezebert-squeezebert-uncased-cross_512_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-within_512_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-within_256_8-acc64_3\n",
      "albert-base-v2-cross_128_32-acc64_3\n",
      "albert-base-v2-within_128_32-acc64_3\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "distilroberta-base-within_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-cross_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-within_512_8-acc64_3\n",
      "google-electra-small-discriminator-within_512_8-acc64_3\n",
      "google-electra-small-discriminator-cross_512_8-acc64_3\n",
      "google-electra-base-discriminator-cross_512_8-acc64_3\n",
      "google-electra-base-discriminator-within_512_8-acc64_3\n",
      "distilroberta-base-cross_512_8-acc64_3\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "roberta-base-within_512_8-acc64_3\n",
      "bert-base-uncased-within_128_32-acc64_3\n",
      "albert-large-v2-within_256_8-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-cross_256_16-acc64_3\n",
      "albert-base-v2-cross_512_16-acc64_10\n",
      "albert-base-v2-within_512_16-acc64_10\n",
      "bert-base-uncased-within_256_16-acc64_10\n",
      "bert-base-uncased-cross_256_16-acc64_10\n",
      "albert-base-v2-cross_256_16-acc64_10\n",
      "albert-base-v2-within_256_16-acc64_10\n",
      "bert-base-cased-cross_256_16-acc64_3\n",
      "facebook-bart-base-cross_256_16-acc64_3\n",
      "facebook-bart-base-within_256_16-acc64_3\n",
      "xlnet-base-cased-cross_256_8-acc64_3\n",
      "xlnet-base-cased-within_256_8-acc64_3\n",
      "albert-base-v1-within_256_16-acc64_3\n",
      "albert-base-v1-cross_256_16-acc64_3\n",
      "google-electra-small-discriminator-cross_256_16-acc64_3\n",
      "google-electra-base-discriminator-cross_256_16-acc64_3\n",
      "bert-base-uncased-cross_512_8-acc64_3\n",
      "bert-base-uncased-within_512_8-acc64_3\n",
      "bert-base-cased-within_256_16-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-within_256_16-acc64_3\n",
      "sentence-transformers-quora-distilbert-base-within_256_16-acc64_3\n",
      "roberta-base-cross_256_16-acc64_3\n",
      "roberta-base-within_256_16-acc64_3\n",
      "google-electra-base-discriminator-within_256_16-acc64_3\n",
      "google-electra-small-discriminator-within_256_16-acc64_3\n",
      "albert-base-v2-within_256_16-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "distilbert-base-cased-cross_256_16-acc64_3\n",
      "distilroberta-base-within_256_16-acc64_3\n",
      "distilroberta-base-cross_256_16-acc64_3\n",
      "albert-base-v2-cross_256_12-acc64_3\n",
      "albert-base-v2-cross_256_16-acc64_3\n",
      "bert-base-uncased-within_256_16-acc64_3\n",
      "bert-base-uncased-cross_256_16-acc64_3\n",
      "bert-base-uncased-cross_128_32-acc64_3\n",
      "distilbert-base-cased-within_256_32-acc64_3\n"
     ]
    }
   ],
   "source": [
    "! ls -t ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output_5:\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "\n",
      "./output_6:\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "roberta-base-within_512_8-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "\n",
      "./output_4:\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "roberta-base-within_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "\n",
      "./output_3:\n",
      "albert-base-v2-within_512_8-acc64_5\n",
      "\n",
      "./output_2:\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n"
     ]
    }
   ],
   "source": [
    "! ls -t ./output_[0-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert-base-v2-within_512_8-acc64_3\n",
      "  eval: 88.40 (89.00)\n",
      "  test: 88.81 (89.30)\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "  eval: 87.08 (87.59)\n",
      "  test: 87.31 (87.62)\n",
      "bert-base-cased-within_256_16-acc64_3\n",
      "  eval: 86.65 (87.21)\n",
      "  test: 86.47 (87.01)\n",
      "bert-base-uncased-within_512_8-acc64_3\n",
      "  eval: 85.94 (86.00)\n",
      "  test: 86.26 (86.28)\n",
      "albert-base-v2-within_256_16-acc64_10\n",
      "  eval: 86.32 (87.37)\n",
      "  test: 86.17 (87.19)\n",
      "bert-base-uncased-within_256_16-acc64_10\n",
      "  eval: 86.65 (87.39)\n",
      "  test: 85.64 (86.36)\n",
      "bert-base-uncased-within_256_16-acc64_3\n",
      "  eval: 85.36 (85.97)\n",
      "  test: 85.45 (86.02)\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "  eval: 86.11 (87.30)\n",
      "  test: 85.32 (86.62)\n",
      "squeezebert-squeezebert-uncased-within_512_8-acc64_3\n",
      "  eval: 84.04 (83.60)\n",
      "  test: 84.46 (83.98)\n",
      "albert-base-v2-within_256_16-acc64_3\n",
      "  eval: 84.44 (84.91)\n",
      "  test: 84.32 (84.72)\n",
      "albert-base-v1-within_256_16-acc64_3\n",
      "  eval: 84.16 (84.65)\n",
      "  test: 83.76 (84.09)\n",
      "squeezebert-squeezebert-uncased-within_256_8-acc64_3\n",
      "  eval: 83.48 (82.90)\n",
      "  test: 82.96 (82.28)\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "  eval: 82.16 (80.39)\n",
      "  test: 82.35 (80.44)\n",
      "xlnet-base-cased-within_256_8-acc64_3\n",
      "  eval: 82.53 (80.68)\n",
      "  test: 82.35 (80.30)\n",
      "google-electra-base-discriminator-within_256_16-acc64_3\n",
      "  eval: 82.67 (82.00)\n",
      "  test: 82.29 (81.52)\n",
      "distilroberta-base-within_512_8-acc64_3\n",
      "  eval: 82.35 (80.75)\n",
      "  test: 82.23 (80.51)\n",
      "roberta-base-within_512_8-acc64_3\n",
      "  eval: 81.99 (79.79)\n",
      "  test: 82.21 (79.99)\n",
      "google-electra-base-discriminator-within_512_8-acc64_3\n",
      "  eval: 82.18 (80.69)\n",
      "  test: 82.04 (80.42)\n",
      "sentence-transformers-stsb-distilbert-base-within_512_8-acc64_3\n",
      "  eval: 81.62 (79.92)\n",
      "  test: 81.16 (79.26)\n",
      "albert-base-v2-within_128_32-acc64_3\n",
      "  eval: 81.22 (80.86)\n",
      "  test: 80.79 (80.38)\n",
      "bert-base-uncased-within_128_32-acc64_3\n",
      "  eval: 77.82 (74.56)\n",
      "  test: 77.59 (74.23)\n",
      "google-electra-small-discriminator-within_512_8-acc64_3\n",
      "  eval: 76.83 (73.72)\n",
      "  test: 76.81 (73.41)\n",
      "roberta-base-within_256_16-acc64_3\n",
      "  eval: 76.83 (72.75)\n",
      "  test: 76.19 (71.85)\n",
      "distilroberta-base-within_256_16-acc64_3\n",
      "  eval: 76.56 (74.09)\n",
      "  test: 75.95 (73.15)\n",
      "sentence-transformers-stsb-distilbert-base-within_256_16-acc64_3\n",
      "  eval: 74.29 (70.85)\n",
      "  test: 74.32 (70.85)\n",
      "distilbert-base-cased-within_256_32-acc64_3\n",
      "  eval: 68.17 (63.68)\n",
      "  test: 67.91 (63.74)\n",
      "sentence-transformers-quora-distilbert-base-within_256_16-acc64_3\n",
      "  eval: 66.38 (61.16)\n",
      "  test: 66.58 (61.21)\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "  eval: 88.26 (88.41)\n",
      "  test: 66.19 (68.95)\n",
      "google-electra-small-discriminator-within_256_16-acc64_3\n",
      "  eval: 65.94 (64.56)\n",
      "  test: 65.48 (63.92)\n",
      "albert-base-v2-cross_256_16-acc64_10\n",
      "  eval: 85.16 (84.82)\n",
      "  test: 65.40 (67.44)\n",
      "bert-base-uncased-cross_512_8-acc64_3\n",
      "  eval: 86.27 (86.41)\n",
      "  test: 64.77 (65.94)\n",
      "albert-base-v2-cross_256_12-acc64_3\n",
      "  eval: 84.96 (85.18)\n",
      "  test: 64.55 (67.29)\n",
      "squeezebert-squeezebert-uncased-cross_512_8-acc64_3\n",
      "  eval: 83.24 (82.98)\n",
      "  test: 64.25 (66.32)\n",
      "albert-base-v1-cross_256_16-acc64_3\n",
      "  eval: 82.31 (80.91)\n",
      "  test: 63.93 (66.51)\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "  eval: 87.68 (87.55)\n",
      "  test: 63.54 (65.64)\n",
      "bert-base-cased-cross_256_16-acc64_3\n",
      "  eval: 86.57 (86.25)\n",
      "  test: 63.23 (65.16)\n",
      "squeezebert-squeezebert-uncased-cross_256_16-acc64_3\n",
      "  eval: 80.75 (77.83)\n",
      "  test: 61.86 (59.96)\n",
      "xlnet-base-cased-cross_256_8-acc64_3\n",
      "  eval: 81.79 (81.01)\n",
      "  test: 61.62 (63.63)\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "  eval: 80.97 (77.87)\n",
      "  test: 61.55 (55.38)\n",
      "bert-base-uncased-cross_256_16-acc64_3\n",
      "  eval: 80.82 (78.71)\n",
      "  test: 60.72 (58.27)\n",
      "bert-base-uncased-cross_128_32-acc64_3\n",
      "  eval: 80.13 (77.42)\n",
      "  test: 60.34 (57.36)\n",
      "roberta-base-cross_256_16-acc64_3\n",
      "  eval: 80.07 (76.19)\n",
      "  test: 60.31 (54.59)\n",
      "distilroberta-base-cross_512_8-acc64_3\n",
      "  eval: 80.87 (77.39)\n",
      "  test: 60.10 (55.69)\n",
      "sentence-transformers-stsb-distilbert-base-cross_256_16-acc64_3\n",
      "  eval: 80.08 (77.15)\n",
      "  test: 59.93 (58.80)\n",
      "google-electra-small-discriminator-cross_256_16-acc64_3\n",
      "  eval: 72.40 (66.12)\n",
      "  test: 59.88 (55.94)\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "  eval: 82.31 (81.23)\n",
      "  test: 59.84 (57.91)\n",
      "google-electra-base-discriminator-cross_256_16-acc64_3\n",
      "  eval: 80.52 (78.15)\n",
      "  test: 59.71 (60.81)\n",
      "google-electra-small-discriminator-cross_512_8-acc64_3\n",
      "  eval: 78.30 (76.42)\n",
      "  test: 59.61 (60.61)\n",
      "google-electra-base-discriminator-cross_512_8-acc64_3\n",
      "  eval: 80.08 (77.24)\n",
      "  test: 59.45 (60.68)\n",
      "albert-base-v2-cross_128_32-acc64_3\n",
      "  eval: 80.08 (77.62)\n",
      "  test: 59.25 (58.65)\n",
      "distilbert-base-cased-cross_256_16-acc64_3\n",
      "  eval: 79.66 (76.68)\n",
      "  test: 59.08 (56.91)\n",
      "distilroberta-base-cross_256_16-acc64_3\n",
      "  eval: 79.82 (76.44)\n",
      "  test: 59.07 (54.80)\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "  eval: 81.11 (77.89)\n",
      "  test: 58.77 (54.87)\n",
      "albert-large-v2-within_256_8-acc64_3\n",
      "  eval: 53.29 (69.52)\n",
      "  test: 53.09 (69.36)\n",
      "bert-base-uncased-cross_256_16-acc64_10\n",
      "  eval: 79.85 (76.94)\n",
      "  test: 51.81 (40.34)\n",
      "sentence-transformers-stsb-distilbert-base-cross_512_8-acc64_3\n",
      "  eval: 80.16 (76.95)\n",
      "  test: 51.47 (46.44)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "fn_base = Path(\"output\")\n",
    "\n",
    "data = list()\n",
    "for fn in sorted(fn_base.iterdir()):\n",
    "    run_name = fn.name\n",
    "\n",
    "    sfn = fn / \"eval_results_same-b.json\"\n",
    "    if not sfn.exists():\n",
    "        continue\n",
    "\n",
    "    with (sfn).open(\"r\") as fp:\n",
    "        stats_eval = json.load(fp)\n",
    "    with (fn / \"test_results_same-b.json\").open(\"r\") as fp:\n",
    "        stats_test = json.load(fp)\n",
    "        \n",
    "    data.append((run_name, stats_eval, stats_test))\n",
    "\n",
    "\n",
    "data = sorted(data, key=lambda x: x[2][\"eval_acc\"], reverse=True)\n",
    "\n",
    "\n",
    "for run_name, stats_eval, stats_test in data:\n",
    "    print(run_name)\n",
    "    print(f\"  eval: {stats_eval['eval_acc'] * 100:.2f} ({stats_eval['eval_f1'] * 100:.2f})\")\n",
    "    print(f\"  test: {stats_test['eval_acc'] * 100:.2f} ({stats_test['eval_f1'] * 100:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip: output/.ipynb_checkpoints, reason: test_results_same-b.json missing\n",
      "Skip: output/albert-base-v2-cross_256_16-acc64_3, reason: test_results_same-b.json missing\n",
      "Skip: output/albert-base-v2-cross_512_16-acc64_10, reason: test_results_same-b.json missing\n",
      "Skip: output/albert-base-v2-within_512_16-acc64_10, reason: test_results_same-b.json missing\n",
      "Skip: output/albert-base-v2-within_512_8-acc64_3-art-art, reason: invalid literal for int() with base 10: '3-art-art'\n",
      "Skip: output/facebook-bart-base-cross_256_16-acc64_3, reason: test_results_same-b.json missing\n",
      "Skip: output/facebook-bart-base-within_256_16-acc64_3, reason: test_results_same-b.json missing\n",
      "\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "  acc [0.65675069 0.6618778  0.66721854] 66.19 00.43\n",
      "  f1  [0.68197338 0.68951989 0.69594496] 68.91 00.57\n",
      "  pre [0.65618696 0.65995381 0.66459162] 66.02 00.34\n",
      "  rec [0.65982386 0.6635683  0.66819173] 66.39 00.34\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "  acc [0.88076983 0.88374276 0.88812392] 88.42 00.30\n",
      "  f1  [0.88810573 0.89220949 0.89304413] 89.11 00.22\n",
      "  pre [0.88045576 0.88428744 0.88754412] 88.41 00.29\n",
      "  rec [0.88007965 0.88225823 0.88867542] 88.37 00.36\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "  acc [0.634373   0.63538774 0.63693655] 63.56 00.11\n",
      "  f1  [0.65629079 0.65636483 0.66819602] 66.03 00.56\n",
      "  pre [0.634301   0.63622284 0.63768912] 63.61 00.14\n",
      "  rec [0.6372441  0.6393259  0.64078533] 63.91 00.15\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "  acc [0.86261931 0.86825223 0.8731028 ] 86.80 00.43\n",
      "  f1  [0.86891609 0.87172456 0.87620211] 87.23 00.30\n",
      "  pre [0.86198541 0.86851083 0.87351689] 86.80 00.47\n",
      "  rec [0.8629468  0.86990217 0.87489754] 86.92 00.49\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "  acc [0.58774834 0.59271523 0.59469131] 59.17 00.29\n",
      "  f1  [0.54867567 0.55775922 0.57126716] 55.92 00.93\n",
      "  pre [0.62266073 0.6254099  0.62832146] 62.55 00.23\n",
      "  rec [0.61484995 0.61701865 0.61876887] 61.69 00.16\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "  acc [0.82084181 0.82303239 0.8235018 ] 82.25 00.12\n",
      "  f1  [0.80006984 0.80443828 0.80496637] 80.32 00.22\n",
      "  pre [0.85216413 0.85483042 0.8549737 ] 85.40 00.13\n",
      "  rec [0.83043539 0.83193541 0.83270756] 83.17 00.09\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "  acc [0.59015168 0.59479812 0.61546678] 60.01 01.10\n",
      "  f1  [0.53360885 0.54922465 0.55384806] 54.56 00.87\n",
      "  pre [0.63879173 0.64183043 0.68072374] 65.38 01.91\n",
      "  rec [0.62266672 0.62430959 0.65118129] 63.27 01.31\n",
      "roberta-base-within_512_8-acc64_3\n",
      "  acc [0.82131122 0.82209357 0.82569238] 82.30 00.19\n",
      "  f1  [0.79922644 0.79985918 0.80852527] 80.25 00.42\n",
      "  pre [0.85370791 0.85848822 0.85989614] 85.74 00.26\n",
      "  rec [0.8312852  0.83213851 0.83442115] 83.26 00.13\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "  acc [0.59837642 0.61867122 0.62192907] 61.30 01.04\n",
      "  f1  [0.57913589 0.63515951 0.65507246] 62.31 03.21\n",
      "  pre [0.61455068 0.62397598 0.62865087] 62.24 00.59\n",
      "  rec [0.61680237 0.61941124 0.63084268] 62.24 00.61\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "  acc [0.8297606  0.83148177 0.85323111] 83.82 01.07\n",
      "  f1  [0.81738839 0.82148185 0.86622932] 83.50 02.21\n",
      "  pre [0.84735071 0.84946284 0.85537748] 85.07 00.34\n",
      "  rec [0.83714588 0.83814556 0.85047434] 84.19 00.61\n",
      "\n",
      "albert-base-v2 & cross & 66.02 $\\pm$0.34 & 66.39 $\\pm$0.34 & 68.91 $\\pm$0.57 & 66.19 $\\pm$0.43 \\\\\n",
      "albert-base-v2 & within & 88.41 $\\pm$0.29 & 88.37 $\\pm$0.36 & 89.11 $\\pm$0.22 & 88.42 $\\pm$0.30 \\\\\n",
      "bert-base-cased & cross & 63.61 $\\pm$0.14 & 63.91 $\\pm$0.15 & 66.03 $\\pm$0.56 & 63.56 $\\pm$0.11 \\\\\n",
      "bert-base-cased & within & 86.80 $\\pm$0.47 & 86.92 $\\pm$0.49 & 87.23 $\\pm$0.30 & 86.80 $\\pm$0.43 \\\\\n",
      "distilbert-base-cased & cross & 62.55 $\\pm$0.23 & 61.69 $\\pm$0.16 & 55.92 $\\pm$0.93 & 59.17 $\\pm$0.29 \\\\\n",
      "distilbert-base-cased & within & 85.40 $\\pm$0.13 & 83.17 $\\pm$0.09 & 80.32 $\\pm$0.22 & 82.25 $\\pm$0.12 \\\\\n",
      "roberta-base & cross & 65.38 $\\pm$1.91 & 63.27 $\\pm$1.31 & 54.56 $\\pm$0.87 & 60.01 $\\pm$1.10 \\\\\n",
      "roberta-base & within & 85.74 $\\pm$0.26 & 83.26 $\\pm$0.13 & 80.25 $\\pm$0.42 & 82.30 $\\pm$0.19 \\\\\n",
      "xlnet-base-cased & cross & 62.24 $\\pm$0.59 & 62.24 $\\pm$0.61 & 62.31 $\\pm$3.21 & 61.30 $\\pm$1.04 \\\\\n",
      "xlnet-base-cased & within & 85.07 $\\pm$0.34 & 84.19 $\\pm$0.61 & 83.50 $\\pm$2.21 & 83.82 $\\pm$1.07 \\\\\n",
      "\n",
      "albert-base-v2 & cross & 66.19 (68.91) \\\\\n",
      "albert-base-v2 & within & 88.42 (89.11) \\\\\n",
      "bert-base-cased & cross & 63.56 (66.03) \\\\\n",
      "bert-base-cased & within & 86.80 (87.23) \\\\\n",
      "distilbert-base-cased & cross & 59.17 (55.92) \\\\\n",
      "distilbert-base-cased & within & 82.25 (80.32) \\\\\n",
      "roberta-base & cross & 60.01 (54.56) \\\\\n",
      "roberta-base & within & 82.30 (80.25) \\\\\n",
      "xlnet-base-cased & cross & 61.30 (62.31) \\\\\n",
      "xlnet-base-cased & within & 83.82 (83.50) \\\\\n",
      "\n",
      "albert-base-v2 & 66.02 $\\pm$0.34 & 66.39 $\\pm$0.34 & 68.91 $\\pm$0.57 & 66.19 $\\pm$0.43 &88.41 $\\pm$0.29 & 88.37 $\\pm$0.36 & 89.11 $\\pm$0.22 & 88.42 $\\pm$0.30 \\\\\n",
      "bert-base-cased & 63.61 $\\pm$0.14 & 63.91 $\\pm$0.15 & 66.03 $\\pm$0.56 & 63.56 $\\pm$0.11 &86.80 $\\pm$0.47 & 86.92 $\\pm$0.49 & 87.23 $\\pm$0.30 & 86.80 $\\pm$0.43 \\\\\n",
      "distilbert-base-cased & 62.55 $\\pm$0.23 & 61.69 $\\pm$0.16 & 55.92 $\\pm$0.93 & 59.17 $\\pm$0.29 &85.40 $\\pm$0.13 & 83.17 $\\pm$0.09 & 80.32 $\\pm$0.22 & 82.25 $\\pm$0.12 \\\\\n",
      "roberta-base & 65.38 $\\pm$1.91 & 63.27 $\\pm$1.31 & 54.56 $\\pm$0.87 & 60.01 $\\pm$1.10 &85.74 $\\pm$0.26 & 83.26 $\\pm$0.13 & 80.25 $\\pm$0.42 & 82.30 $\\pm$0.19 \\\\\n",
      "xlnet-base-cased & 62.24 $\\pm$0.59 & 62.24 $\\pm$0.61 & 62.31 $\\pm$3.21 & 61.30 $\\pm$1.04 &85.07 $\\pm$0.34 & 84.19 $\\pm$0.61 & 83.50 $\\pm$2.21 & 83.82 $\\pm$1.07 \\\\\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fn_bases = (\"output\", \"output_2\", \"output_4\")\n",
    "# TODO: delete output_2 (same seed as 'output')\n",
    "fn_bases = (\"output\", \"output_4\", \"output_5\", \"output_6\")\n",
    "\n",
    "results = dict()\n",
    "results_map = dict()\n",
    "\n",
    "for fn_base in fn_bases:\n",
    "    fn_base = Path(fn_base)\n",
    "\n",
    "    for fn in sorted(fn_base.iterdir()):\n",
    "        run_name = fn.name\n",
    "        \n",
    "        sfn = fn / \"test_results_same-b.json\"\n",
    "        if not sfn.exists():\n",
    "            print(f\"Skip: {fn}, reason: {sfn.name} missing\")\n",
    "            continue\n",
    "        with (sfn).open(\"r\") as fp:\n",
    "            stats_test = json.load(fp)\n",
    "\n",
    "        parts = run_name.split(\"_\")\n",
    "        model_name, data_name = parts[0].rsplit(\"-\", 1)\n",
    "        seq_len = int(parts[1])\n",
    "        batch_size, acc_steps = parts[2].split(\"-acc\")\n",
    "        batch_size, acc_steps = int(batch_size), int(acc_steps)\n",
    "        try:\n",
    "            num_epoch = int(parts[3])\n",
    "        except Exception as ex:\n",
    "            print(f\"Skip: {fn}, reason: {ex!s}\")\n",
    "            continue\n",
    "        hypers = (model_name, data_name, seq_len, batch_size, acc_steps, num_epoch)\n",
    "\n",
    "        #data.append((run_name, hypers, stats_test))\n",
    "        try:\n",
    "            results[run_name][\"results\"][fn_base.name] = stats_test\n",
    "        except KeyError:\n",
    "            results[run_name] = dict()\n",
    "            results[run_name][\"hypers\"] = hypers\n",
    "            results[run_name][\"results\"] = dict()\n",
    "            results[run_name][\"results\"][fn_base.name] = stats_test\n",
    "        \n",
    "        try:\n",
    "            results_map[(model_name, seq_len, batch_size, acc_steps, num_epoch)].add(run_name)\n",
    "        except KeyError:\n",
    "            results_map[(model_name, seq_len, batch_size, acc_steps, num_epoch)] = {run_name}\n",
    "\n",
    "for run_name, data in results.items():\n",
    "    run_results = data[\"results\"]\n",
    "    \n",
    "    if len(run_results) == 1:\n",
    "        continue\n",
    "\n",
    "    run_acc = np.array([stats[\"eval_acc\"] for stats in run_results.values()])\n",
    "    run_f1 = np.array([stats[\"eval_f1\"] for stats in run_results.values()])\n",
    "    run_pre = np.array([stats[\"eval_class_report\"][\"macro avg\"][\"precision\"] for stats in run_results.values()])\n",
    "    run_rec = np.array([stats[\"eval_class_report\"][\"macro avg\"][\"recall\"] for stats in run_results.values()])\n",
    "\n",
    "    data[\"metrics_raw\"] = (run_pre, run_rec, run_f1, run_acc)\n",
    "\n",
    "    run_acc = np.unique(run_acc)\n",
    "    run_f1 = np.unique(run_f1)\n",
    "    run_pre = np.unique(run_pre)\n",
    "    run_rec = np.unique(run_rec)\n",
    "\n",
    "    data[\"metrics\"] = (run_pre, run_rec, run_f1, run_acc)\n",
    "\n",
    "run_ids = set()\n",
    "for run_name, data in results.items():\n",
    "    (model_name, data_name, seq_len, batch_size, acc_steps, num_epoch) = data[\"hypers\"]\n",
    "    run_id = (model_name, seq_len, batch_size, acc_steps, num_epoch)\n",
    "    runs = results_map[run_id]\n",
    "    if len(runs) != 2:\n",
    "        continue\n",
    "    \n",
    "    run_ids.add(run_id)\n",
    "\n",
    "run_ids = sorted(run_ids)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print()\n",
    "\n",
    "# dump list of each run metric\n",
    "for run_name, data in results.items():\n",
    "    if \"metrics\" not in data:\n",
    "        continue\n",
    "    \n",
    "    (run_pre, run_rec, run_f1, run_acc) = data[\"metrics\"]\n",
    "\n",
    "    print(run_name)\n",
    "    print(f\"  acc {run_acc} {np.mean(run_acc)*100:05.02f} {np.std(run_acc)*100:05.02f}\")\n",
    "    print(f\"  f1  {run_f1 } {np.mean(run_f1 )*100:05.02f} {np.std(run_f1 )*100:05.02f}\")\n",
    "    print(f\"  pre {run_pre} {np.mean(run_pre)*100:05.02f} {np.std(run_pre)*100:05.02f}\")\n",
    "    print(f\"  rec {run_rec} {np.mean(run_rec)*100:05.02f} {np.std(run_rec)*100:05.02f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# print avg: mean + std. dev\n",
    "for run_name, data in results.items():\n",
    "    if len(data[\"results\"]) == 1:\n",
    "        continue\n",
    "    if \"metrics\" not in data:\n",
    "        continue\n",
    "\n",
    "    (model_name, data_name, *_) = data[\"hypers\"]\n",
    "    (run_pre, run_rec, run_f1, run_acc) = data[\"metrics\"]\n",
    "\n",
    "    print(\n",
    "        f\"{model_name} & \"\n",
    "        f\"{data_name} & \"\n",
    "        f\"{np.mean(run_pre)*100:05.02f} $\\\\pm${np.std(run_pre)*100:.02f} & \"\n",
    "        f\"{np.mean(run_rec)*100:05.02f} $\\\\pm${np.std(run_rec)*100:.02f} & \"\n",
    "        f\"{np.mean(run_f1 )*100:05.02f} $\\\\pm${np.std(run_f1 )*100:.02f} & \"\n",
    "        f\"{np.mean(run_acc)*100:05.02f} $\\\\pm${np.std(run_acc)*100:.02f} \\\\\\\\\"\n",
    "    )\n",
    "\n",
    "print()\n",
    "\n",
    "# print latex short\n",
    "for run_name, data in results.items():\n",
    "    if len(data[\"results\"]) == 1:\n",
    "        continue\n",
    "    if \"metrics\" not in data:\n",
    "        continue\n",
    "\n",
    "    (model_name, data_name, *_) = data[\"hypers\"]\n",
    "    (run_pre, run_rec, run_f1, run_acc) = data[\"metrics\"]\n",
    "\n",
    "    print(\n",
    "        f\"{model_name} & \"\n",
    "        f\"{data_name} & \"\n",
    "        f\"{np.mean(run_acc)*100:05.02f} ({np.mean(run_f1 )*100:05.02f}) \\\\\\\\\"\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print()\n",
    "\n",
    "# print latex, combined cross+within results, mean+stddev\n",
    "for run_id in run_ids:\n",
    "    runs = results_map[run_id]\n",
    "    cross_data = results[[r for r in runs if \"-cross_\" in r][0]]\n",
    "    within_data = results[[r for r in runs if \"-within_\" in r][0]]\n",
    "    (model_name, seq_len, batch_size, acc_steps, num_epoch) = run_id\n",
    "\n",
    "    if \"metrics\" not in cross_data or \"metrics\" not in within_data:\n",
    "        #print(f\"Skip: {run_id}, reason: no metrics pre-computed\")\n",
    "        continue\n",
    "\n",
    "    (cross_run_pre, cross_run_rec, cross_run_f1, cross_run_acc) = cross_data[\"metrics\"]\n",
    "    (within_run_pre, within_run_rec, within_run_f1, within_run_acc) = within_data[\"metrics\"]\n",
    "\n",
    "    print(\n",
    "        f\"{model_name} & \"\n",
    "        f\"{np.mean(cross_run_pre)*100:05.02f} $\\\\pm${np.std(cross_run_pre)*100:.02f} & \"\n",
    "        f\"{np.mean(cross_run_rec)*100:05.02f} $\\\\pm${np.std(cross_run_rec)*100:.02f} & \"\n",
    "        f\"{np.mean(cross_run_f1 )*100:05.02f} $\\\\pm${np.std(cross_run_f1 )*100:.02f} & \"\n",
    "        f\"{np.mean(cross_run_acc)*100:05.02f} $\\\\pm${np.std(cross_run_acc)*100:.02f} &\"\n",
    "        f\"{np.mean(within_run_pre)*100:05.02f} $\\\\pm${np.std(within_run_pre)*100:.02f} & \"\n",
    "        f\"{np.mean(within_run_rec)*100:05.02f} $\\\\pm${np.std(within_run_rec)*100:.02f} & \"\n",
    "        f\"{np.mean(within_run_f1 )*100:05.02f} $\\\\pm${np.std(within_run_f1 )*100:.02f} & \"\n",
    "        f\"{np.mean(within_run_acc)*100:05.02f} $\\\\pm${np.std(within_run_acc)*100:.02f} \\\\\\\\\"\n",
    "    )\n",
    "\n",
    "#pprint(results)\n",
    "#pprint(results_map)\n",
    "#pprint(run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ignore\n",
    "\n",
    "\n",
    "data = sorted(data, key=lambda x: x[2][\"eval_acc\"], reverse=True)\n",
    "\n",
    "\n",
    "for run_name, stats_eval, stats_test in data:\n",
    "    print(run_name)\n",
    "    print(f\"  eval: {stats_eval['eval_acc'] * 100:.2f} ({stats_eval['eval_f1'] * 100:.2f})\")\n",
    "    print(f\"  test: {stats_test['eval_acc'] * 100:.2f} ({stats_test['eval_f1'] * 100:.2f})\")\n",
    "\n",
    "    parts = run_name.split(\"_\")\n",
    "    model_name, data_name = parts[0].rsplit(\"-\", 1)\n",
    "    seq_len = int(parts[1])\n",
    "    batch_size, acc_steps = parts[2].split(\"-acc\")\n",
    "    batch_size, acc_steps = int(batch_size), int(acc_steps)\n",
    "    num_epoch = int(parts[3])\n",
    "    \n",
    "    if data_name not in (\"within\", \"cross\"):\n",
    "        print(f\"### Unknown dataset! Run: {run_name}, supposed data: {data_name} ###\")\n",
    "        continue\n",
    "\n",
    "    data.append((run_name, model_name, data_name, seq_len, batch_size, acc_steps, num_epoch))\n",
    "\n",
    "metrics = dict()\n",
    "\n",
    "for run_name, model_name, data_name, seq_len, batch_size, acc_steps, num_epoch in data:\n",
    "    fn_preds = Path(f\"./output_emnlp21/{run_name}/pred_results_same-b.txt\")\n",
    "    with fn_preds.open(\"r\") as fp:\n",
    "        fp.readline()\n",
    "        pred_data = [line.rstrip().split(\"\\t\") for line in fp]\n",
    "    pred_data = [(int(id_), int(label)) for id_, label in pred_data]\n",
    "    df_preds = pd.DataFrame.from_records(pred_data, columns=[\"id\", \"label\"], index=\"id\")\n",
    "\n",
    "    df_gold = within_test_df if data_name == \"within\" else cross_test_df\n",
    "\n",
    "    labels_truth = df_gold[\"is_same_side\"].astype(\"bool\").to_numpy()\n",
    "    label_preds = df_preds[\"label\"].astype(\"bool\").to_numpy()\n",
    "\n",
    "    metrics[run_name] = {\n",
    "        \"precision\": precision_score(labels_truth, label_preds, average=\"binary\"),\n",
    "        \"recall\": recall_score(labels_truth, label_preds, average=\"binary\"),\n",
    "        \"f1\": f1_score(labels_truth, label_preds, average=\"binary\"),\n",
    "        \"accuracy\": accuracy_score(labels_truth, label_preds),\n",
    "    }\n",
    "\n",
    "pad_length = [max(len(str(x[i])) for x in data) for i in range(len(data[0]))]\n",
    "\n",
    "for task, subdata in (\n",
    "    (\"within\", [x for x in data if x[2] == \"within\"]),\n",
    "    (\"cross\", [x for x in data if x[2] == \"cross\"])\n",
    "):\n",
    "    print()\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Task: {task.upper()}\")\n",
    "    print(\"-\" * 30)\n",
    "    for run_name, model_name, data_name, seq_len, batch_size, acc_steps, num_epoch in subdata:\n",
    "        run_metric = metrics[run_name]\n",
    "\n",
    "        print(\n",
    "            # model_name, data_name, seq_len\n",
    "            f\"{model_name:<{pad_length[1]}}\"\n",
    "            #f\"  {data_name:<{pad_length[2]}}\"\n",
    "            f\"  {seq_len:>{pad_length[3]}}\"\n",
    "            f\"  |  {run_metric['precision'] * 100:>6.02f}%\"\n",
    "            f\" {run_metric['recall'] * 100:>6.02f}%\"\n",
    "            f\" {run_metric['f1'] * 100:>6.02f}%\"\n",
    "            f\" {run_metric['accuracy'] * 100:>6.02f}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6057 data_raw/argmining/ground-truth/cross-topics-ground-truth-subset.csv\n",
      "     253 data_raw/argmining/ground-truth/within-topics-ground-truth-subset.csv\n",
      "    6310 total\n",
      "\n",
      "    6164 data_raw/argmining/cross/test.csv\n",
      "    3553 data_raw/argmining/within/test.csv\n",
      "    9717 total\n"
     ]
    }
   ],
   "source": [
    "! wc -l data_raw/argmining/ground-truth/*.csv\n",
    "print()\n",
    "! wc -l data_raw/argmining/*/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### ?\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

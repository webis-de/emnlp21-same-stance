{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset preparation - SameStance (Webis)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import Timer\n",
    "\n",
    "# make tqdm jupyter friendly\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "# for .progress_apply() we have to hack it like this?\n",
    "tqdm().pandas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2021 (new data)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data train/dev/test (2021)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_data_path = \"data/data_split.pkl\"\n",
    "\n",
    "with open(fn_data_path, \"rb\") as fp:\n",
    "    cross_train = pickle.load(fp)\n",
    "    cross_dev = pickle.load(fp)\n",
    "    cross_test = pickle.load(fp)   \n",
    "    within_train = pickle.load(fp)\n",
    "    within_dev = pickle.load(fp)\n",
    "    within_test = pickle.load(fp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# argument statistics\n",
    "if False:\n",
    "    print(\"pairs\")\n",
    "    print(f\"cross:  {len(cross_train):,d} / {len(cross_dev):,d} / {len(cross_test):,d}\")\n",
    "    print(f\"within: {len(within_train):,d} / {len(within_dev):,d} / {len(within_test):,d}\")\n",
    "\n",
    "    cross_train_args = len(set([i.split(\"-\", 1)[0] for i in sorted(cross_train[\"argument1_id\"])] + [i.split(\"-\", 1)[0] for i in sorted(cross_train[\"argument2_id\"])]))\n",
    "    cross_dev_args = len(set([i.split(\"-\", 1)[0] for i in sorted(cross_dev[\"argument1_id\"])] + [i.split(\"-\", 1)[0] for i in sorted(cross_dev[\"argument2_id\"])]))\n",
    "    cross_test_args = len(set([i.split(\"-\", 1)[0] for i in sorted(cross_test[\"argument1_id\"])] + [i.split(\"-\", 1)[0] for i in sorted(cross_test[\"argument2_id\"])]))\n",
    "    within_train_args = len(set([i.split(\"-\", 1)[0] for i in sorted(within_train[\"argument1_id\"])] + [i.split(\"-\", 1)[0] for i in sorted(within_train[\"argument2_id\"])]))\n",
    "    within_dev_args = len(set([i.split(\"-\", 1)[0] for i in sorted(within_dev[\"argument1_id\"])] + [i.split(\"-\", 1)[0] for i in sorted(within_dev[\"argument2_id\"])]))\n",
    "    within_test_args = len(set([i.split(\"-\", 1)[0] for i in sorted(within_test[\"argument1_id\"])] + [i.split(\"-\", 1)[0] for i in sorted(within_test[\"argument2_id\"])]))\n",
    "\n",
    "    print(\"argument ids (unique)\")\n",
    "    print(f\"cross:  {cross_train_args:,d} / {cross_dev_args:,d} / {cross_test_args:,d}\")\n",
    "    print(f\"within: {within_train_args:,d} / {within_dev_args:,d} / {within_test_args:,d}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# argmining --> argmining\n",
    "data_argmining_within_tdt_path = Path(\"data/argmining/within\")\n",
    "data_argmining_cross_tdt_path = Path(\"data/argmining/cross\")\n",
    "\n",
    "if not data_argmining_within_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_within_tdt_path}\")\n",
    "    data_argmining_within_tdt_path.mkdir(parents=True)\n",
    "\n",
    "if not data_argmining_cross_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_cross_tdt_path}\")\n",
    "    data_argmining_cross_tdt_path.mkdir(parents=True)\n",
    "\n",
    "fn_within_train_tsv = data_argmining_within_tdt_path / \"train.tsv\"\n",
    "fn_within_dev_tsv = data_argmining_within_tdt_path / \"dev.tsv\"\n",
    "fn_within_test_tsv = data_argmining_within_tdt_path / \"test.tsv\"\n",
    "\n",
    "fn_cross_train_tsv = data_argmining_cross_tdt_path / \"train.tsv\"\n",
    "fn_cross_dev_tsv = data_argmining_cross_tdt_path / \"dev.tsv\"\n",
    "fn_cross_test_tsv = data_argmining_cross_tdt_path / \"test.tsv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with fn_within_train_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(within_train.itertuples(), desc=\"train (within)\", total=len(within_train)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "\n",
    "with fn_within_dev_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(within_dev.itertuples(), desc=\"dev (within)\", total=len(within_dev)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "        \n",
    "with fn_within_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(within_test.itertuples(), desc=\"test pred (within)\", total=len(within_test)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "        \n",
    "with fn_cross_train_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(cross_train.itertuples(), desc=\"train (cross)\", total=len(cross_train)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "\n",
    "with fn_cross_dev_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(cross_dev.itertuples(), desc=\"dev (cross)\", total=len(cross_dev)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "\n",
    "with fn_cross_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(cross_test.itertuples(), desc=\"test pred (cross)\", total=len(cross_test)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# symlink pred.tsv\n",
    "! ln -s test.tsv {data_argmining_within_tdt_path}/pred.tsv\n",
    "! ln -s test.tsv {data_argmining_cross_tdt_path}/pred.tsv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "just write within train data (combined train/dev, separate test) for artificial dataset analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# argmining --> argmining_tt\n",
    "\n",
    "# TODO: ...\n",
    "within_train = pd.concat([within_train, within_dev], ignore_index=True)\n",
    "\n",
    "data_argmining_within_tdt_path = Path(\"data/argmining_tt/within\")\n",
    "\n",
    "if not data_argmining_within_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_within_tdt_path}\")\n",
    "    data_argmining_within_tdt_path.mkdir(parents=True)\n",
    "\n",
    "fn_within_train_tsv = data_argmining_within_tdt_path / \"train.tsv\"\n",
    "fn_within_test_tsv = data_argmining_within_tdt_path / \"test.tsv\"\n",
    "\n",
    "\n",
    "with fn_within_train_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(within_train.itertuples(), desc=\"train (within)\", total=len(within_train)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "        \n",
    "with fn_within_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(within_test.itertuples(), desc=\"test pred (within)\", total=len(within_test)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground-truth dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm().pandas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data pred (2021)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_ground_truth = \"data_raw/argmining/ground-truth/{}-topics-ground-truth-subset.csv\"\n",
    "\n",
    "within_test_df = pd.read_csv(fn_ground_truth.format(\"within\"), index_col=\"id\")\n",
    "cross_test_df = pd.read_csv(fn_ground_truth.format(\"cross\"), index_col=\"id\")\n",
    "\n",
    "within_test_df[\"tag\"] = within_test_df[\"subject\"]\n",
    "cross_test_df[\"tag\"] = cross_test_df[\"subject\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_ground_truth_p = \"data/ground_truth.p\"\n",
    "\n",
    "with open(fn_ground_truth_p, \"wb\") as fp:\n",
    "    pickle.dump(within_test_df, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(cross_test_df, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# argmining --> argmining\n",
    "data_argmining_groundtruth_tdt_path = Path(\"data/argmining/ground_truth\")\n",
    "data_argmining_groundtruth_within_tdt_path = data_argmining_groundtruth_tdt_path / \"within\"\n",
    "data_argmining_groundtruth_cross_tdt_path = data_argmining_groundtruth_tdt_path / \"cross\"\n",
    "\n",
    "if not data_argmining_groundtruth_within_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_groundtruth_within_tdt_path}\")\n",
    "    data_argmining_groundtruth_within_tdt_path.mkdir(parents=True)\n",
    "if not data_argmining_groundtruth_cross_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_groundtruth_cross_tdt_path}\")\n",
    "    data_argmining_groundtruth_cross_tdt_path.mkdir(parents=True)\n",
    "\n",
    "fn_gold_within_test_tsv = data_argmining_groundtruth_within_tdt_path / \"test.tsv\"\n",
    "fn_gold_cross_test_tsv = data_argmining_groundtruth_cross_tdt_path / \"test.tsv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with fn_gold_within_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(within_test_df.itertuples(), desc=\"pred/test (within)\", total=len(within_test_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "\n",
    "with fn_gold_cross_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(cross_test_df.itertuples(), desc=\"pred/test (cross)\", total=len(cross_test_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# symlink pred.tsv\n",
    "! ln -s test.tsv {data_argmining_groundtruth_within_tdt_path}/pred.tsv\n",
    "! ln -s test.tsv {data_argmining_groundtruth_cross_tdt_path}/pred.tsv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Artificial dataset\n",
    "\n",
    "see `data/` folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "tqdm().pandas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data pred (2021)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_art_eval = \"data/artificial_evalset.tsv\"\n",
    "\n",
    "artificial_evalset_df = pd.read_csv(fn_art_eval, sep=\"\\t\", index_col=None)\n",
    "\n",
    "new_cols = artificial_evalset_df.columns.to_list()\n",
    "new_cols[2] = \"type\"\n",
    "artificial_evalset_df.columns = new_cols\n",
    "\n",
    "def fix_cols(row):\n",
    "    row[\"argument1_id\"] = row[\"arg_id\"]\n",
    "    row[\"argument2_id\"] = \"{}-{}\".format(row[\"arg_id\"], row[\"type\"])\n",
    "    row[\"topic\"] = \"gay marriage\"\n",
    "    row[\"tag\"] = \"gay marriage\"\n",
    "    return row\n",
    "\n",
    "artificial_evalset_df = artificial_evalset_df.progress_apply(fix_cols, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_art_eval_p = \"data/artificial_evalset.p\"\n",
    "\n",
    "with open(fn_art_eval_p, \"wb\") as fp:\n",
    "    pickle.dump(artificial_evalset_df, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# argmining --> argmining\n",
    "data_argmining_art_tdt_path = Path(\"data/argmining/artificial\")\n",
    "\n",
    "if not data_argmining_art_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_art_tdt_path}\")\n",
    "    data_argmining_art_tdt_path.mkdir(parents=True)\n",
    "\n",
    "fn_art_test_tsv = data_argmining_art_tdt_path / \"test.tsv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with fn_art_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(artificial_evalset_df.itertuples(), desc=\"pred/test (within, gay)\", total=len(artificial_evalset_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# symlink pred.tsv\n",
    "! ln -s test.tsv {data_argmining_art_tdt_path}/pred.tsv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_cross_path = \"data_raw/argmining/cross/{}.csv\"\n",
    "data_within_path = \"data_raw/argmining/within/{}.csv\"\n",
    "new_within_test = \"data_raw/argmining/within/test.csv\"\n",
    "\n",
    "names_columns_X = [\"argument1\", \"argument2\", \"argument1_id\", \"argument2_id\", \"topic\"]\n",
    "names_columns_y = [\"is_same_side\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load data webis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_official_data_cross():\n",
    "    with Timer(\"read S3C cross train/dev\"):\n",
    "        cross_traindev_df = pd.read_csv(\n",
    "            data_cross_path.format(\"training\"),\n",
    "            quotechar='\"',\n",
    "            quoting=csv.QUOTE_ALL,\n",
    "            encoding=\"utf-8\",\n",
    "            escapechar=\"\\\\\",\n",
    "            doublequote=False,\n",
    "            index_col=\"id\",\n",
    "        )\n",
    "        cross_test_df = pd.read_csv(data_cross_path.format(\"test\"), index_col=\"id\")\n",
    "\n",
    "    return cross_traindev_df, cross_test_df\n",
    "\n",
    "\n",
    "def load_official_data_within():\n",
    "    with Timer(\"read S3C within train/dev\"):\n",
    "        within_traindev_df = pd.read_csv(\n",
    "            data_within_path.format(\"training\"),\n",
    "            quotechar='\"',\n",
    "            quoting=csv.QUOTE_ALL,\n",
    "            encoding=\"utf-8\",\n",
    "            escapechar=\"\\\\\",\n",
    "            doublequote=False,\n",
    "            index_col=\"id\",\n",
    "        )\n",
    "        # within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "        #                              quotechar='\"',\n",
    "        #                              quoting=csv.QUOTE_ALL,\n",
    "        #                              encoding='utf-8',\n",
    "        #                              escapechar='\\\\',\n",
    "        #                              doublequote=True,  # <-- change, \"\" as quote escape in text?\n",
    "        #                              index_col='id')\n",
    "        within_test_df = pd.read_csv(data_within_path.format(\"test\"), index_col=\"id\")\n",
    "        new_within_test_df = pd.read_csv(new_within_test, index_col=\"id\")\n",
    "\n",
    "    return within_traindev_df, new_within_test_df\n",
    "\n",
    "\n",
    "def load_official_data(task=\"within\"):\n",
    "    if task == \"within\":\n",
    "        return load_official_data_within()\n",
    "    if task == \"cross\":\n",
    "        return load_official_data_cross()\n",
    "    raise Exception(\"Unknown dataset!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def add_tag(df):\n",
    "    # Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "    def _add_tag(row):\n",
    "        title = row['topic'].lower().strip()\n",
    "        if \"abortion\" in title:\n",
    "            row['tag'] = 'abortion'\n",
    "        elif \"gay marriage\"  in title:\n",
    "            row['tag'] = 'gay marriage'\n",
    "        else:\n",
    "            row['tag'] = 'NA'\n",
    "        return row\n",
    "    \n",
    "    return df.progress_apply(_add_tag, axis=1)\n",
    "\n",
    "\n",
    "def load_and_prepare_official_data(task=\"within\"):\n",
    "    traindev_df, test_df = load_official_data(task=task)\n",
    "    \n",
    "    with Timer(\"tag {} train/dev\".format(task)):\n",
    "        traindev_df = add_tag(traindev_df)\n",
    "        test_df = add_tag(test_df)\n",
    "\n",
    "    return traindev_df, test_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Split train/dev"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train dev set - 70% 30%\n",
    "def get_train_test_sets(df, ratio=0.30, random_state=42):\n",
    "    X = df[names_columns_X]\n",
    "    y = df[names_columns_y]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def split_within_by_topic(within_df):\n",
    "    groups = within_df.groupby(['tag'])\n",
    "    abortion_df = groups.get_group(\"abortion\")\n",
    "    gay_marriage_df = groups.get_group(\"gay marriage\")\n",
    "    \n",
    "    X_abortion = abortion_df[names_columns_X]\n",
    "    y_abortion = abortion_df[names_columns_y]\n",
    "    X_gay_marriage = gay_marriage_df[names_columns_X]\n",
    "    y_gay_marriage = gay_marriage_df[names_columns_y]\n",
    "    \n",
    "    return X_abortion, X_gay_marriage, y_abortion, y_gay_marriage"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "within_traindev_df, within_test_df = load_and_prepare_official_data(\"within\")\n",
    "cross_traindev_df, cross_test_df = load_and_prepare_official_data(\"cross\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_argmining_within_tdt_path = Path(\"data/argmining/within\")\n",
    "data_argmining_cross_tdt_path = Path(\"data/argmining/cross\")\n",
    "\n",
    "if not data_argmining_within_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_within_tdt_path}\")\n",
    "    data_argmining_within_tdt_path.mkdir(parents=True)\n",
    "\n",
    "if not data_argmining_cross_tdt_path.exists():\n",
    "    print(f\"Create dir: {data_argmining_cross_tdt_path}\")\n",
    "    data_argmining_cross_tdt_path.mkdir(parents=True)\n",
    "\n",
    "fn_within_train_tsv = data_argmining_within_tdt_path / \"train.tsv\"\n",
    "fn_within_dev_tsv = data_argmining_within_tdt_path / \"dev.tsv\"\n",
    "fn_within_test_tsv = data_argmining_within_tdt_path / \"pred.tsv\"\n",
    "\n",
    "fn_cross_train_tsv = data_argmining_cross_tdt_path / \"train.tsv\"\n",
    "fn_cross_dev_tsv = data_argmining_cross_tdt_path / \"dev.tsv\"\n",
    "fn_cross_test_tsv = data_argmining_cross_tdt_path / \"pred.tsv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.20, random_state=42)\n",
    "\n",
    "train_df = X_train.merge(y_train, left_index=True, right_index=True)\n",
    "dev_df = X_dev.merge(y_dev, left_index=True, right_index=True)\n",
    "\n",
    "with fn_within_train_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(train_df.itertuples(), desc=\"train (within)\", total=len(train_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "\n",
    "with fn_within_dev_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(dev_df.itertuples(), desc=\"dev (within)\", total=len(dev_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.20, random_state=42)\n",
    "\n",
    "train_df = X_train.merge(y_train, left_index=True, right_index=True)\n",
    "dev_df = X_dev.merge(y_dev, left_index=True, right_index=True)\n",
    "\n",
    "with fn_cross_train_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(train_df.itertuples(), desc=\"train (cross)\", total=len(train_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "\n",
    "with fn_cross_dev_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(dev_df.itertuples(), desc=\"dev (cross)\", total=len(dev_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = \"1\" if str(row.is_same_side) == \"True\" else \"0\"\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with fn_within_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(within_test_df.itertuples(), desc=\"test pred (within)\", total=len(within_test_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = -1\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")\n",
    "\n",
    "with fn_cross_test_tsv.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    for row in tqdm(cross_test_df.itertuples(), desc=\"test pred (cross)\", total=len(cross_test_df)):\n",
    "        text1 = row.argument1.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        text2 = row.argument2.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        label = -1\n",
    "        fp.write(f\"\"\"{row.Index}\\t{text1}\\t{text2}\\t{label}\\n\"\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# symlink pred.tsv\n",
    "! ln -s test.tsv {data_argmining_within_tdt_path}/pred.tsv\n",
    "! ln -s test.tsv {data_argmining_cross_tdt_path}/pred.tsv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"bert-base-cased\"\n",
    "#model_name = \"distilroberta-base\"\n",
    "#model_name = \"distilbert-base-cased\"\n",
    "model_name = \"albert-base-v2\"\n",
    "#model_name = \"albert-base-v1\"\n",
    "#model_name = \"roberta-base\"\n",
    "\n",
    "#model_name = \"bert-large-cased\"\n",
    "#model_name = \"albert-large-v2\"\n",
    "\n",
    "model_name = \"xlnet-base-cased\"\n",
    "#model_name = \"reformer-enwik8\"\n",
    "#model_name = \"funnel-transformer/small\"\n",
    "#model_name = \"squeezebert/squeezebert-uncased\"\n",
    "#model_name = \"facebook/bart-base\"\n",
    "\n",
    "#model_name = \"google/electra-small-discriminator\"\n",
    "#model_name = \"google/electra-base-discriminator\"\n",
    "#model_name = \"sentence-transformers/stsb-distilbert-base\"\n",
    "#model_name = \"sentence-transformers/quora-distilbert-base\"\n",
    "#model_name = \"sentence-transformers/bert-base-nli-mean-tokens\"\n",
    "\n",
    "data_name = \"cross\"\n",
    "data_name = \"within\"\n",
    "\n",
    "seq_len = 512\n",
    "batch_size = 4\n",
    "acc_steps = 64\n",
    "num_epoch = 3\n",
    "cuda_devs = \"1\"\n",
    "\n",
    "run_name = f\"{model_name.replace('/', '-')}-{data_name}_{seq_len}_{batch_size}-acc{acc_steps}_{num_epoch}\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create folder for logging\n",
    "log_dir = f\"./output_5_logs/{run_name}\"\n",
    "! mkdir -p {log_dir}\n",
    "\n",
    "! \\\n",
    "    PYTHONASYNCIODEBUG=1 \\\n",
    "    HF_MLFLOW_LOG_ARTIFACTS=TRUE \\\n",
    "    MLFLOW_EXPERIMENT_NAME=same-stance \\\n",
    "    CUDA_VISIBLE_DEVICES={cuda_devs} \\\n",
    "    python trainer.py \\\n",
    "    --do_train --do_eval --do_test --do_pred \\\n",
    "    --seed 743 \\\n",
    "    --model_name_or_path {model_name} \\\n",
    "    --task_name same-b \\\n",
    "    --data_dir ./data/argmining/{data_name} \\\n",
    "    --output_dir ./output_5/{run_name} \\\n",
    "    --run_name {run_name} \\\n",
    "    --per_device_eval_batch_size {batch_size} \\\n",
    "    --per_device_train_batch_size {batch_size} \\\n",
    "    --gradient_accumulation_steps {acc_steps} \\\n",
    "    --eval_steps 128 \\\n",
    "    --logging_steps 2000 \\\n",
    "    --save_steps 2000 \\\n",
    "    --save_total_limit 4 \\\n",
    "    --num_train_epochs {num_epoch} \\\n",
    "    --max_seq_length {seq_len} \\\n",
    "    --evaluation_strategy steps \\\n",
    "    --load_best_model_at_end \\\n",
    "    > >(tee -a {log_dir}/stdout.log) \\\n",
    "    2> >(tee -a {log_dir}/stderr.log >&2)\n",
    "\n",
    "# --overwrite_output_dir \\\n",
    "# --overwrite_cache \\\n",
    "# --eval_steps 100 (same as --logging_steps)\n",
    "# --load_best_model_at_end \\\n",
    "# --max_steps 1000 \\\n",
    "# --gradient_accumulation_steps {acc_steps} \\"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if False:\n",
    "\n",
    "    # create folder for logging\n",
    "    ! mkdir -p ./output_logs/{run_name}\"-(2)\"\n",
    "\n",
    "    ! \\\n",
    "        HF_MLFLOW_LOG_ARTIFACTS=TRUE \\\n",
    "        MLFLOW_EXPERIMENT_NAME=same-stance \\\n",
    "        CUDA_VISIBLE_DEVICES={cuda_devs} \\\n",
    "        python trainer.py \\\n",
    "        --do_eval \\\n",
    "        --model_name_or_path ./output/{run_name} \\\n",
    "        --task_name same-b \\\n",
    "        --data_dir ./data/argmining/{data_name} \\\n",
    "        --output_dir ./output/{run_name}\"-(2)\" \\\n",
    "        --run_name {run_name} \\\n",
    "        --per_device_eval_batch_size {batch_size} \\\n",
    "        --gradient_accumulation_steps {acc_steps} \\\n",
    "        --logging_steps 100 \\\n",
    "        --max_seq_length {seq_len} \\\n",
    "        > >(tee -a ./output_logs/{run_name}\"-(2)\"/stdout.log) \\\n",
    "        2> >(tee -a ./output_logs/{run_name}\"-(2)\"/stderr.log >&2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Run artificial dataset prediction\n",
    "\n",
    "--> _run_name_ and params from above"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train model\n",
    "\n",
    "load_name = f\"./output/{run_name}\"\n",
    "run_name = f\"{run_name}-art\"\n",
    "log_dir = f\"./output_logs/{run_name}\"\n",
    "\n",
    "# create folder for logging\n",
    "! mkdir -p {log_dir}\n",
    "\n",
    "! \\\n",
    "    PYTHONASYNCIODEBUG=1 \\\n",
    "    HF_MLFLOW_LOG_ARTIFACTS=TRUE \\\n",
    "    MLFLOW_EXPERIMENT_NAME=same-stance \\\n",
    "    CUDA_VISIBLE_DEVICES={cuda_devs} \\\n",
    "    python trainer.py \\\n",
    "    --do_train --do_test \\\n",
    "    --model_name_or_path {model_name} \\\n",
    "    --task_name same-b \\\n",
    "    --data_dir ./data/argmining_tt/{data_name} \\\n",
    "    --output_dir ./output/{run_name} \\\n",
    "    --run_name {run_name} \\\n",
    "    --per_device_eval_batch_size {batch_size} \\\n",
    "    --per_device_train_batch_size {batch_size} \\\n",
    "    --gradient_accumulation_steps {acc_steps} \\\n",
    "    --logging_steps 1000 \\\n",
    "    --save_steps 1000 \\\n",
    "    --save_total_limit 4 \\\n",
    "    --num_train_epochs {num_epoch} \\\n",
    "    --max_seq_length {seq_len} \\\n",
    "    > >(tee -a ./output_logs/{run_name}/stdout.log) \\\n",
    "    2> >(tee -a ./output_logs/{run_name}/stderr.log >&2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# evaluate\n",
    "\n",
    "load_name = f\"./output/{run_name}\"\n",
    "run_name = f\"{run_name}-art\"\n",
    "log_dir = f\"./output_logs/{run_name}\"\n",
    "\n",
    "# create folder for logging\n",
    "! mkdir -p {log_dir}\n",
    "\n",
    "! \\\n",
    "    HF_MLFLOW_LOG_ARTIFACTS=TRUE \\\n",
    "    MLFLOW_EXPERIMENT_NAME=same-stance \\\n",
    "    CUDA_VISIBLE_DEVICES={cuda_devs} \\\n",
    "    python trainer.py \\\n",
    "    --do_test --do_pred \\\n",
    "    --model_name_or_path {load_name} \\\n",
    "    --task_name same-b \\\n",
    "    --data_dir ./data/argmining/artificial \\\n",
    "    --output_dir ./output/{run_name} \\\n",
    "    --overwrite_output_dir \\\n",
    "    --overwrite_cache \\\n",
    "    --run_name {run_name} \\\n",
    "    --max_seq_length {seq_len} \\\n",
    "    --per_device_eval_batch_size {batch_size} \\\n",
    "    --logging_steps 100 \\\n",
    "    > >(tee -a {log_dir}/stdout.log) \\\n",
    "    2> >(tee -a {log_dir}/stderr.log >&2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn.metrics as sklm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class IdentityEstimator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.is_fitted_ = True\n",
    "        self.classes_ = [0, 1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X\n",
    "\n",
    "estim = IdentityEstimator()\n",
    "\n",
    "def plot_conf_mat(true_labels, predicted_labels, label_names, plot_title, fname=None):\n",
    "    matplotlib.rcParams.update({'font.size': 30})  # 20\n",
    "    disp = sklm.plot_confusion_matrix(estim, np.array(predicted_labels), true_labels,\n",
    "                                      cmap=plt.cm.Blues, values_format = '.5g',\n",
    "                                      display_labels=label_names)\n",
    "    disp.ax_.set_title(plot_title)\n",
    "    if fname is not None:\n",
    "        plt.savefig(fname, transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_results = Path(\"output/albert-base-v2-within_512_8-acc64_3-art-art/pred_results_same-b.txt\")\n",
    "\n",
    "preds = list()\n",
    "with fn_results.open(\"r\") as fp:\n",
    "    fp.readline()\n",
    "    preds = [int(l.split(\"\\t\")[1]) for l in fp]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NOTE: load artificial_evalset_df with code above\n",
    "if True:\n",
    "    fn_art_eval_p = \"data/artificial_evalset.p\"\n",
    "\n",
    "    with open(fn_art_eval_p, \"rb\") as fp:\n",
    "        artificial_evalset_df = pickle.load(fp)\n",
    "\n",
    "preds = pd.Series(preds, dtype=bool, name=\"predictions\")\n",
    "artificial_evalset_df = artificial_evalset_df.join(preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "true_labels = artificial_evalset_df[\"is_same_side\"].to_list()\n",
    "pred_labels = artificial_evalset_df[\"predictions\"].to_list()\n",
    "\n",
    "filter_neg = artificial_evalset_df[\"type\"].str.endswith(\"NEG\")\n",
    "\n",
    "art_df_neg = artificial_evalset_df[filter_neg]\n",
    "true_labels_n = art_df_neg[\"is_same_side\"].to_list()\n",
    "pred_labels_n = art_df_neg[\"predictions\"].to_list()\n",
    "\n",
    "art_df_no_neg = artificial_evalset_df[~filter_neg]\n",
    "true_labels_no_n = art_df_no_neg[\"is_same_side\"].to_list()\n",
    "pred_labels_no_n = art_df_no_neg[\"predictions\"].to_list()\n",
    "\n",
    "art_df_para = artificial_evalset_df[artificial_evalset_df[\"type\"].str.startswith(\"CON\")]\n",
    "true_labels_para = art_df_para[\"is_same_side\"].to_list()\n",
    "pred_labels_para = art_df_para[\"predictions\"].to_list()\n",
    "\n",
    "art_df_arg = artificial_evalset_df[artificial_evalset_df[\"type\"].str.startswith(\"DIFF\")]\n",
    "true_labels_arg = art_df_arg[\"is_same_side\"].to_list()\n",
    "pred_labels_arg = art_df_arg[\"predictions\"].to_list()\n",
    "\n",
    "art_df_cit = artificial_evalset_df[artificial_evalset_df[\"type\"].str.startswith(\"CIT\")]\n",
    "true_labels_cit = art_df_cit[\"is_same_side\"].to_list()\n",
    "pred_labels_cit = art_df_cit[\"predictions\"].to_list()\n",
    "\n",
    "fig_prefix = \"fig_1_\"\n",
    "fig_fmt = \".pdf\"  # png/pdf\n",
    "plot_conf_mat(true_labels, pred_labels, ['0', '1'], 'ALL', fname=f\"{fig_prefix}all{fig_fmt}\")\n",
    "plot_conf_mat(true_labels_n, pred_labels_n, ['0', '1'], 'w/ negation', fname=f\"{fig_prefix}neg{fig_fmt}\")\n",
    "plot_conf_mat(true_labels_no_n, pred_labels_no_n, ['0', '1'], 'w/o negation', fname=f\"{fig_prefix}noneg{fig_fmt}\")\n",
    "plot_conf_mat(true_labels_para, pred_labels_para, ['0', '1'], 'Paraphrase', fname=f\"{fig_prefix}para{fig_fmt}\")\n",
    "plot_conf_mat(true_labels_arg, pred_labels_arg, ['0', '1'], 'Argument', fname=f\"{fig_prefix}arg{fig_fmt}\") # Diff. Arg.\n",
    "plot_conf_mat(true_labels_cit, pred_labels_cit, ['0', '1'], 'Citation', fname=f\"{fig_prefix}cit{fig_fmt}\") # Reference"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! dbot-message -c .dbot.conf \"Finished \"{run_name}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#! tail -n 10 ./output_logs/{run_name}/stderr.log | dbot-message - -c .dbot.conf --type"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
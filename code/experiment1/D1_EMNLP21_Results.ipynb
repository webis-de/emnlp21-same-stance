{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Same Side Stance Classification - EMNLP2021 - GroundTruth/GoldLabels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "\n",
    "- 3 epochs\n",
    "- accumulation steps: 64\n",
    "- sequence length 128-256-512 with batch sizes from 8-16(12)-32\n",
    "- tasks, within/cross\n",
    "- train/dev/test - 80:10:10 - @gregor\n",
    "\n",
    "See [D1_samestance_base.ipynb](D1_samestance_base.ipynb)  \n",
    "See [D1_Results.ipynb](D1_Results.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result-Matrix\n",
    "\n",
    "- 3 epochs, acc-step: 64\n",
    "\n",
    "```\n",
    "model_name             task    seql  dev-acc (f1)     test-acc (f1)\n",
    "\n",
    "bert-base-uncased      cross   128   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "bert-base-uncased      cross   256   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "bert-base-uncased      cross   512   0.xxxx (0.xxxx)  0.xxxx (0.xxxx) *?\n",
    "bert-base-uncased      within  128   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "bert-base-uncased      within  256   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "bert-base-uncased      within  512   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "\n",
    "bert-base-cased        cross   256   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "bert-base-cased        cross   512   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "bert-base-cased        within  256   0.xxxx (0.xxxx)  0.xxxx (0.xxxx)\n",
    "bert-base-cased        within  512   0.xxxx (0.xxxx)  0.xxxx (0.xxxx) *?\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "! ls -t ./output"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "albert-base-v2-within_512_8-acc64_3-art-art\n",
      "squeezebert-squeezebert-uncased-cross_256_16-acc64_3\n",
      "squeezebert-squeezebert-uncased-cross_512_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-within_512_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-within_256_8-acc64_3\n",
      "albert-base-v2-cross_128_32-acc64_3\n",
      "albert-base-v2-within_128_32-acc64_3\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "distilroberta-base-within_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-cross_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-within_512_8-acc64_3\n",
      "google-electra-small-discriminator-within_512_8-acc64_3\n",
      "google-electra-small-discriminator-cross_512_8-acc64_3\n",
      "google-electra-base-discriminator-cross_512_8-acc64_3\n",
      "google-electra-base-discriminator-within_512_8-acc64_3\n",
      "distilroberta-base-cross_512_8-acc64_3\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "roberta-base-within_512_8-acc64_3\n",
      "bert-base-uncased-within_128_32-acc64_3\n",
      "albert-large-v2-within_256_8-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-cross_256_16-acc64_3\n",
      "albert-base-v2-cross_512_16-acc64_10\n",
      "albert-base-v2-within_512_16-acc64_10\n",
      "bert-base-uncased-within_256_16-acc64_10\n",
      "bert-base-uncased-cross_256_16-acc64_10\n",
      "albert-base-v2-cross_256_16-acc64_10\n",
      "albert-base-v2-within_256_16-acc64_10\n",
      "bert-base-cased-cross_256_16-acc64_3\n",
      "facebook-bart-base-cross_256_16-acc64_3\n",
      "facebook-bart-base-within_256_16-acc64_3\n",
      "xlnet-base-cased-cross_256_8-acc64_3\n",
      "xlnet-base-cased-within_256_8-acc64_3\n",
      "albert-base-v1-within_256_16-acc64_3\n",
      "albert-base-v1-cross_256_16-acc64_3\n",
      "google-electra-small-discriminator-cross_256_16-acc64_3\n",
      "google-electra-base-discriminator-cross_256_16-acc64_3\n",
      "bert-base-uncased-cross_512_8-acc64_3\n",
      "bert-base-uncased-within_512_8-acc64_3\n",
      "bert-base-cased-within_256_16-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-within_256_16-acc64_3\n",
      "sentence-transformers-quora-distilbert-base-within_256_16-acc64_3\n",
      "roberta-base-cross_256_16-acc64_3\n",
      "roberta-base-within_256_16-acc64_3\n",
      "google-electra-base-discriminator-within_256_16-acc64_3\n",
      "google-electra-small-discriminator-within_256_16-acc64_3\n",
      "albert-base-v2-within_256_16-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "distilbert-base-cased-cross_256_16-acc64_3\n",
      "distilroberta-base-within_256_16-acc64_3\n",
      "distilroberta-base-cross_256_16-acc64_3\n",
      "albert-base-v2-cross_256_12-acc64_3\n",
      "albert-base-v2-cross_256_16-acc64_3\n",
      "bert-base-uncased-within_256_16-acc64_3\n",
      "bert-base-uncased-cross_256_16-acc64_3\n",
      "bert-base-uncased-cross_128_32-acc64_3\n",
      "distilbert-base-cased-within_256_32-acc64_3\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "! ls -t ./output_emnlp21"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "albert-base-v2-cross_256_12-acc64_3\n",
      "albert-base-v1-cross_256_16-acc64_3\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "xlnet-base-cased-within_256_8-acc64_3\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "xlnet-base-cased-cross_256_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-within_512_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-within_256_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-cross_512_8-acc64_3\n",
      "squeezebert-squeezebert-uncased-cross_256_16-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-within_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-within_256_16-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-cross_512_8-acc64_3\n",
      "sentence-transformers-stsb-distilbert-base-cross_256_16-acc64_3\n",
      "sentence-transformers-quora-distilbert-base-within_256_16-acc64_3\n",
      "roberta-base-within_512_8-acc64_3\n",
      "roberta-base-within_256_16-acc64_3\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "roberta-base-cross_256_16-acc64_3\n",
      "google-electra-small-discriminator-within_512_8-acc64_3\n",
      "google-electra-small-discriminator-within_256_16-acc64_3\n",
      "google-electra-small-discriminator-cross_512_8-acc64_3\n",
      "google-electra-small-discriminator-cross_256_16-acc64_3\n",
      "google-electra-base-discriminator-within_512_8-acc64_3\n",
      "google-electra-base-discriminator-within_256_16-acc64_3\n",
      "google-electra-base-discriminator-cross_512_8-acc64_3\n",
      "google-electra-base-discriminator-cross_256_16-acc64_3\n",
      "distilroberta-base-within_512_8-acc64_3\n",
      "distilroberta-base-within_256_16-acc64_3\n",
      "distilroberta-base-cross_512_8-acc64_3\n",
      "distilroberta-base-cross_256_16-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "distilbert-base-cased-within_256_32-acc64_3\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-cross_256_16-acc64_3\n",
      "bert-base-uncased-within_512_8-acc64_3\n",
      "bert-base-uncased-within_256_16-acc64_3\n",
      "bert-base-uncased-within_256_16-acc64_10\n",
      "bert-base-uncased-within_128_32-acc64_3\n",
      "bert-base-uncased-cross_512_8-acc64_3\n",
      "bert-base-uncased-cross_256_16-acc64_3\n",
      "bert-base-uncased-cross_256_16-acc64_10\n",
      "bert-base-uncased-cross_128_32-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "bert-base-cased-within_256_16-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "bert-base-cased-cross_256_16-acc64_3\n",
      "albert-large-v2-within_256_8-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "albert-base-v2-within_256_16-acc64_3\n",
      "albert-base-v2-within_256_16-acc64_10\n",
      "albert-base-v2-within_128_32-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "albert-base-v2-cross_256_16-acc64_10\n",
      "albert-base-v2-cross_128_32-acc64_3\n",
      "albert-base-v1-within_256_16-acc64_3\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "! ls -t1 ./output_2\n",
    "print()\n",
    "! ls -t1 ./output_4"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "albert-base-v2-cross_512_8-acc64_3\n",
      "albert-base-v2-within_512_8-acc64_3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "fn_base = Path(\"output\")\n",
    "\n",
    "data = list()\n",
    "for fn in sorted(fn_base.iterdir()):\n",
    "    run_name = fn.name\n",
    "    \n",
    "    sfn = fn / \"eval_results_same-b.json\"\n",
    "    if not sfn.exists():\n",
    "        continue\n",
    "\n",
    "    stats_eval = stats_test = None\n",
    "\n",
    "    data.append((run_name, stats_eval, stats_test))\n",
    "\n",
    "\n",
    "#data = sorted(data, key=lambda x: x[2][\"eval_acc\"], reverse=True)\n",
    "\n",
    "\n",
    "for run_name, stats_eval, stats_test in data:\n",
    "    print(run_name)\n",
    "    #print(f\"  eval: {stats_eval['eval_acc'] * 100:.2f} ({stats_eval['eval_f1'] * 100:.2f})\")\n",
    "    #print(f\"  test: {stats_test['eval_acc'] * 100:.2f} ({stats_test['eval_f1'] * 100:.2f})\")"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "fn_base = Path(\"output_emnlp21\")\n",
    "\n",
    "data = list()\n",
    "for fn in sorted(fn_base.iterdir()):\n",
    "    run_name = fn.name\n",
    "\n",
    "    sfn = fn / \"test_results_same-b.json\"\n",
    "    if not sfn.exists():\n",
    "        continue\n",
    "\n",
    "    with (sfn).open(\"r\") as fp:\n",
    "        stats_test = json.load(fp)\n",
    "\n",
    "    parts = run_name.split(\"_\")\n",
    "    model_name, data_name = parts[0].rsplit(\"-\", 1)\n",
    "    seq_len = int(parts[1])\n",
    "    batch_size, acc_steps = parts[2].split(\"-acc\")\n",
    "    batch_size, acc_steps = int(batch_size), int(acc_steps)\n",
    "    num_epoch = int(parts[3])\n",
    "\n",
    "    if data_name not in (\"within\", \"cross\"):\n",
    "        print(f\"### Unknown dataset! Run: {run_name}, supposed data: {data_name} ###\")\n",
    "        continue\n",
    "\n",
    "    data.append((run_name, (model_name, data_name, seq_len, batch_size, acc_steps, num_epoch), stats_test))\n",
    "\n",
    "\n",
    "data = sorted(data, key=lambda x: x[2][\"eval_acc\"], reverse=True)\n",
    "\n",
    "\n",
    "for run_name, params, stats_test in data:\n",
    "    print(run_name)\n",
    "    print(f\"  test: {stats_test['eval_acc'] * 100:05.2f} ({stats_test['eval_f1'] * 100:05.2f})\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "albert-base-v2-cross_512_8-acc64_3\n",
      "  test: 74.16 (73.70)\n",
      "albert-base-v2-within_512_8-acc64_3\n",
      "  test: 73.81 (72.03)\n",
      "bert-base-cased-within_256_16-acc64_3\n",
      "  test: 73.02 (70.18)\n",
      "bert-base-uncased-within_512_8-acc64_3\n",
      "  test: 71.83 (65.70)\n",
      "bert-base-uncased-within_256_16-acc64_10\n",
      "  test: 71.43 (69.75)\n",
      "albert-base-v2-within_256_16-acc64_10\n",
      "  test: 70.63 (70.87)\n",
      "bert-base-uncased-cross_512_8-acc64_3\n",
      "  test: 70.56 (69.04)\n",
      "albert-base-v2-cross_256_16-acc64_10\n",
      "  test: 69.96 (66.30)\n",
      "bert-base-cased-within_512_8-acc64_3\n",
      "  test: 69.84 (63.81)\n",
      "bert-base-cased-cross_512_8-acc64_3\n",
      "  test: 69.57 (66.61)\n",
      "albert-base-v2-cross_256_12-acc64_3\n",
      "  test: 69.52 (68.44)\n",
      "albert-base-v1-within_256_16-acc64_3\n",
      "  test: 68.25 (63.30)\n",
      "bert-base-cased-cross_256_16-acc64_3\n",
      "  test: 67.93 (64.01)\n",
      "xlnet-base-cased-within_512_4-acc64_3\n",
      "  test: 66.67 (66.40)\n",
      "bert-base-uncased-within_256_16-acc64_3\n",
      "  test: 66.27 (62.22)\n",
      "albert-base-v2-within_256_16-acc64_3\n",
      "  test: 64.68 (57.00)\n",
      "squeezebert-squeezebert-uncased-cross_512_8-acc64_3\n",
      "  test: 64.51 (60.93)\n",
      "albert-base-v1-cross_256_16-acc64_3\n",
      "  test: 62.14 (50.25)\n",
      "squeezebert-squeezebert-uncased-within_512_8-acc64_3\n",
      "  test: 61.11 (44.32)\n",
      "xlnet-base-cased-cross_256_8-acc64_3\n",
      "  test: 61.10 (52.04)\n",
      "squeezebert-squeezebert-uncased-within_256_8-acc64_3\n",
      "  test: 59.92 (42.29)\n",
      "xlnet-base-cased-cross_512_4-acc64_3\n",
      "  test: 58.93 (43.90)\n",
      "squeezebert-squeezebert-uncased-cross_256_16-acc64_3\n",
      "  test: 56.36 (29.99)\n",
      "bert-base-uncased-cross_256_16-acc64_3\n",
      "  test: 55.98 (34.75)\n",
      "albert-base-v2-within_128_32-acc64_3\n",
      "  test: 55.56 (37.78)\n",
      "google-electra-base-discriminator-cross_256_16-acc64_3\n",
      "  test: 55.27 (31.30)\n",
      "albert-base-v2-cross_128_32-acc64_3\n",
      "  test: 54.66 (29.63)\n",
      "bert-base-uncased-cross_128_32-acc64_3\n",
      "  test: 54.54 (28.73)\n",
      "google-electra-base-discriminator-cross_512_8-acc64_3\n",
      "  test: 54.03 (28.69)\n",
      "roberta-base-cross_512_8-acc64_3\n",
      "  test: 53.68 (17.62)\n",
      "distilroberta-base-cross_512_8-acc64_3\n",
      "  test: 53.40 (16.85)\n",
      "sentence-transformers-stsb-distilbert-base-cross_256_16-acc64_3\n",
      "  test: 53.25 (21.73)\n",
      "distilroberta-base-cross_256_16-acc64_3\n",
      "  test: 53.14 (18.31)\n",
      "distilbert-base-cased-cross_512_8-acc64_3\n",
      "  test: 53.09 (18.24)\n",
      "distilbert-base-cased-cross_256_16-acc64_3\n",
      "  test: 53.01 (20.41)\n",
      "google-electra-base-discriminator-within_256_16-acc64_3\n",
      "  test: 52.78 (31.21)\n",
      "google-electra-base-discriminator-within_512_8-acc64_3\n",
      "  test: 52.78 (20.13)\n",
      "google-electra-small-discriminator-within_512_8-acc64_3\n",
      "  test: 52.78 (15.60)\n",
      "roberta-base-cross_256_16-acc64_3\n",
      "  test: 52.64 (12.93)\n",
      "bert-base-uncased-within_128_32-acc64_3\n",
      "  test: 52.38 (16.67)\n",
      "sentence-transformers-stsb-distilbert-base-within_256_16-acc64_3\n",
      "  test: 52.38 (21.05)\n",
      "google-electra-small-discriminator-cross_256_16-acc64_3\n",
      "  test: 52.31 (15.21)\n",
      "distilroberta-base-within_512_8-acc64_3\n",
      "  test: 51.98 (12.95)\n",
      "google-electra-small-discriminator-cross_512_8-acc64_3\n",
      "  test: 51.82 (35.81)\n",
      "xlnet-base-cased-within_256_8-acc64_3\n",
      "  test: 51.59 (10.29)\n",
      "distilroberta-base-within_256_16-acc64_3\n",
      "  test: 51.19 (11.51)\n",
      "roberta-base-within_256_16-acc64_3\n",
      "  test: 51.19 (04.65)\n",
      "sentence-transformers-stsb-distilbert-base-cross_512_8-acc64_3\n",
      "  test: 50.89 (39.33)\n",
      "sentence-transformers-stsb-distilbert-base-within_512_8-acc64_3\n",
      "  test: 50.79 (31.87)\n",
      "distilbert-base-cased-within_512_8-acc64_3\n",
      "  test: 50.40 (07.41)\n",
      "sentence-transformers-quora-distilbert-base-within_256_16-acc64_3\n",
      "  test: 50.40 (03.10)\n",
      "albert-large-v2-within_256_8-acc64_3\n",
      "  test: 50.00 (66.67)\n",
      "roberta-base-within_512_8-acc64_3\n",
      "  test: 49.60 (00.00)\n",
      "bert-base-uncased-cross_256_16-acc64_10\n",
      "  test: 49.26 (06.68)\n",
      "distilbert-base-cased-within_256_32-acc64_3\n",
      "  test: 49.21 (03.03)\n",
      "google-electra-small-discriminator-within_256_16-acc64_3\n",
      "  test: 49.21 (05.88)\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "param_pad_length = [max(len(str(x[1][i])) for x in data) for i in range(len(data[0][1]))]\n",
    "\n",
    "\n",
    "for _, (model_name, data_name, seq_len, batch_size, acc_steps, num_epoch), stats_test in data:\n",
    "    print(\n",
    "        # model_name\n",
    "        f\"{model_name:<{param_pad_length[0]}}\"\n",
    "        # data_name\n",
    "        f\"  {data_name:<{param_pad_length[1]}}\"\n",
    "        # seq_len\n",
    "        f\"  {seq_len:>{param_pad_length[2]}}\"\n",
    "        # batch_size\n",
    "        #f\"  {batch_size:>{param_pad_length[3]}}\"\n",
    "        # acc_steps\n",
    "        #f\"  {acc_steps:>{pad_length[4]}}\"\n",
    "        # num_epoch\n",
    "        #f\"  {num_epoch:>{pad_length[5]}}\"\n",
    "        # accuracy, f1-score\n",
    "        f\"  |  {stats_test['eval_acc'] * 100:05.2f}\"\n",
    "        f\" ({stats_test['eval_f1'] * 100:05.2f})\"\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "albert-base-v2                               cross   512  |  74.16 (73.70)\n",
      "albert-base-v2                               within  512  |  73.81 (72.03)\n",
      "bert-base-cased                              within  256  |  73.02 (70.18)\n",
      "bert-base-uncased                            within  512  |  71.83 (65.70)\n",
      "bert-base-uncased                            within  256  |  71.43 (69.75)\n",
      "albert-base-v2                               within  256  |  70.63 (70.87)\n",
      "bert-base-uncased                            cross   512  |  70.56 (69.04)\n",
      "albert-base-v2                               cross   256  |  69.96 (66.30)\n",
      "bert-base-cased                              within  512  |  69.84 (63.81)\n",
      "bert-base-cased                              cross   512  |  69.57 (66.61)\n",
      "albert-base-v2                               cross   256  |  69.52 (68.44)\n",
      "albert-base-v1                               within  256  |  68.25 (63.30)\n",
      "bert-base-cased                              cross   256  |  67.93 (64.01)\n",
      "xlnet-base-cased                             within  512  |  66.67 (66.40)\n",
      "bert-base-uncased                            within  256  |  66.27 (62.22)\n",
      "albert-base-v2                               within  256  |  64.68 (57.00)\n",
      "squeezebert-squeezebert-uncased              cross   512  |  64.51 (60.93)\n",
      "albert-base-v1                               cross   256  |  62.14 (50.25)\n",
      "squeezebert-squeezebert-uncased              within  512  |  61.11 (44.32)\n",
      "xlnet-base-cased                             cross   256  |  61.10 (52.04)\n",
      "squeezebert-squeezebert-uncased              within  256  |  59.92 (42.29)\n",
      "xlnet-base-cased                             cross   512  |  58.93 (43.90)\n",
      "squeezebert-squeezebert-uncased              cross   256  |  56.36 (29.99)\n",
      "bert-base-uncased                            cross   256  |  55.98 (34.75)\n",
      "albert-base-v2                               within  128  |  55.56 (37.78)\n",
      "google-electra-base-discriminator            cross   256  |  55.27 (31.30)\n",
      "albert-base-v2                               cross   128  |  54.66 (29.63)\n",
      "bert-base-uncased                            cross   128  |  54.54 (28.73)\n",
      "google-electra-base-discriminator            cross   512  |  54.03 (28.69)\n",
      "roberta-base                                 cross   512  |  53.68 (17.62)\n",
      "distilroberta-base                           cross   512  |  53.40 (16.85)\n",
      "sentence-transformers-stsb-distilbert-base   cross   256  |  53.25 (21.73)\n",
      "distilroberta-base                           cross   256  |  53.14 (18.31)\n",
      "distilbert-base-cased                        cross   512  |  53.09 (18.24)\n",
      "distilbert-base-cased                        cross   256  |  53.01 (20.41)\n",
      "google-electra-base-discriminator            within  256  |  52.78 (31.21)\n",
      "google-electra-base-discriminator            within  512  |  52.78 (20.13)\n",
      "google-electra-small-discriminator           within  512  |  52.78 (15.60)\n",
      "roberta-base                                 cross   256  |  52.64 (12.93)\n",
      "bert-base-uncased                            within  128  |  52.38 (16.67)\n",
      "sentence-transformers-stsb-distilbert-base   within  256  |  52.38 (21.05)\n",
      "google-electra-small-discriminator           cross   256  |  52.31 (15.21)\n",
      "distilroberta-base                           within  512  |  51.98 (12.95)\n",
      "google-electra-small-discriminator           cross   512  |  51.82 (35.81)\n",
      "xlnet-base-cased                             within  256  |  51.59 (10.29)\n",
      "distilroberta-base                           within  256  |  51.19 (11.51)\n",
      "roberta-base                                 within  256  |  51.19 (04.65)\n",
      "sentence-transformers-stsb-distilbert-base   cross   512  |  50.89 (39.33)\n",
      "sentence-transformers-stsb-distilbert-base   within  512  |  50.79 (31.87)\n",
      "distilbert-base-cased                        within  512  |  50.40 (07.41)\n",
      "sentence-transformers-quora-distilbert-base  within  256  |  50.40 (03.10)\n",
      "albert-large-v2                              within  256  |  50.00 (66.67)\n",
      "roberta-base                                 within  512  |  49.60 (00.00)\n",
      "bert-base-uncased                            cross   256  |  49.26 (06.68)\n",
      "distilbert-base-cased                        within  256  |  49.21 (03.03)\n",
      "google-electra-small-discriminator           within  256  |  49.21 (05.88)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute metrics and rank"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm().pandas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "fn_base = Path(\"output\")\n",
    "\n",
    "data = list()\n",
    "for fn in sorted(fn_base.iterdir()):\n",
    "    run_name = fn.name\n",
    "\n",
    "    sfn = fn / \"eval_results_same-b.json\"\n",
    "    if not sfn.exists():\n",
    "        continue\n",
    "\n",
    "    parts = run_name.split(\"_\")\n",
    "    model_name, data_name = parts[0].rsplit(\"-\", 1)\n",
    "    seq_len = int(parts[1])\n",
    "    batch_size, acc_steps = parts[2].split(\"-acc\")\n",
    "    batch_size, acc_steps = int(batch_size), int(acc_steps)\n",
    "    num_epoch = int(parts[3])\n",
    "    \n",
    "    if data_name not in (\"within\", \"cross\"):\n",
    "        print(f\"### Unknown dataset! Run: {run_name}, supposed data: {data_name} ###\")\n",
    "        continue\n",
    "\n",
    "    data.append((run_name, model_name, data_name, seq_len, batch_size, acc_steps, num_epoch))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "pad_length = [max(len(str(x[i])) for x in data) for i in range(len(data[0]))]\n",
    "for parts in data:\n",
    "    # print(f\"{parts[0]:<{pad_length[0]}}\")  # run_name\n",
    "    print(\n",
    "        # model_name, data_name\n",
    "        f\"{parts[1]:<{pad_length[1]}}  {parts[2]:<{pad_length[2]}}  \"\n",
    "        # seq_len, batch_size\n",
    "        f\"{parts[3]:>{pad_length[3]}}  {parts[4]:>{pad_length[4]}}  \"\n",
    "        # acc_steps, num_epoch\n",
    "        f\"{parts[5]:>{pad_length[5]}}  {parts[6]:>{pad_length[6]}}\"\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "albert-base-v1                               cross   256  16  64   3\n",
      "albert-base-v1                               within  256  16  64   3\n",
      "albert-base-v2                               cross   128  32  64   3\n",
      "albert-base-v2                               cross   256  12  64   3\n",
      "albert-base-v2                               cross   256  16  64  10\n",
      "albert-base-v2                               cross   512   8  64   3\n",
      "albert-base-v2                               within  128  32  64   3\n",
      "albert-base-v2                               within  256  16  64  10\n",
      "albert-base-v2                               within  256  16  64   3\n",
      "albert-base-v2                               within  512   8  64   3\n",
      "albert-large-v2                              within  256   8  64   3\n",
      "bert-base-cased                              cross   256  16  64   3\n",
      "bert-base-cased                              cross   512   8  64   3\n",
      "bert-base-cased                              within  256  16  64   3\n",
      "bert-base-cased                              within  512   8  64   3\n",
      "bert-base-uncased                            cross   128  32  64   3\n",
      "bert-base-uncased                            cross   256  16  64  10\n",
      "bert-base-uncased                            cross   256  16  64   3\n",
      "bert-base-uncased                            cross   512   8  64   3\n",
      "bert-base-uncased                            within  128  32  64   3\n",
      "bert-base-uncased                            within  256  16  64  10\n",
      "bert-base-uncased                            within  256  16  64   3\n",
      "bert-base-uncased                            within  512   8  64   3\n",
      "distilbert-base-cased                        cross   256  16  64   3\n",
      "distilbert-base-cased                        cross   512   8  64   3\n",
      "distilbert-base-cased                        within  256  32  64   3\n",
      "distilbert-base-cased                        within  512   8  64   3\n",
      "distilroberta-base                           cross   256  16  64   3\n",
      "distilroberta-base                           cross   512   8  64   3\n",
      "distilroberta-base                           within  256  16  64   3\n",
      "distilroberta-base                           within  512   8  64   3\n",
      "google-electra-base-discriminator            cross   256  16  64   3\n",
      "google-electra-base-discriminator            cross   512   8  64   3\n",
      "google-electra-base-discriminator            within  256  16  64   3\n",
      "google-electra-base-discriminator            within  512   8  64   3\n",
      "google-electra-small-discriminator           cross   256  16  64   3\n",
      "google-electra-small-discriminator           cross   512   8  64   3\n",
      "google-electra-small-discriminator           within  256  16  64   3\n",
      "google-electra-small-discriminator           within  512   8  64   3\n",
      "roberta-base                                 cross   256  16  64   3\n",
      "roberta-base                                 cross   512   8  64   3\n",
      "roberta-base                                 within  256  16  64   3\n",
      "roberta-base                                 within  512   8  64   3\n",
      "sentence-transformers-quora-distilbert-base  within  256  16  64   3\n",
      "sentence-transformers-stsb-distilbert-base   cross   256  16  64   3\n",
      "sentence-transformers-stsb-distilbert-base   cross   512   8  64   3\n",
      "sentence-transformers-stsb-distilbert-base   within  256  16  64   3\n",
      "sentence-transformers-stsb-distilbert-base   within  512   8  64   3\n",
      "squeezebert-squeezebert-uncased              cross   256  16  64   3\n",
      "squeezebert-squeezebert-uncased              cross   512   8  64   3\n",
      "squeezebert-squeezebert-uncased              within  256   8  64   3\n",
      "squeezebert-squeezebert-uncased              within  512   8  64   3\n",
      "xlnet-base-cased                             cross   256   8  64   3\n",
      "xlnet-base-cased                             cross   512   4  64   3\n",
      "xlnet-base-cased                             within  256   8  64   3\n",
      "xlnet-base-cased                             within  512   4  64   3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load gold labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "fn_ground_truth_p = \"data/ground_truth.p\"\n",
    "\n",
    "with open(fn_ground_truth_p, \"rb\") as fp:\n",
    "    within_test_df = pickle.load(fp)\n",
    "    cross_test_df = pickle.load(fp)"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load predictions and compute metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "metrics = dict()\n",
    "\n",
    "for run_name, model_name, data_name, seq_len, batch_size, acc_steps, num_epoch in data:\n",
    "    fn_preds = Path(f\"./output_emnlp21/{run_name}/pred_results_same-b.txt\")\n",
    "    with fn_preds.open(\"r\") as fp:\n",
    "        fp.readline()\n",
    "        pred_data = [line.rstrip().split(\"\\t\") for line in fp]\n",
    "    pred_data = [(int(id_), int(label)) for id_, label in pred_data]\n",
    "    df_preds = pd.DataFrame.from_records(pred_data, columns=[\"id\", \"label\"], index=\"id\")\n",
    "\n",
    "    df_gold = within_test_df if data_name == \"within\" else cross_test_df\n",
    "\n",
    "    labels_truth = df_gold[\"is_same_side\"].astype(\"bool\").to_numpy()\n",
    "    label_preds = df_preds[\"label\"].astype(\"bool\").to_numpy()\n",
    "\n",
    "    metrics[run_name] = {\n",
    "        \"precision\": precision_score(labels_truth, label_preds, average=\"binary\"),\n",
    "        \"recall\": recall_score(labels_truth, label_preds, average=\"binary\"),\n",
    "        \"f1\": f1_score(labels_truth, label_preds, average=\"binary\"),\n",
    "        \"accuracy\": accuracy_score(labels_truth, label_preds),\n",
    "    }"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rank and plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "pad_length = [max(len(str(x[i])) for x in data) for i in range(len(data[0]))]\n",
    "\n",
    "for task, subdata in (\n",
    "    (\"within\", [x for x in data if x[2] == \"within\"]),\n",
    "    (\"cross\", [x for x in data if x[2] == \"cross\"])\n",
    "):\n",
    "    print()\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Task: {task.upper()}\")\n",
    "    print(\"-\" * 30)\n",
    "    for run_name, model_name, data_name, seq_len, batch_size, acc_steps, num_epoch in subdata:\n",
    "        run_metric = metrics[run_name]\n",
    "\n",
    "        print(\n",
    "            # model_name, data_name, seq_len\n",
    "            f\"{model_name:<{pad_length[1]}}\"\n",
    "            #f\"  {data_name:<{pad_length[2]}}\"\n",
    "            f\"  {seq_len:>{pad_length[3]}}\"\n",
    "            f\"  |  {run_metric['precision'] * 100:>6.02f}%\"\n",
    "            f\" {run_metric['recall'] * 100:>6.02f}%\"\n",
    "            f\" {run_metric['f1'] * 100:>6.02f}%\"\n",
    "            f\" {run_metric['accuracy'] * 100:>6.02f}%\"\n",
    "        )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------------------------\n",
      "Task: WITHIN\n",
      "------------------------------\n",
      "albert-base-v1                               256  |   75.00%  54.76%  63.30%  68.25%\n",
      "albert-base-v2                               128  |   62.96%  26.98%  37.78%  55.56%\n",
      "albert-base-v2                               256  |   70.31%  71.43%  70.87%  70.63%\n",
      "albert-base-v2                               256  |   72.84%  46.83%  57.00%  64.68%\n",
      "albert-base-v2                               512  |   77.27%  67.46%  72.03%  73.81%\n",
      "albert-large-v2                              256  |   50.00% 100.00%  66.67%  50.00%\n",
      "bert-base-cased                              256  |   78.43%  63.49%  70.18%  73.02%\n",
      "bert-base-cased                              512  |   79.76%  53.17%  63.81%  69.84%\n",
      "bert-base-uncased                            128  |   66.67%   9.52%  16.67%  52.38%\n",
      "bert-base-uncased                            256  |   74.11%  65.87%  69.75%  71.43%\n",
      "bert-base-uncased                            256  |   70.71%  55.56%  62.22%  66.27%\n",
      "bert-base-uncased                            512  |   83.95%  53.97%  65.70%  71.83%\n",
      "distilbert-base-cased                        256  |   33.33%   1.59%   3.03%  49.21%\n",
      "distilbert-base-cased                        512  |   55.56%   3.97%   7.41%  50.40%\n",
      "distilroberta-base                           256  |   61.54%   6.35%  11.51%  51.19%\n",
      "distilroberta-base                           512  |   69.23%   7.14%  12.95%  51.98%\n",
      "google-electra-base-discriminator            256  |   57.45%  21.43%  31.21%  52.78%\n",
      "google-electra-base-discriminator            512  |   65.22%  11.90%  20.13%  52.78%\n",
      "google-electra-small-discriminator           256  |   40.00%   3.17%   5.88%  49.21%\n",
      "google-electra-small-discriminator           512  |   73.33%   8.73%  15.60%  52.78%\n",
      "roberta-base                                 256  |  100.00%   2.38%   4.65%  51.19%\n",
      "roberta-base                                 512  |    0.00%   0.00%   0.00%  49.60%\n",
      "sentence-transformers-quora-distilbert-base  256  |   66.67%   1.59%   3.10%  50.40%\n",
      "sentence-transformers-stsb-distilbert-base   256  |   61.54%  12.70%  21.05%  52.38%\n",
      "sentence-transformers-stsb-distilbert-base   512  |   51.79%  23.02%  31.87%  50.79%\n",
      "squeezebert-squeezebert-uncased              256  |   75.51%  29.37%  42.29%  59.92%\n",
      "squeezebert-squeezebert-uncased              512  |   78.00%  30.95%  44.32%  61.11%\n",
      "xlnet-base-cased                             256  |   70.00%   5.56%  10.29%  51.59%\n",
      "xlnet-base-cased                             512  |   66.94%  65.87%  66.40%  66.67%\n",
      "\n",
      "------------------------------\n",
      "Task: CROSS\n",
      "------------------------------\n",
      "albert-base-v1                               256  |   73.24%  38.24%  50.25%  62.14%\n",
      "albert-base-v2                               128  |   66.13%  19.09%  29.63%  54.66%\n",
      "albert-base-v2                               256  |   70.94%  66.12%  68.44%  69.52%\n",
      "albert-base-v2                               256  |   75.52%  59.08%  66.30%  69.96%\n",
      "albert-base-v2                               512  |   75.03%  72.42%  73.70%  74.16%\n",
      "bert-base-cased                              256  |   72.93%  57.03%  64.01%  67.93%\n",
      "bert-base-cased                              512  |   73.79%  60.70%  66.61%  69.57%\n",
      "bert-base-uncased                            128  |   66.47%  18.33%  28.73%  54.54%\n",
      "bert-base-uncased                            256  |   41.51%   3.63%   6.68%  49.26%\n",
      "bert-base-uncased                            256  |   67.11%  23.45%  34.75%  55.98%\n",
      "bert-base-uncased                            512  |   72.79%  65.65%  69.04%  70.56%\n",
      "distilbert-base-cased                        256  |   66.61%  12.05%  20.41%  53.01%\n",
      "distilbert-base-cased                        512  |   70.92%  10.47%  18.24%  53.09%\n",
      "distilroberta-base                           256  |   71.30%  10.50%  18.31%  53.14%\n",
      "distilroberta-base                           512  |   78.14%   9.45%  16.85%  53.40%\n",
      "google-electra-base-discriminator            256  |   67.43%  20.38%  31.30%  55.27%\n",
      "google-electra-base-discriminator            512  |   63.93%  18.49%  28.69%  54.03%\n",
      "google-electra-small-discriminator           256  |   68.52%   8.55%  15.21%  52.31%\n",
      "google-electra-small-discriminator           512  |   53.62%  26.88%  35.81%  51.82%\n",
      "roberta-base                                 256  |   80.08%   7.03%  12.93%  52.64%\n",
      "roberta-base                                 512  |   79.58%   9.91%  17.62%  53.68%\n",
      "sentence-transformers-stsb-distilbert-base   256  |   66.72%  12.98%  21.73%  53.25%\n",
      "sentence-transformers-stsb-distilbert-base   512  |   51.44%  31.84%  39.33%  50.89%\n",
      "squeezebert-squeezebert-uncased              256  |   75.77%  18.69%  29.99%  56.36%\n",
      "squeezebert-squeezebert-uncased              512  |   67.77%  55.35%  60.93%  64.51%\n",
      "xlnet-base-cased                             256  |   67.83%  42.21%  52.04%  61.10%\n",
      "xlnet-base-cased                             512  |   69.25%  32.13%  43.90%  58.93%\n"
     ]
    }
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pad_length = [max(len(str(x[i])) for x in data) for i in range(len(data[0]))]\n",
    "\n",
    "for task, subdata in (\n",
    "    (\"within\", [x for x in data if x[2] == \"within\"]),\n",
    "    (\"cross\", [x for x in data if x[2] == \"cross\"])\n",
    "):\n",
    "    print()\n",
    "    print(\"=\" * 79)\n",
    "    print(f\"Task: {task.upper()}\")\n",
    "    print(\"=\" * 79)\n",
    "    \n",
    "    for seq_len, subdata in (\n",
    "        (128, [x for x in subdata if x[3] == 128]),\n",
    "        (256, [x for x in subdata if x[3] == 256]),\n",
    "        (512, [x for x in subdata if x[3] == 512])\n",
    "    ):\n",
    "        print()\n",
    "        print(f\"Sequence length: {seq_len}\")\n",
    "        print(\"-\" * 79)\n",
    "\n",
    "        subdata = sorted(subdata, key=lambda x: metrics[x[0]][\"f1\"], reverse=True)\n",
    "\n",
    "        for run_name, model_name, data_name, seq_len, batch_size, acc_steps, num_epoch in subdata:\n",
    "            run_metric = metrics[run_name]\n",
    "\n",
    "            print(\n",
    "                # model_name, data_name, seq_len\n",
    "                f\"{model_name:<{pad_length[1]}}\"\n",
    "                #f\"  {data_name:<{pad_length[2]}}\"\n",
    "                #f\"  {seq_len:>{pad_length[3]}}\"\n",
    "                f\"  |  {run_metric['precision'] * 100:>6.02f}%\"\n",
    "                f\" {run_metric['recall'] * 100:>6.02f}%\"\n",
    "                f\" {run_metric['f1'] * 100:>6.02f}%\"\n",
    "                f\" {run_metric['accuracy'] * 100:>6.02f}%\"\n",
    "            )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "===============================================================================\n",
      "Task: WITHIN\n",
      "===============================================================================\n",
      "\n",
      "Sequence length: 128\n",
      "-------------------------------------------------------------------------------\n",
      "albert-base-v2                               |   62.96%  26.98%  37.78%  55.56%\n",
      "bert-base-uncased                            |   66.67%   9.52%  16.67%  52.38%\n",
      "\n",
      "Sequence length: 256\n",
      "-------------------------------------------------------------------------------\n",
      "albert-base-v2                               |   70.31%  71.43%  70.87%  70.63%\n",
      "bert-base-cased                              |   78.43%  63.49%  70.18%  73.02%\n",
      "bert-base-uncased                            |   74.11%  65.87%  69.75%  71.43%\n",
      "albert-large-v2                              |   50.00% 100.00%  66.67%  50.00%\n",
      "albert-base-v1                               |   75.00%  54.76%  63.30%  68.25%\n",
      "bert-base-uncased                            |   70.71%  55.56%  62.22%  66.27%\n",
      "albert-base-v2                               |   72.84%  46.83%  57.00%  64.68%\n",
      "squeezebert-squeezebert-uncased              |   75.51%  29.37%  42.29%  59.92%\n",
      "google-electra-base-discriminator            |   57.45%  21.43%  31.21%  52.78%\n",
      "sentence-transformers-stsb-distilbert-base   |   61.54%  12.70%  21.05%  52.38%\n",
      "distilroberta-base                           |   61.54%   6.35%  11.51%  51.19%\n",
      "xlnet-base-cased                             |   70.00%   5.56%  10.29%  51.59%\n",
      "google-electra-small-discriminator           |   40.00%   3.17%   5.88%  49.21%\n",
      "roberta-base                                 |  100.00%   2.38%   4.65%  51.19%\n",
      "sentence-transformers-quora-distilbert-base  |   66.67%   1.59%   3.10%  50.40%\n",
      "distilbert-base-cased                        |   33.33%   1.59%   3.03%  49.21%\n",
      "\n",
      "Sequence length: 512\n",
      "-------------------------------------------------------------------------------\n",
      "albert-base-v2                               |   77.27%  67.46%  72.03%  73.81%\n",
      "xlnet-base-cased                             |   66.94%  65.87%  66.40%  66.67%\n",
      "bert-base-uncased                            |   83.95%  53.97%  65.70%  71.83%\n",
      "bert-base-cased                              |   79.76%  53.17%  63.81%  69.84%\n",
      "squeezebert-squeezebert-uncased              |   78.00%  30.95%  44.32%  61.11%\n",
      "sentence-transformers-stsb-distilbert-base   |   51.79%  23.02%  31.87%  50.79%\n",
      "google-electra-base-discriminator            |   65.22%  11.90%  20.13%  52.78%\n",
      "google-electra-small-discriminator           |   73.33%   8.73%  15.60%  52.78%\n",
      "distilroberta-base                           |   69.23%   7.14%  12.95%  51.98%\n",
      "distilbert-base-cased                        |   55.56%   3.97%   7.41%  50.40%\n",
      "roberta-base                                 |    0.00%   0.00%   0.00%  49.60%\n",
      "\n",
      "===============================================================================\n",
      "Task: CROSS\n",
      "===============================================================================\n",
      "\n",
      "Sequence length: 128\n",
      "-------------------------------------------------------------------------------\n",
      "albert-base-v2                               |   66.13%  19.09%  29.63%  54.66%\n",
      "bert-base-uncased                            |   66.47%  18.33%  28.73%  54.54%\n",
      "\n",
      "Sequence length: 256\n",
      "-------------------------------------------------------------------------------\n",
      "albert-base-v2                               |   70.94%  66.12%  68.44%  69.52%\n",
      "albert-base-v2                               |   75.52%  59.08%  66.30%  69.96%\n",
      "bert-base-cased                              |   72.93%  57.03%  64.01%  67.93%\n",
      "xlnet-base-cased                             |   67.83%  42.21%  52.04%  61.10%\n",
      "albert-base-v1                               |   73.24%  38.24%  50.25%  62.14%\n",
      "bert-base-uncased                            |   67.11%  23.45%  34.75%  55.98%\n",
      "google-electra-base-discriminator            |   67.43%  20.38%  31.30%  55.27%\n",
      "squeezebert-squeezebert-uncased              |   75.77%  18.69%  29.99%  56.36%\n",
      "sentence-transformers-stsb-distilbert-base   |   66.72%  12.98%  21.73%  53.25%\n",
      "distilbert-base-cased                        |   66.61%  12.05%  20.41%  53.01%\n",
      "distilroberta-base                           |   71.30%  10.50%  18.31%  53.14%\n",
      "google-electra-small-discriminator           |   68.52%   8.55%  15.21%  52.31%\n",
      "roberta-base                                 |   80.08%   7.03%  12.93%  52.64%\n",
      "bert-base-uncased                            |   41.51%   3.63%   6.68%  49.26%\n",
      "\n",
      "Sequence length: 512\n",
      "-------------------------------------------------------------------------------\n",
      "albert-base-v2                               |   75.03%  72.42%  73.70%  74.16%\n",
      "bert-base-uncased                            |   72.79%  65.65%  69.04%  70.56%\n",
      "bert-base-cased                              |   73.79%  60.70%  66.61%  69.57%\n",
      "squeezebert-squeezebert-uncased              |   67.77%  55.35%  60.93%  64.51%\n",
      "xlnet-base-cased                             |   69.25%  32.13%  43.90%  58.93%\n",
      "sentence-transformers-stsb-distilbert-base   |   51.44%  31.84%  39.33%  50.89%\n",
      "google-electra-small-discriminator           |   53.62%  26.88%  35.81%  51.82%\n",
      "google-electra-base-discriminator            |   63.93%  18.49%  28.69%  54.03%\n",
      "distilbert-base-cased                        |   70.92%  10.47%  18.24%  53.09%\n",
      "roberta-base                                 |   79.58%   9.91%  17.62%  53.68%\n",
      "distilroberta-base                           |   78.14%   9.45%  16.85%  53.40%\n"
     ]
    }
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "### ?\n",
    "\n",
    "<details>\n",
    "<summary>dev</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>test</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}